searchData={"items":[{"type":"module","title":"Anoma.Constants","doc":"","ref":"Anoma.Constants.html"},{"type":"function","title":"Anoma.Constants.cairo_compliance_program_hash/0","doc":"","ref":"Anoma.Constants.html#cairo_compliance_program_hash/0"},{"type":"function","title":"Anoma.Constants.felt_one/0","doc":"","ref":"Anoma.Constants.html#felt_one/0"},{"type":"function","title":"Anoma.Constants.felt_zero/0","doc":"","ref":"Anoma.Constants.html#felt_zero/0"},{"type":"function","title":"Anoma.Constants.prf_expand_personalization_felt/0","doc":"","ref":"Anoma.Constants.html#prf_expand_personalization_felt/0"},{"type":"module","title":"Anoma.System.Directories","doc":"I provide out utilities for ensuring user Data, Config,\netc. directories are properly setup for the host operating system.\n\nPlease use me when trying to write to user directories.","ref":"Anoma.System.Directories.html"},{"type":"function","title":"Anoma.System.Directories.configuration/2","doc":"I provide a proper translation from a user directory to the\ncorresponding system configuration directory.","ref":"Anoma.System.Directories.html#configuration/2"},{"type":"function","title":"Parameters - Anoma.System.Directories.configuration/2","doc":"- `file_path` - the path given by the user\n- `env` (optional) - the system environment. It defaults to the\n  application environment. The `:test` environment uses the local\n  directory instead of the system directory","ref":"Anoma.System.Directories.html#configuration/2-parameters"},{"type":"function","title":"Returns - Anoma.System.Directories.configuration/2","doc":"The correct environment which to save configuration details","ref":"Anoma.System.Directories.html#configuration/2-returns"},{"type":"function","title":"Anoma.System.Directories.data/2","doc":"I provide a proper translation from a user directory to the\ncorresponding system data directory.","ref":"Anoma.System.Directories.html#data/2"},{"type":"function","title":"Parameters - Anoma.System.Directories.data/2","doc":"- `file_path` - the path given by the user\n- `env` (optional) - the system environment. It defaults to the\n  application environment. The `:test` environment uses the local\n  directory instead of the system directory","ref":"Anoma.System.Directories.html#data/2-parameters"},{"type":"function","title":"Returns - Anoma.System.Directories.data/2","doc":"The correct environment which to save data details","ref":"Anoma.System.Directories.html#data/2-returns"},{"type":"module","title":"Glossary","doc":"","ref":"Glossary.html"},{"type":"function","title":"Glossary.transaction_candidate/0","doc":"A transaction candidate is `t:Noun.t/0` that evaluates to a valid or\ninvalid `transaction` for a specified\n`t:Anoma.Node.Executor.Worker.backend/0`","ref":"Glossary.html#transaction_candidate/0"},{"type":"module","title":"IdentityMap","doc":"A map with an identity value; all keys not explicitly assigned a value map to\nthe identity.","ref":"IdentityMap.html"},{"type":"function","title":"IdentityMap.get/2","doc":"","ref":"IdentityMap.html#get/2"},{"type":"function","title":"IdentityMap.new/3","doc":"","ref":"IdentityMap.html#new/3"},{"type":"function","title":"IdentityMap.put/3","doc":"","ref":"IdentityMap.html#put/3"},{"type":"function","title":"IdentityMap.update/3","doc":"","ref":"IdentityMap.html#update/3"},{"type":"type","title":"IdentityMap.t/2","doc":"","ref":"IdentityMap.html#t:t/2"},{"type":"module","title":"Livebook","doc":"I generate out extra information for Livebook\n\nMy main purpose is to generate out the TOC for each livebook\ndocument we have.\n\nto do this please run `toc_toplevel/0`\n\nTo set a certain order please set `sort_order/0` to have the updated\norder","ref":"Livebook.html"},{"type":"module","title":"API - Livebook","doc":"- `sort_order/0`\n- `toc_toplevel/0`\n- `get_all_livemd_documents/0`\n- `example_toc/0`","ref":"Livebook.html#module-api"},{"type":"function","title":"Livebook.add_heading_num/1","doc":"","ref":"Livebook.html#add_heading_num/1"},{"type":"function","title":"Livebook.change_header/4","doc":"I replace the header with the given TOC","ref":"Livebook.html#change_header/4"},{"type":"function","title":"Example - Livebook.change_header/4","doc":"> markdown_text = \"","ref":"Livebook.html#change_header/4-example"},{"type":"function","title":"Intro ... - Livebook.change_header/4","doc":"","ref":"Livebook.html#change_header/4-intro"},{"type":"function","title":"Index - Livebook.change_header/4","doc":"text here","ref":"Livebook.html#change_header/4-index"},{"type":"function","title":"Conclusion - Livebook.change_header/4","doc":"All good\"\n  > Livebook.change_header(markdown_text, \"##\", \"Index\", \"New Content\") |> IO.puts","ref":"Livebook.html#change_header/4-conclusion"},{"type":"function","title":"Intro ... - Livebook.change_header/4","doc":"","ref":"Livebook.html#change_header/4-intro"},{"type":"function","title":"Index - Livebook.change_header/4","doc":"New Content","ref":"Livebook.html#change_header/4-index"},{"type":"function","title":"Conclusion - Livebook.change_header/4","doc":"All good\n    :ok","ref":"Livebook.html#change_header/4-conclusion"},{"type":"function","title":"Livebook.count_depth/1","doc":"","ref":"Livebook.html#count_depth/1"},{"type":"function","title":"Livebook.dir_from_path/1","doc":"","ref":"Livebook.html#dir_from_path/1"},{"type":"function","title":"Livebook.example_toc/0","doc":"I provide an example of what a TOC looks like","ref":"Livebook.html#example_toc/0"},{"type":"function","title":"Livebook.generate_heading/4","doc":"","ref":"Livebook.html#generate_heading/4"},{"type":"function","title":"Livebook.generate_TOC/2","doc":"Generates out a TOC, given a series of nested documents\n\nWe take a path, and a place where we should be calculating the TOC from.","ref":"Livebook.html#generate_TOC/2"},{"type":"function","title":"Example - Livebook.generate_TOC/2","doc":"","ref":"Livebook.html#generate_TOC/2-example"},{"type":"function","title":"Livebook.get_all_livemd_documents/0","doc":"I get out all live view docs","ref":"Livebook.html#get_all_livemd_documents/0"},{"type":"function","title":"Livebook.get_livemd_documents/1","doc":"Gets all livemd documents in a sorted list given a path.","ref":"Livebook.html#get_livemd_documents/1"},{"type":"function","title":"Livebook.inject_TOC/2","doc":"","ref":"Livebook.html#inject_TOC/2"},{"type":"function","title":"Livebook.sort_order/0","doc":"","ref":"Livebook.html#sort_order/0"},{"type":"function","title":"Livebook.toc_toplevel/0","doc":"I generate out the TOC for all liveview docs","ref":"Livebook.html#toc_toplevel/0"},{"type":"type","title":"Livebook.sort/0","doc":"","ref":"Livebook.html#t:sort/0"},{"type":"module","title":"MapSetMap","doc":"An IdentityMap where the values are MapSets, plus some convenient helper functions.","ref":"MapSetMap.html"},{"type":"function","title":"MapSetMap.add/3","doc":"","ref":"MapSetMap.html#add/3"},{"type":"function","title":"MapSetMap.empty_map_p/1","doc":"","ref":"MapSetMap.html#empty_map_p/1"},{"type":"function","title":"MapSetMap.get/2","doc":"","ref":"MapSetMap.html#get/2"},{"type":"function","title":"MapSetMap.new/0","doc":"","ref":"MapSetMap.html#new/0"},{"type":"function","title":"MapSetMap.remove/3","doc":"","ref":"MapSetMap.html#remove/3"},{"type":"type","title":"MapSetMap.t/2","doc":"","ref":"MapSetMap.html#t:t/2"},{"type":"task","title":"mix toc","doc":"I generate out the TOC for each liveview doc","ref":"Mix.Tasks.Toc.html"},{"type":"function","title":"Mix.Tasks.Toc.run/1","doc":"","ref":"Mix.Tasks.Toc.html#run/1"},{"type":"module","title":"Anoma.RM.Trans","doc":"","ref":"Anoma.RM.Trans.html"},{"type":"function","title":"Anoma.RM.Trans.compose_pre_check/2","doc":"","ref":"Anoma.RM.Trans.html#compose_pre_check/2"},{"type":"protocol","title":"Anoma.RM.Transaction","doc":"I am the Transaction protocol.\n\nUse me when you want to write logic over transactions.\n\nTransactions practically speaking be `Noun.Nounable`","ref":"Anoma.RM.Transaction.html"},{"type":"function","title":"Anoma.RM.Transaction.cm_tree/2","doc":"","ref":"Anoma.RM.Transaction.html#cm_tree/2"},{"type":"function","title":"Anoma.RM.Transaction.commitments/1","doc":"","ref":"Anoma.RM.Transaction.html#commitments/1"},{"type":"function","title":"Anoma.RM.Transaction.compose/2","doc":"I compose two transactions into a new transaction","ref":"Anoma.RM.Transaction.html#compose/2"},{"type":"function","title":"Anoma.RM.Transaction.nullifiers/1","doc":"","ref":"Anoma.RM.Transaction.html#nullifiers/1"},{"type":"function","title":"Anoma.RM.Transaction.resource_existence_check/2","doc":"","ref":"Anoma.RM.Transaction.html#resource_existence_check/2"},{"type":"function","title":"Anoma.RM.Transaction.storage_commitments/1","doc":"","ref":"Anoma.RM.Transaction.html#storage_commitments/1"},{"type":"function","title":"Anoma.RM.Transaction.storage_nullifiers/1","doc":"","ref":"Anoma.RM.Transaction.html#storage_nullifiers/1"},{"type":"function","title":"Anoma.RM.Transaction.verify/1","doc":"","ref":"Anoma.RM.Transaction.html#verify/1"},{"type":"type","title":"Anoma.RM.Transaction.t/0","doc":"All the types that implement this protocol.","ref":"Anoma.RM.Transaction.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource","doc":"I am a shielded resource.","ref":"Anoma.ShieldedResource.html"},{"type":"function","title":"Anoma.ShieldedResource.commitment/1","doc":"A commitment to the given resource.","ref":"Anoma.ShieldedResource.html#commitment/1"},{"type":"function","title":"Anoma.ShieldedResource.get_npk/1","doc":"Generate the nullifier public key from the nulliffier (private)key.","ref":"Anoma.ShieldedResource.html#get_npk/1"},{"type":"function","title":"Anoma.ShieldedResource.nullifier/1","doc":"The nullifier of the given resource.","ref":"Anoma.ShieldedResource.html#nullifier/1"},{"type":"function","title":"Anoma.ShieldedResource.random/1","doc":"Randomizes the rseed of a resource.","ref":"Anoma.ShieldedResource.html#random/1"},{"type":"function","title":"Anoma.ShieldedResource.set_nonce/2","doc":"Set the nonce of a resource, the nonce of output resource comes from the\nnullifer of input recource in the compliance proof.","ref":"Anoma.ShieldedResource.html#set_nonce/2"},{"type":"function","title":"Anoma.ShieldedResource.to_bytes/1","doc":"","ref":"Anoma.ShieldedResource.html#to_bytes/1"},{"type":"type","title":"Anoma.ShieldedResource.t/0","doc":"","ref":"Anoma.ShieldedResource.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.ComplianceInput","doc":"I represent a compliance's input.","ref":"Anoma.ShieldedResource.ComplianceInput.html"},{"type":"function","title":"Anoma.ShieldedResource.ComplianceInput.to_json_string/1","doc":"Generate the compliance input json","ref":"Anoma.ShieldedResource.ComplianceInput.html#to_json_string/1"},{"type":"type","title":"Anoma.ShieldedResource.ComplianceInput.t/0","doc":"","ref":"Anoma.ShieldedResource.ComplianceInput.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.ComplianceOutput","doc":"I represent a resource's output.","ref":"Anoma.ShieldedResource.ComplianceOutput.html"},{"type":"function","title":"Anoma.ShieldedResource.ComplianceOutput.from_public_input/1","doc":"","ref":"Anoma.ShieldedResource.ComplianceOutput.html#from_public_input/1"},{"type":"type","title":"Anoma.ShieldedResource.ComplianceOutput.t/0","doc":"","ref":"Anoma.ShieldedResource.ComplianceOutput.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.PartialTransaction","doc":"I am a shielded resource machine partial transaction.","ref":"Anoma.ShieldedResource.PartialTransaction.html"},{"type":"function","title":"Anoma.ShieldedResource.PartialTransaction.from_noun/1","doc":"","ref":"Anoma.ShieldedResource.PartialTransaction.html#from_noun/1"},{"type":"function","title":"Anoma.ShieldedResource.PartialTransaction.verify/1","doc":"","ref":"Anoma.ShieldedResource.PartialTransaction.html#verify/1"},{"type":"type","title":"Anoma.ShieldedResource.PartialTransaction.t/0","doc":"","ref":"Anoma.ShieldedResource.PartialTransaction.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.ProofRecord","doc":"I am a proof record for a shielded resource.","ref":"Anoma.ShieldedResource.ProofRecord.html"},{"type":"function","title":"Anoma.ShieldedResource.ProofRecord.from_noun/1","doc":"","ref":"Anoma.ShieldedResource.ProofRecord.html#from_noun/1"},{"type":"function","title":"Anoma.ShieldedResource.ProofRecord.generate_compliance_proof/1","doc":"","ref":"Anoma.ShieldedResource.ProofRecord.html#generate_compliance_proof/1"},{"type":"type","title":"Anoma.ShieldedResource.ProofRecord.t/0","doc":"","ref":"Anoma.ShieldedResource.ProofRecord.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.ShieldedTransaction","doc":"I am a shielded resource machine transaction.","ref":"Anoma.ShieldedResource.ShieldedTransaction.html"},{"type":"function","title":"Anoma.ShieldedResource.ShieldedTransaction.finalize/1","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#finalize/1"},{"type":"function","title":"Anoma.ShieldedResource.ShieldedTransaction.from_noun/1","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#from_noun/1"},{"type":"function","title":"Anoma.ShieldedResource.ShieldedTransaction.get_binding_messages/1","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#get_binding_messages/1"},{"type":"function","title":"Anoma.ShieldedResource.ShieldedTransaction.get_compliance_outputs/1","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#get_compliance_outputs/1"},{"type":"type","title":"Anoma.ShieldedResource.ShieldedTransaction.t/0","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#t:t/0"},{"type":"module","title":"Anoma.Node","doc":"","ref":"Anoma.Node.html"},{"type":"function","title":"Anoma.Node.start/2","doc":"","ref":"Anoma.Node.html#start/2"},{"type":"module","title":"Anoma.Node.Transport","doc":"","ref":"Anoma.Node.Transport.html"},{"type":"function","title":"Anoma.Node.Transport.create_accepter/2","doc":"","ref":"Anoma.Node.Transport.html#create_accepter/2"},{"type":"function","title":"Anoma.Node.Transport.create_engine_proxy/1","doc":"I create a new proxy engine to talk to remote engines.","ref":"Anoma.Node.Transport.html#create_engine_proxy/1"},{"type":"function","title":"Anoma.Node.Transport.start_tcp_client/1","doc":"I create a new TCP client","ref":"Anoma.Node.Transport.html#start_tcp_client/1"},{"type":"function","title":"Anoma.Node.Transport.start_tcp_server/1","doc":"I create a new TCP listening server under the transport supervisor.","ref":"Anoma.Node.Transport.html#start_tcp_server/1"},{"type":"module","title":"Anoma.Node.Transport.Addressing","doc":"I contain logic to deal with addresses to local and remote engines.","ref":"Anoma.Node.Transport.Addressing.html"},{"type":"function","title":"Anoma.Node.Transport.Addressing.get_address_for/2","doc":"Given an engine id and an engine type I can return the pid to send messages to.","ref":"Anoma.Node.Transport.Addressing.html#get_address_for/2"},{"type":"module","title":"Anoma.Node.Transport.Discovery","doc":"I contain logic to handle the discovery of new nodes on the network.\n\nI am used to register remote nodes locally, and to setup the necessary connections to them.\nI also register proxies locally, and create the necessary inform","ref":"Anoma.Node.Transport.Discovery.html"},{"type":"function","title":"Anoma.Node.Transport.Discovery.inform_node/2","doc":"I inform a remote node about my existence.\n\nGiven a process id of a network connection I send a message that contains\nmy type, a message, and my router id.","ref":"Anoma.Node.Transport.Discovery.html#inform_node/2"},{"type":"function","title":"Anoma.Node.Transport.Discovery.register_as_tcp_for_node/1","doc":"I register the current process as the tcp connection for a given remote router id.\nIf there is already a tcp registered for this remote router id I return that process.","ref":"Anoma.Node.Transport.Discovery.html#register_as_tcp_for_node/1"},{"type":"function","title":"Anoma.Node.Transport.Discovery.remember_node/1","doc":"Given a remote router id, I create a proxy engine for that remote router.\nThis proxy can then be used to send messages to the remote router.\n\nNote: this proxy does not have to know the tcp connection to the remote router.\n      the proxy will lookup the connection in the registry to see if its available.\n      This allows the registry to be the single source of truth for all connections.\n      If the connection is down, the registry will not have this process anymore, and the proxy\n      will not be able to send messages to the remote router.","ref":"Anoma.Node.Transport.Discovery.html#remember_node/1"},{"type":"module","title":"Anoma.Node.Transport.EngineProxy","doc":"I am an engine proxy and I serve as the single point of contact to a remote node.","ref":"Anoma.Node.Transport.EngineProxy.html"},{"type":"function","title":"Anoma.Node.Transport.EngineProxy.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transport.EngineProxy.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.EngineProxy.init/1","doc":"I am the init function for an engine proxy.\nI register this process as a proxy engine in the registry for the given remote node id.","ref":"Anoma.Node.Transport.EngineProxy.html#init/1"},{"type":"function","title":"Anoma.Node.Transport.EngineProxy.start_link/1","doc":"","ref":"Anoma.Node.Transport.EngineProxy.html#start_link/1"},{"type":"type","title":"Anoma.Node.Transport.EngineProxy.t/0","doc":"I am the state of the proxy engine.\n\nMy fields contain information to facilitate the connection with a remote engine.","ref":"Anoma.Node.Transport.EngineProxy.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.EngineProxy.t/0","doc":"- `:remote_id`      - the id of the remote engine.\n  - `:type`          - the type of the connection (e.g., :router, :mempool, ..)\n  - `:message_queue` - A queue of messages for the remote engine.","ref":"Anoma.Node.Transport.EngineProxy.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transport.EngineProxy.AsyncMessage","doc":"","ref":"Anoma.Node.Transport.EngineProxy.AsyncMessage.html"},{"type":"type","title":"Anoma.Node.Transport.EngineProxy.AsyncMessage.t/0","doc":"I contain all data for an asynchronous message send.\n\nMy fields contain information to keep track of the message and to send it to the remote.","ref":"Anoma.Node.Transport.EngineProxy.AsyncMessage.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.EngineProxy.AsyncMessage.t/0","doc":"- `:message`       - The message to send.","ref":"Anoma.Node.Transport.EngineProxy.AsyncMessage.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transport.EngineProxy.SyncMessage","doc":"","ref":"Anoma.Node.Transport.EngineProxy.SyncMessage.html"},{"type":"type","title":"Anoma.Node.Transport.EngineProxy.SyncMessage.t/0","doc":"I contain all data for a synchronous message send.\n\nMy fields contain information to keep track of the message and to send it to the remote.","ref":"Anoma.Node.Transport.EngineProxy.SyncMessage.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.EngineProxy.SyncMessage.t/0","doc":"- `:from`          - The process id of the sender.\n- `:message`       - The message to send.\n- `:timeout`       - The timeout of the message.\n- `:ref`           - The unique reference of the message.\n- `:timestamp`     - The timestamp of the message.","ref":"Anoma.Node.Transport.EngineProxy.SyncMessage.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transport.MessageEncoding","doc":"I contain logic to encode and decode the bytes coming in over a network connection.","ref":"Anoma.Node.Transport.MessageEncoding.html"},{"type":"function","title":"Anoma.Node.Transport.MessageEncoding.decode_bytes/1","doc":"I decode a binary message into a proper term.","ref":"Anoma.Node.Transport.MessageEncoding.html#decode_bytes/1"},{"type":"function","title":"Anoma.Node.Transport.MessageEncoding.encode_message/1","doc":"I encode any term into a binary message for the socket.","ref":"Anoma.Node.Transport.MessageEncoding.html#encode_message/1"},{"type":"module","title":"Anoma.Node.Transport.Router","doc":"I am the router module. I route messages to local and remote engines.","ref":"Anoma.Node.Transport.Router.html"},{"type":"module","title":"Public API - Anoma.Node.Transport.Router","doc":"I provide the following public functionality:\n\n- `start_tcp_server/0`\n- `start_tcp_client/0`","ref":"Anoma.Node.Transport.Router.html#module-public-api"},{"type":"function","title":"Anoma.Node.Transport.Router.async_send/3","doc":"I send an async message to an engine by sending it to its proxy.\nThe proxy will then forward it to via a connection (e.g., TCP).","ref":"Anoma.Node.Transport.Router.html#async_send/3"},{"type":"function","title":"Anoma.Node.Transport.Router.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transport.Router.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.Router.dump_register/0","doc":"I am a helper function to dump the entire register.\nI am used for debugging purposes.","ref":"Anoma.Node.Transport.Router.html#dump_register/0"},{"type":"function","title":"Anoma.Node.Transport.Router.handle_lookup_engine/2","doc":"I lookup the pid of a proxy engine for a given id and type.","ref":"Anoma.Node.Transport.Router.html#handle_lookup_engine/2"},{"type":"function","title":"Examples - Anoma.Node.Transport.Router.handle_lookup_engine/2","doc":"iex> Router.lookup_engine(some_id, :router)\n  {:ok, pid}\n\n  iex> Router.lookup_engine(some_id, :router)\n  {:error, :not_found}","ref":"Anoma.Node.Transport.Router.html#handle_lookup_engine/2-examples"},{"type":"function","title":"Anoma.Node.Transport.Router.handle_start_proxy_engine/2","doc":"I start a new proxy engine for a given router id.","ref":"Anoma.Node.Transport.Router.html#handle_start_proxy_engine/2"},{"type":"function","title":"Anoma.Node.Transport.Router.handle_start_tcp_client/3","doc":"I start a new TCP client process that will connect to a remote TCP server.","ref":"Anoma.Node.Transport.Router.html#handle_start_tcp_client/3"},{"type":"function","title":"Anoma.Node.Transport.Router.handle_start_tcp_server/1","doc":"I start a new TCP server process.\n\nI use the configuration of the router to start the server on the proper port and host.","ref":"Anoma.Node.Transport.Router.html#handle_start_tcp_server/1"},{"type":"function","title":"Anoma.Node.Transport.Router.lookup_engine/2","doc":"Given the id of a node and engine type, I lookup the address of the engine's proxy.","ref":"Anoma.Node.Transport.Router.html#lookup_engine/2"},{"type":"function","title":"Anoma.Node.Transport.Router.start_link/1","doc":"","ref":"Anoma.Node.Transport.Router.html#start_link/1"},{"type":"function","title":"Anoma.Node.Transport.Router.start_proxy_engine/1","doc":"Given the id of an engine, I start a proxy engine for this id.\nThis proxy can be used to route messages to a remote node.","ref":"Anoma.Node.Transport.Router.html#start_proxy_engine/1"},{"type":"function","title":"Anoma.Node.Transport.Router.start_tcp_client/2","doc":"I start a new TCP client to connect to a remote node at the given host and port.","ref":"Anoma.Node.Transport.Router.html#start_tcp_client/2"},{"type":"function","title":"Anoma.Node.Transport.Router.start_tcp_server/0","doc":"I start a new TCP server process.","ref":"Anoma.Node.Transport.Router.html#start_tcp_server/0"},{"type":"function","title":"Anoma.Node.Transport.Router.sync_send/4","doc":"","ref":"Anoma.Node.Transport.Router.html#sync_send/4"},{"type":"type","title":"Anoma.Node.Transport.Router.router_config/0","doc":"I am the type of the configuration to start a router process.","ref":"Anoma.Node.Transport.Router.html#t:router_config/0"},{"type":"type","title":"Anoma.Node.Transport.Router.t/0","doc":"I am the state of the router.\n\nMy fields contain information to communicate with other engines.","ref":"Anoma.Node.Transport.Router.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.Router.t/0","doc":"- `:config` - The configuration parameters of the node.","ref":"Anoma.Node.Transport.Router.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transport.Supervisor","doc":"I am the transport supervisor.\n\nMy main functionality is to supervise the physical transport connections\nin this node (e.g., TCP connections).","ref":"Anoma.Node.Transport.Supervisor.html"},{"type":"module","title":"Registry - Anoma.Node.Transport.Supervisor","doc":"The registry maps process ids to names. For each external node connection\na value is put into the register where the key is the remote key and the\ntype of connection. For example, a TCP connection would be stored as\n`%{remote_id: remote_id, type: :tcp}` and a remote engine proxy is\nstored as `%{remote_id: remote_id, type: :router}`.","ref":"Anoma.Node.Transport.Supervisor.html#module-registry"},{"type":"module","title":"TCP Supervisor - Anoma.Node.Transport.Supervisor","doc":"The TCP supervisor is a dynamic supervisor that supervises TCP connections.","ref":"Anoma.Node.Transport.Supervisor.html#module-tcp-supervisor"},{"type":"module","title":"Proxy Supervisor - Anoma.Node.Transport.Supervisor","doc":"The proxy supervisor is a dynamic supervisor that supervises proxy engine\nprocesses. A proxy engine is a process that acts as a message relay for a\nremote engine.\n\nThe proxy engine can receive messages and knows which physical connection\nshould be used to relay the message to the remote engine.","ref":"Anoma.Node.Transport.Supervisor.html#module-proxy-supervisor"},{"type":"function","title":"Anoma.Node.Transport.Supervisor.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transport.Supervisor.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.Supervisor.start_link/1","doc":"","ref":"Anoma.Node.Transport.Supervisor.html#start_link/1"},{"type":"module","title":"Anoma.Node.Transport.TCPClient","doc":"I am a TCP client. I connect to a remote TCP server and send messages to it.\n\nI decode the incoming data and encode outgoing data.","ref":"Anoma.Node.Transport.TCPClient.html"},{"type":"function","title":"Anoma.Node.Transport.TCPClient.child_spec/1","doc":"I am the child spec for a TCP client.\n\nI ensure that TCP clients are not restarted if they terminate.","ref":"Anoma.Node.Transport.TCPClient.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.TCPClient.init/1","doc":"I am the init function for a TCP client connection.\n\nI expect a host, port, and local router key to initialize the connection.","ref":"Anoma.Node.Transport.TCPClient.html#init/1"},{"type":"function","title":"Anoma.Node.Transport.TCPClient.start_link/1","doc":"","ref":"Anoma.Node.Transport.TCPClient.html#start_link/1"},{"type":"type","title":"Anoma.Node.Transport.TCPClient.t/0","doc":"I am the state of a TCP client.\n\nMy fields contain information to facilitate the TCP connection with a remote node.","ref":"Anoma.Node.Transport.TCPClient.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.TCPClient.t/0","doc":"- `:host`       - The host address of the remote tcp server.\n- `:port`       - The port of the remote tcp server.\n- `:socket`     - The socket of the connection.\n- `:router_key` - The key of this router. This value is used to announce myself to other\n                  nodes.","ref":"Anoma.Node.Transport.TCPClient.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transport.TCPServer","doc":"I am a TCP server. I listen on a given interface and port for incoming connections.\n\nI decode the incoming data and encode outgoing data.","ref":"Anoma.Node.Transport.TCPServer.html"},{"type":"function","title":"Anoma.Node.Transport.TCPServer.child_spec/1","doc":"I am the child spec for a TCP server.\n\nI ensure that TCP server are not restarted if they terminate.","ref":"Anoma.Node.Transport.TCPServer.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.TCPServer.init/1","doc":"I am the init function for a TCP server.\n\nI expect a host, port, and local router key to initialize the connection.\n\nIf I am called for a new TCP server, I start up a socket and start accepting connections.\nIf I am called for an accepted connection, I wait for incoming messages.","ref":"Anoma.Node.Transport.TCPServer.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Transport.TCPServer.init/1","doc":"- `init([host: host, port: port, router_key: router_key])`\n  I initialize a new TCP server with the given host, port and key.\n\n- `init(%TCPServer{})`:\n  I initialize a new TCP connection with the given state.","ref":"Anoma.Node.Transport.TCPServer.html#init/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Transport.TCPServer.start_link/1","doc":"I create a new TCP server based on a host, port and key.","ref":"Anoma.Node.Transport.TCPServer.html#start_link/1"},{"type":"type","title":"Anoma.Node.Transport.TCPServer.t/0","doc":"I am the state of a TCP server.\n\nMy fields contain information to facilitate the TCP connection with a remote node.","ref":"Anoma.Node.Transport.TCPServer.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.TCPServer.t/0","doc":"- `:host`          - The host address of the remote tcp server.\n- `:port`          - The port of the remote tcp server.\n- `:listen_socket` - The socket of the listening server.\n- `:socket`        - The socket of an accepted connection.\n- `:router_key`    - The key of this router. This value is used to announce myself to other\n                     nodes.","ref":"Anoma.Node.Transport.TCPServer.html#t:t/0-fields"},{"type":"module","title":"Examples.ECommitmentTree","doc":"","ref":"Examples.ECommitmentTree.html"},{"type":"function","title":"Examples.ECommitmentTree.babylon_mnesia_ct/1","doc":"","ref":"Examples.ECommitmentTree.html#babylon_mnesia_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.cairo_poseidon_spec/0","doc":"","ref":"Examples.ECommitmentTree.html#cairo_poseidon_spec/0"},{"type":"function","title":"Examples.ECommitmentTree.current_tree_mnesia_ct/1","doc":"This fetches the current mnesia tree storage\n\nThis value is expected to differ, and will be a fixture for other\ntests to assert about.","ref":"Examples.ECommitmentTree.html#current_tree_mnesia_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.empty_mnesia_backed_ct/1","doc":"","ref":"Examples.ECommitmentTree.html#empty_mnesia_backed_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.lots_of_inserts_ct/1","doc":"","ref":"Examples.ECommitmentTree.html#lots_of_inserts_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.memory_backed_ct/1","doc":"","ref":"Examples.ECommitmentTree.html#memory_backed_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.sha256_32_spec/0","doc":"","ref":"Examples.ECommitmentTree.html#sha256_32_spec/0"},{"type":"function","title":"Examples.ECommitmentTree.tree_storage/0","doc":"","ref":"Examples.ECommitmentTree.html#tree_storage/0"},{"type":"module","title":"Examples.ECrypto","doc":"","ref":"Examples.ECrypto.html"},{"type":"function","title":"Examples.ECrypto.alice/0","doc":"","ref":"Examples.ECrypto.html#alice/0"},{"type":"function","title":"Examples.ECrypto.alice_rsa/0","doc":"","ref":"Examples.ECrypto.html#alice_rsa/0"},{"type":"function","title":"Examples.ECrypto.bertha/0","doc":"","ref":"Examples.ECrypto.html#bertha/0"},{"type":"function","title":"Examples.ECrypto.blood_l_signed/0","doc":"","ref":"Examples.ECrypto.html#blood_l_signed/0"},{"type":"function","title":"Examples.ECrypto.blood_l_signed_detached/0","doc":"","ref":"Examples.ECrypto.html#blood_l_signed_detached/0"},{"type":"function","title":"Examples.ECrypto.blood_msg/0","doc":"","ref":"Examples.ECrypto.html#blood_msg/0"},{"type":"function","title":"Examples.ECrypto.bob_rsa/0","doc":"","ref":"Examples.ECrypto.html#bob_rsa/0"},{"type":"function","title":"Examples.ECrypto.eve/0","doc":"","ref":"Examples.ECrypto.html#eve/0"},{"type":"function","title":"Examples.ECrypto.londo/0","doc":"","ref":"Examples.ECrypto.html#londo/0"},{"type":"function","title":"Examples.ECrypto.xcc/0","doc":"","ref":"Examples.ECrypto.html#xcc/0"},{"type":"module","title":"Examples.ENock","doc":"","ref":"Examples.ENock.html"},{"type":"function","title":"Examples.ENock.bex/0","doc":"","ref":"Examples.ENock.html#bex/0"},{"type":"function","title":"Examples.ENock.bex_arm/0","doc":"The bex arm for taking bex:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localbex   =>  logics  |=  a=@  (bex a)\n\nand then grabbing the arm of localbex.","ref":"Examples.ENock.html#bex_arm/0"},{"type":"function","title":"Examples.ENock.counter_arm/0","doc":"The counter arm.\n\nAvailiable through `counter:logics` core.","ref":"Examples.ENock.html#counter_arm/0"},{"type":"function","title":"Examples.ENock.counter_logic/0","doc":"","ref":"Examples.ENock.html#counter_logic/0"},{"type":"function","title":"Examples.ENock.cue/0","doc":"","ref":"Examples.ENock.html#cue/0"},{"type":"function","title":"Examples.ENock.cue_arm/0","doc":"A cue arm for taking cue:anoma out of the logics core environment.\n\nCan be gotten by defining gate locally as\n\n=localcue   =>  logics  |=  a=@  (cue a)\n\nand then grabbing the arm of localcue.","ref":"Examples.ENock.html#cue_arm/0"},{"type":"function","title":"Examples.ENock.dec/0","doc":"","ref":"Examples.ENock.html#dec/0"},{"type":"function","title":"Examples.ENock.dec_arm/0","doc":"The decrement arm in the tests core.\n\nAvailiable through `use-dec:tests` core.","ref":"Examples.ENock.html#dec_arm/0"},{"type":"function","title":"Examples.ENock.factorial/0","doc":"","ref":"Examples.ENock.html#factorial/0"},{"type":"function","title":"Examples.ENock.factorial_arm/0","doc":"I am the battery of the fib:tests gate of the anoma stadard library.\n\nYou can dump me by calling\n\n.*  fib:tests  [0 2]","ref":"Examples.ENock.html#factorial_arm/0"},{"type":"function","title":"Examples.ENock.incorrectly_ending/0","doc":"","ref":"Examples.ENock.html#incorrectly_ending/0"},{"type":"function","title":"Examples.ENock.incorrectly_nested_noun/0","doc":"","ref":"Examples.ENock.html#incorrectly_nested_noun/0"},{"type":"function","title":"Examples.ENock.incorrectly_starting/0","doc":"","ref":"Examples.ENock.html#incorrectly_starting/0"},{"type":"function","title":"Examples.ENock.increment_counter_val/1","doc":"","ref":"Examples.ENock.html#increment_counter_val/1"},{"type":"function","title":"Examples.ENock.indexed_noun/0","doc":"","ref":"Examples.ENock.html#indexed_noun/0"},{"type":"function","title":"Examples.ENock.jam/0","doc":"","ref":"Examples.ENock.html#jam/0"},{"type":"function","title":"Examples.ENock.jam_and_cue/2","doc":"","ref":"Examples.ENock.html#jam_and_cue/2"},{"type":"function","title":"Examples.ENock.jam_arm/0","doc":"A cue arm for taking jam:anoma out of the logics core environment.\n\nCan be gotten by defining gate locally as\n\n=localjam   =>  logics  |=  a=@  (jam a)\n\nand then grabbing the arm of localjam.","ref":"Examples.ENock.html#jam_arm/0"},{"type":"function","title":"Examples.ENock.jamming_and_cueing/0","doc":"","ref":"Examples.ENock.html#jamming_and_cueing/0"},{"type":"function","title":"Examples.ENock.lsh0/0","doc":"I evaluate lsh at block size 0 and gate-input [2 6].\n\nlsh(0) evaluates the gate of the block door at block size 0,\n[6 1 2 6] replaces the sample with [2 6].","ref":"Examples.ENock.html#lsh0/0"},{"type":"function","title":"Examples.ENock.lsh1/0","doc":"I evaluate lsh at block size 1 and gate-input [2 6].\n\nlsh(1) evaluates the gate of the block door at block size 1,\n[6 1 2 6] replaces the sample with [2 6].","ref":"Examples.ENock.html#lsh1/0"},{"type":"function","title":"Examples.ENock.lsh2/0","doc":"I evaluate lsh at block size 1 and gate-input [2 6].\n\nlsh(2) evaluates the gate of the block door at block size 2,\n[6 1 2 6] replaces the sample with [2 6].","ref":"Examples.ENock.html#lsh2/0"},{"type":"function","title":"Examples.ENock.lsh/1","doc":"I am an lash arm in the block door.\n\nMy index inside the door can be seen by asking to dump the logic of\n=llsh   =>  logics  |=  a=@  lsh:block","ref":"Examples.ENock.html#lsh/1"},{"type":"function","title":"Examples.ENock.mat/0","doc":"","ref":"Examples.ENock.html#mat/0"},{"type":"function","title":"Examples.ENock.mat_arm/0","doc":"The mat arm for taking mat:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localmat   =>  logics  |=  a  (mat a)\n\nand then grabbing the arm of locamix.","ref":"Examples.ENock.html#mat_arm/0"},{"type":"function","title":"Examples.ENock.met0/0","doc":"I evaluate met at block size 0 and gate-input 28.\n\nmet(0) evaluates the gate of the block door at block size 0,\n[6 1 28] replaces the sample with 28.","ref":"Examples.ENock.html#met0/0"},{"type":"function","title":"Examples.ENock.met1/0","doc":"I evaluate met at block size 1 and gate-input 28.\n\nmet(1) evaluates the gate of the block door at block size 1,\n[6 1 28] replaces the sample with 28.","ref":"Examples.ENock.html#met1/0"},{"type":"function","title":"Examples.ENock.met2/0","doc":"I evaluate met at block size 2 and gate-input 28.\n\nmet(2) evaluates the gate of the block door at block size 2,\n[6 1 28] replaces the sample with 28.","ref":"Examples.ENock.html#met2/0"},{"type":"function","title":"Examples.ENock.met/1","doc":"I am an lash arm in the block door.\n\nMy index inside the door can be seen by asking to dump the logic of\n=lmet   =>  logics  |=  a=@  met:block","ref":"Examples.ENock.html#met/1"},{"type":"function","title":"Examples.ENock.mix/0","doc":"","ref":"Examples.ENock.html#mix/0"},{"type":"function","title":"Examples.ENock.mix_arm/0","doc":"The mix arm for taking mix:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localmix   =>  logics  |=  [a=@ b=@]  (mix [a b])\n\nand then grabbing the arm of locamix.","ref":"Examples.ENock.html#mix_arm/0"},{"type":"function","title":"Examples.ENock.nesting_noun/0","doc":"","ref":"Examples.ENock.html#nesting_noun/0"},{"type":"function","title":"Examples.ENock.one_two/0","doc":"","ref":"Examples.ENock.html#one_two/0"},{"type":"function","title":"Examples.ENock.raw_27_4/0","doc":"","ref":"Examples.ENock.html#raw_27_4/0"},{"type":"function","title":"Examples.ENock.raw_arm/0","doc":"I represent the raw gate call as a 2-argument gate.\n\nCan be gotten by defining\n\n=lraw   =>  logics  |=   [a=@ b=@]  (~(raw og a) b)","ref":"Examples.ENock.html#raw_arm/0"},{"type":"function","title":"Examples.ENock.raw_call/2","doc":"I am function calling the raw gate of the og door with specified\nseed and bitwidth.","ref":"Examples.ENock.html#raw_call/2"},{"type":"function","title":"Examples.ENock.replacing_terms/0","doc":"","ref":"Examples.ENock.html#replacing_terms/0"},{"type":"function","title":"Examples.ENock.rsh0/0","doc":"I evaluate rsh at block size 0 and gate-input [2 40].\n\nrsh(0) evaluates the gate of the block door at block size 0,\n[6 1 2 40] replaces the sample with [2 40].","ref":"Examples.ENock.html#rsh0/0"},{"type":"function","title":"Examples.ENock.rsh1/0","doc":"I evaluate rsh at block size 1 and gate-input [2 40].\n\nrsh(1) evaluates the gate of the block door at block size 1,\n[6 1 2 40] replaces the sample with [2 40].","ref":"Examples.ENock.html#rsh1/0"},{"type":"function","title":"Examples.ENock.rsh2/0","doc":"I evaluate rsh at block size 2 and gate-input [2 40].\n\nrsh(2) evaluates the gate of the block door at block size 2,\n[6 1 1 40] replaces the sample with [1 40].","ref":"Examples.ENock.html#rsh2/0"},{"type":"function","title":"Examples.ENock.rsh/1","doc":"I am an lash arm in the block door.\n\nMy index inside the door can be seen by asking to dump the logic of\n=rsh   =>  logics  |=  a=@  rsh:block","ref":"Examples.ENock.html#rsh/1"},{"type":"function","title":"Examples.ENock.shax/0","doc":"","ref":"Examples.ENock.html#shax/0"},{"type":"function","title":"Examples.ENock.shax_arm/0","doc":"The shax arm for taking shax:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localshax   =>  logics  |=  a=@  (shax a)\n\nand then grabbing the arm of localshax.","ref":"Examples.ENock.html#shax_arm/0"},{"type":"function","title":"Examples.ENock.sign/0","doc":"","ref":"Examples.ENock.html#sign/0"},{"type":"function","title":"Examples.ENock.sign_arm/0","doc":"The sign arm for taking sign:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localsign   =>  logics  |=  [a=@ b=@]  (sign [a b])\n\nand then grabbing the arm of localsign.","ref":"Examples.ENock.html#sign_arm/0"},{"type":"function","title":"Examples.ENock.sign_detatched/0","doc":"","ref":"Examples.ENock.html#sign_detatched/0"},{"type":"function","title":"Examples.ENock.sign_detatched_arm/0","doc":"The sign-detatched arm for taking sign-detached:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localsigndetached   =>  logics  |=  [a=@ b=@]  (sign-detached [a b])\n\nand then grabbing the arm of localsighdetached.","ref":"Examples.ENock.html#sign_detatched_arm/0"},{"type":"function","title":"Examples.ENock.uend0/0","doc":"I evaluate uend at block size 0 and gate-input [5 80].\n\nuend(0) evaluates the gate of the block door at block size 0,\n[6 1 5 80] replaces the sample with [5 80].","ref":"Examples.ENock.html#uend0/0"},{"type":"function","title":"Examples.ENock.uend1/0","doc":"I evaluate uend at block size 1 and gate-input [3 80] and [4 80].\n\nuend(1) evaluates the gate of the block door at block size 1,\n[6 1 3 80] replaces the sample with [3 80],\n[6 1 4 80] replaces the sample with [3 80]","ref":"Examples.ENock.html#uend1/0"},{"type":"function","title":"Examples.ENock.uend/1","doc":"I am an lash arm in the block door.\n\nMy index inside the door can be seen by asking to dump the logic of\n=luend   =>  logics  |=  a=@  luend:block","ref":"Examples.ENock.html#uend/1"},{"type":"function","title":"Examples.ENock.verify/0","doc":"","ref":"Examples.ENock.html#verify/0"},{"type":"function","title":"Examples.ENock.verify_arm/0","doc":"The verify arm for taking verify:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localverify   =>  logics  |=  [a=@ b=@]  (verify [a b])\n\nand then grabbing the arm of localverify.","ref":"Examples.ENock.html#verify_arm/0"},{"type":"function","title":"Examples.ENock.verify_detatched/0","doc":"","ref":"Examples.ENock.html#verify_detatched/0"},{"type":"function","title":"Examples.ENock.verify_detatched_arm/0","doc":"The verify-detatched arm for taking verify-detached:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localverifydetached   =>  logics  |=  [a=@ b=@ c=@]  (verify-detached [a b])\n\nand then grabbing the arm of localverifydetached.","ref":"Examples.ENock.html#verify_detatched_arm/0"},{"type":"function","title":"Examples.ENock.zero_counter/1","doc":"","ref":"Examples.ENock.html#zero_counter/1"},{"type":"function","title":"Examples.ENock.zero_delta_logic/0","doc":"","ref":"Examples.ENock.html#zero_delta_logic/0"},{"type":"module","title":"Anoma.Crypto.Encrypt","doc":"","ref":"Anoma.Crypto.Encrypt.html"},{"type":"function","title":"Anoma.Crypto.Encrypt.new_keypair/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Encrypt.seal/2","doc":"I seal the given message for the publicly known recipient.\n\nThe message will be turned into binary via :erlang.term_to_binary,\nso please do not turn it to binary before hand.","ref":"Anoma.Crypto.Encrypt.html#seal/2"},{"type":"function","title":"Anoma.Crypto.Encrypt.unseal/3","doc":"","ref":"Anoma.Crypto.Encrypt.html#unseal/3"},{"type":"type","title":"Anoma.Crypto.Encrypt.box_public/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:box_public/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.box_secret/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:box_secret/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.public/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:public/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.secret/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:secret/0"},{"type":"module","title":"Anoma.Crypto.Id","doc":"I represent the Identity","ref":"Anoma.Crypto.Id.html"},{"type":"function","title":"Anoma.Crypto.Id.external_id/1","doc":"Grabs the external id of a given key\n\nUseful when we want to use id and the external as interchangeable","ref":"Anoma.Crypto.Id.html#external_id/1"},{"type":"function","title":"Anoma.Crypto.Id.new_keypair/0","doc":"","ref":"Anoma.Crypto.Id.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Id.salt_keys/2","doc":"I salt the given keys for further storage. Or for storage\nlookup\n\nI can be used on `t\u0000`, `Intern.t\u0000` or `Extern.t\u0000`.\n\n- `t\u0000` is useful for salting for storage\n- `Extern.t\u0000` is useful for looking up keys for storage\n- `Intern.t\u0000` is useful in case one wants to see the salted key","ref":"Anoma.Crypto.Id.html#salt_keys/2"},{"type":"function","title":"Anoma.Crypto.Id.seal/2","doc":"","ref":"Anoma.Crypto.Id.html#seal/2"},{"type":"function","title":"Anoma.Crypto.Id.truncated_key_string/1","doc":"","ref":"Anoma.Crypto.Id.html#truncated_key_string/1"},{"type":"function","title":"Anoma.Crypto.Id.unsalt_keys/2","doc":"I unsalt the given keys for use after looking up from storage\n\nI can be used on `t\u0000`, `Intern.t\u0000` or `Extern.t\u0000`.\n\n- `t\u0000` is useful for unsalting from Storage\n- `Extern.t\u0000` is useful for external keys which are salted\n- `Intern.t\u0000` is useful in case when one wants to unsalt their private keys","ref":"Anoma.Crypto.Id.html#unsalt_keys/2"},{"type":"function","title":"Anoma.Crypto.Id.verify/2","doc":"","ref":"Anoma.Crypto.Id.html#verify/2"},{"type":"type","title":"Anoma.Crypto.Id.identities/0","doc":"","ref":"Anoma.Crypto.Id.html#t:identities/0"},{"type":"type","title":"Anoma.Crypto.Id.t/0","doc":"","ref":"Anoma.Crypto.Id.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Id.Extern","doc":"","ref":"Anoma.Crypto.Id.Extern.html"},{"type":"type","title":"Anoma.Crypto.Id.Extern.t/0","doc":"","ref":"Anoma.Crypto.Id.Extern.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Id.Intern","doc":"","ref":"Anoma.Crypto.Id.Intern.html"},{"type":"type","title":"Anoma.Crypto.Id.Intern.t/0","doc":"","ref":"Anoma.Crypto.Id.Intern.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Randomness","doc":"I am an implementation of the Local Randomness Engine","ref":"Anoma.Crypto.Randomness.html"},{"type":"function","title":"Anoma.Crypto.Randomness.get_random/1","doc":"Given a non-negative integer N, I provide a random bit of size N","ref":"Anoma.Crypto.Randomness.html#get_random/1"},{"type":"module","title":"Anoma.Crypto.Sign","doc":"","ref":"Anoma.Crypto.Sign.html"},{"type":"function","title":"Anoma.Crypto.Sign.new_keypair/0","doc":"","ref":"Anoma.Crypto.Sign.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Sign.sign/2","doc":"","ref":"Anoma.Crypto.Sign.html#sign/2"},{"type":"function","title":"Anoma.Crypto.Sign.sign_detached/2","doc":"","ref":"Anoma.Crypto.Sign.html#sign_detached/2"},{"type":"function","title":"Anoma.Crypto.Sign.verify/2","doc":"","ref":"Anoma.Crypto.Sign.html#verify/2"},{"type":"function","title":"Anoma.Crypto.Sign.verify_detached/3","doc":"","ref":"Anoma.Crypto.Sign.html#verify_detached/3"},{"type":"type","title":"Anoma.Crypto.Sign.ed25519_public/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:ed25519_public/0"},{"type":"type","title":"Anoma.Crypto.Sign.ed25519_secret/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:ed25519_secret/0"},{"type":"type","title":"Anoma.Crypto.Sign.public/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:public/0"},{"type":"type","title":"Anoma.Crypto.Sign.secret/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:secret/0"},{"type":"module","title":"Anoma.Crypto.Symmetric","doc":"","ref":"Anoma.Crypto.Symmetric.html"},{"type":"function","title":"Anoma.Crypto.Symmetric.decrypt/2","doc":"","ref":"Anoma.Crypto.Symmetric.html#decrypt/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.decrypt_raw/2","doc":"","ref":"Anoma.Crypto.Symmetric.html#decrypt_raw/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.encrypt/2","doc":"I encrypt data given any known schema and a message.\n\nThe message will be turned into binary via :erlang.term_to_binary,\nso please do not turn it to binary before hand.","ref":"Anoma.Crypto.Symmetric.html#encrypt/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.encrypt_raw/2","doc":"I encrypt data given any known schema and a message.\n\nI am raw in that I do not serialize the data, Only use me if you\nknow what you are doing.","ref":"Anoma.Crypto.Symmetric.html#encrypt_raw/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha/0"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha_key/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha_key/0"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha_nonce/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha_nonce/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.t/0","doc":"I represent the symmetric types available to the system","ref":"Anoma.Crypto.Symmetric.html#t:t/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha_key/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha_key/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha_nonce/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha_nonce/0"},{"type":"module","title":"Anoma.Node.DummyStorage","doc":"I am dummy storage during the defactor, to avoid undue stress on shielded rm.","ref":"Anoma.Node.DummyStorage.html"},{"type":"function","title":"Anoma.Node.DummyStorage.get/2","doc":"","ref":"Anoma.Node.DummyStorage.html#get/2"},{"type":"module","title":"Anoma.Node.Examples.EConsensus","doc":"","ref":"Anoma.Node.Examples.EConsensus.html"},{"type":"function","title":"Anoma.Node.Examples.EConsensus.execution_continues/0","doc":"","ref":"Anoma.Node.Examples.EConsensus.html#execution_continues/0"},{"type":"function","title":"Anoma.Node.Examples.EConsensus.restart_consensus/0","doc":"","ref":"Anoma.Node.Examples.EConsensus.html#restart_consensus/0"},{"type":"function","title":"Anoma.Node.Examples.EConsensus.restart_consensus_env/0","doc":"","ref":"Anoma.Node.Examples.EConsensus.html#restart_consensus_env/0"},{"type":"function","title":"Anoma.Node.Examples.EConsensus.startup_execution/0","doc":"","ref":"Anoma.Node.Examples.EConsensus.html#startup_execution/0"},{"type":"module","title":"Anoma.Node.Examples.ELogging","doc":"","ref":"Anoma.Node.Examples.ELogging.html"},{"type":"function","title":"Anoma.Node.Examples.ELogging.block_event/2","doc":"","ref":"Anoma.Node.Examples.ELogging.html#block_event/2"},{"type":"function","title":"Anoma.Node.Examples.ELogging.check_block_event/0","doc":"","ref":"Anoma.Node.Examples.ELogging.html#check_block_event/0"},{"type":"function","title":"Anoma.Node.Examples.ELogging.check_block_event_leave_one_out/0","doc":"","ref":"Anoma.Node.Examples.ELogging.html#check_block_event_leave_one_out/0"},{"type":"function","title":"Anoma.Node.Examples.ELogging.check_block_event_multiple/0","doc":"","ref":"Anoma.Node.Examples.ELogging.html#check_block_event_multiple/0"},{"type":"function","title":"Anoma.Node.Examples.ELogging.check_consensus_event/0","doc":"","ref":"Anoma.Node.Examples.ELogging.html#check_consensus_event/0"},{"type":"function","title":"Anoma.Node.Examples.ELogging.check_consensus_event_multiple/0","doc":"","ref":"Anoma.Node.Examples.ELogging.html#check_consensus_event_multiple/0"},{"type":"function","title":"Anoma.Node.Examples.ELogging.check_multiple_tx_events/0","doc":"","ref":"Anoma.Node.Examples.ELogging.html#check_multiple_tx_events/0"},{"type":"function","title":"Anoma.Node.Examples.ELogging.check_tx_event/0","doc":"","ref":"Anoma.Node.Examples.ELogging.html#check_tx_event/0"},{"type":"function","title":"Anoma.Node.Examples.ELogging.consensus_event/1","doc":"","ref":"Anoma.Node.Examples.ELogging.html#consensus_event/1"},{"type":"function","title":"Anoma.Node.Examples.ELogging.restart_logging/0","doc":"","ref":"Anoma.Node.Examples.ELogging.html#restart_logging/0"},{"type":"function","title":"Anoma.Node.Examples.ELogging.tx_event/3","doc":"","ref":"Anoma.Node.Examples.ELogging.html#tx_event/3"},{"type":"module","title":"Anoma.Node.Examples.ETransaction","doc":"","ref":"Anoma.Node.Examples.ETransaction.html"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.append_then_read/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#append_then_read/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.append_then_read_same/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#append_then_read_same/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.append_then_read_several/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#append_then_read_several/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.append_twice_then_read/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#append_twice_then_read/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.append_twice_then_read_with_commit/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#append_twice_then_read_with_commit/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.bluf/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#bluf/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.bluf_transaction_errors/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#bluf_transaction_errors/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.bluff_txs_write_nothing/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#bluff_txs_write_nothing/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.complicated_storage/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#complicated_storage/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.complicated_storage_with_commit/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#complicated_storage_with_commit/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.inc/1","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#inc/1"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.inc_counter_submit_after_read/1","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#inc_counter_submit_after_read/1"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.inc_counter_submit_after_zero/1","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#inc_counter_submit_after_zero/1"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.inc_counter_submit_with_zero/1","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#inc_counter_submit_with_zero/1"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.mempool_startup_consensus/1","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#mempool_startup_consensus/1"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.mempool_startup_txs/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#mempool_startup_txs/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.ord_order_first/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#ord_order_first/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.ord_read_future_then_write/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#ord_read_future_then_write/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.ord_write_then_read/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#ord_write_then_read/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.read_future_then_write/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#read_future_then_write/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.read_other_future_then_write/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#read_other_future_then_write/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.read_txs_write_nothing/1","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#read_txs_write_nothing/1"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.restart_executor/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#restart_executor/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.restart_mempool/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#restart_mempool/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.restart_ordering/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#restart_ordering/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.restart_storage/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#restart_storage/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.restart_tx_module/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#restart_tx_module/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.write_future_multiple_then_write_present/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#write_future_multiple_then_write_present/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.write_future_then_write_present/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#write_future_then_write_present/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.write_multiple_then_read/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#write_multiple_then_read/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.write_then_read/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#write_then_read/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.write_then_read_other/0","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#write_then_read_other/0"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.zero/1","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#zero/1"},{"type":"function","title":"Anoma.Node.Examples.ETransaction.zero_counter_submit/1","doc":"","ref":"Anoma.Node.Examples.ETransaction.html#zero_counter_submit/1"},{"type":"module","title":"Anoma.Node.Examples.ETransport","doc":"","ref":"Anoma.Node.Examples.ETransport.html"},{"type":"module","title":"Anoma.Node.Examples.ETransport.ETcp","doc":"","ref":"Anoma.Node.Examples.ETransport.ETcp.html"},{"type":"function","title":"Anoma.Node.Examples.ETransport.ETcp.test_tcp_server_1/0","doc":"","ref":"Anoma.Node.Examples.ETransport.ETcp.html#test_tcp_server_1/0"},{"type":"function","title":"Anoma.Node.Examples.ETransport.ETcp.test_tcp_server_2/0","doc":"","ref":"Anoma.Node.Examples.ETransport.ETcp.html#test_tcp_server_2/0"},{"type":"module","title":"Anoma.Node.Logging","doc":"Replay manager with logger functionality","ref":"Anoma.Node.Logging.html"},{"type":"function","title":"Anoma.Node.Logging.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Logging.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Logging.init/1","doc":"","ref":"Anoma.Node.Logging.html#init/1"},{"type":"function","title":"Anoma.Node.Logging.logging_filter/0","doc":"","ref":"Anoma.Node.Logging.html#logging_filter/0"},{"type":"function","title":"Anoma.Node.Logging.replay/4","doc":"","ref":"Anoma.Node.Logging.html#replay/4"},{"type":"function","title":"Anoma.Node.Logging.start_link/1","doc":"","ref":"Anoma.Node.Logging.html#start_link/1"},{"type":"type","title":"Anoma.Node.Logging.flag/0","doc":"","ref":"Anoma.Node.Logging.html#t:flag/0"},{"type":"type","title":"Anoma.Node.Logging.t/0","doc":"","ref":"Anoma.Node.Logging.html#t:t/0"},{"type":"module","title":"Anoma.Node.Logging.LoggingEvent","doc":"","ref":"Anoma.Node.Logging.LoggingEvent.html"},{"type":"type","title":"Anoma.Node.Logging.LoggingEvent.t/0","doc":"","ref":"Anoma.Node.Logging.LoggingEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Logging.LoggingFilter","doc":"I am a filter for the logging engine.\n\nThis includes both logs and events.","ref":"Anoma.Node.Logging.LoggingFilter.html"},{"type":"function","title":"Anoma.Node.Logging.LoggingFilter.filter/2","doc":"","ref":"Anoma.Node.Logging.LoggingFilter.html#filter/2"},{"type":"type","title":"Anoma.Node.Logging.LoggingFilter.t/0","doc":"","ref":"Anoma.Node.Logging.LoggingFilter.html#t:t/0"},{"type":"module","title":"Anoma.Node.Supervisor","doc":"I am the top level supervisor for the Anoma node.","ref":"Anoma.Node.Supervisor.html"},{"type":"function","title":"Anoma.Node.Supervisor.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Supervisor.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Supervisor.init/1","doc":"","ref":"Anoma.Node.Supervisor.html#init/1"},{"type":"function","title":"Anoma.Node.Supervisor.start_link/1","doc":"","ref":"Anoma.Node.Supervisor.html#start_link/1"},{"type":"module","title":"Anoma.Node.Transaction.Backends","doc":"Backend module.\nSupport :kv, :ro, :rm, :cairo execution.","ref":"Anoma.Node.Transaction.Backends.html"},{"type":"function","title":"Anoma.Node.Transaction.Backends.blob_store/2","doc":"","ref":"Anoma.Node.Transaction.Backends.html#blob_store/2"},{"type":"function","title":"Anoma.Node.Transaction.Backends.execute/2","doc":"","ref":"Anoma.Node.Transaction.Backends.html#execute/2"},{"type":"function","title":"Anoma.Node.Transaction.Backends.store_value/2","doc":"","ref":"Anoma.Node.Transaction.Backends.html#store_value/2"},{"type":"type","title":"Anoma.Node.Transaction.Backends.backend/0","doc":"","ref":"Anoma.Node.Transaction.Backends.html#t:backend/0"},{"type":"type","title":"Anoma.Node.Transaction.Backends.transaction/0","doc":"","ref":"Anoma.Node.Transaction.Backends.html#t:transaction/0"},{"type":"module","title":"Anoma.Node.Transaction.Backends.CompleteEvent","doc":"","ref":"Anoma.Node.Transaction.Backends.CompleteEvent.html"},{"type":"type","title":"Anoma.Node.Transaction.Backends.CompleteEvent.t/0","doc":"","ref":"Anoma.Node.Transaction.Backends.CompleteEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Backends.CompleteFilter","doc":"I am a filter for backend result messages.","ref":"Anoma.Node.Transaction.Backends.CompleteFilter.html"},{"type":"function","title":"Anoma.Node.Transaction.Backends.CompleteFilter.filter/2","doc":"","ref":"Anoma.Node.Transaction.Backends.CompleteFilter.html#filter/2"},{"type":"type","title":"Anoma.Node.Transaction.Backends.CompleteFilter.t/0","doc":"","ref":"Anoma.Node.Transaction.Backends.CompleteFilter.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Backends.ForMempoolFilter","doc":"Important messages for mempool.","ref":"Anoma.Node.Transaction.Backends.ForMempoolFilter.html"},{"type":"function","title":"Anoma.Node.Transaction.Backends.ForMempoolFilter.filter/2","doc":"","ref":"Anoma.Node.Transaction.Backends.ForMempoolFilter.html#filter/2"},{"type":"type","title":"Anoma.Node.Transaction.Backends.ForMempoolFilter.t/0","doc":"","ref":"Anoma.Node.Transaction.Backends.ForMempoolFilter.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Backends.ResultEvent","doc":"","ref":"Anoma.Node.Transaction.Backends.ResultEvent.html"},{"type":"type","title":"Anoma.Node.Transaction.Backends.ResultEvent.t/0","doc":"","ref":"Anoma.Node.Transaction.Backends.ResultEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Executor","doc":"","ref":"Anoma.Node.Transaction.Executor.html"},{"type":"function","title":"Anoma.Node.Transaction.Executor.complete_filter/0","doc":"","ref":"Anoma.Node.Transaction.Executor.html#complete_filter/0"},{"type":"function","title":"Anoma.Node.Transaction.Executor.execute/1","doc":"","ref":"Anoma.Node.Transaction.Executor.html#execute/1"},{"type":"function","title":"Anoma.Node.Transaction.Executor.execution_event/1","doc":"","ref":"Anoma.Node.Transaction.Executor.html#execution_event/1"},{"type":"function","title":"Anoma.Node.Transaction.Executor.handle_cast/2","doc":"","ref":"Anoma.Node.Transaction.Executor.html#handle_cast/2"},{"type":"function","title":"Anoma.Node.Transaction.Executor.init/1","doc":"","ref":"Anoma.Node.Transaction.Executor.html#init/1"},{"type":"function","title":"Anoma.Node.Transaction.Executor.launch/2","doc":"","ref":"Anoma.Node.Transaction.Executor.html#launch/2"},{"type":"function","title":"Anoma.Node.Transaction.Executor.start_link/1","doc":"","ref":"Anoma.Node.Transaction.Executor.html#start_link/1"},{"type":"type","title":"Anoma.Node.Transaction.Executor.t/0","doc":"","ref":"Anoma.Node.Transaction.Executor.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Executor.ExecutionEvent","doc":"","ref":"Anoma.Node.Transaction.Executor.ExecutionEvent.html"},{"type":"type","title":"Anoma.Node.Transaction.Executor.ExecutionEvent.t/0","doc":"","ref":"Anoma.Node.Transaction.Executor.ExecutionEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Mempool","doc":"","ref":"Anoma.Node.Transaction.Mempool.html"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.block_event/2","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#block_event/2"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transaction.Mempool.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.consensus_event/1","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#consensus_event/1"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.execute/1","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#execute/1"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.filter_for_mempool/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#filter_for_mempool/0"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.init/1","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#init/1"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.start_link/1","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#start_link/1"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.tx/1","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#tx/1"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.tx/2","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#tx/2"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.tx_dump/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#tx_dump/0"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.tx_event/2","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#tx_event/2"},{"type":"function","title":"Anoma.Node.Transaction.Mempool.worker_module_filter/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#worker_module_filter/0"},{"type":"type","title":"Anoma.Node.Transaction.Mempool.t/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#t:t/0"},{"type":"type","title":"Anoma.Node.Transaction.Mempool.tx_result/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#t:tx_result/0"},{"type":"type","title":"Anoma.Node.Transaction.Mempool.vm_result/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.html#t:vm_result/0"},{"type":"module","title":"Anoma.Node.Transaction.Mempool.BlockEvent","doc":"","ref":"Anoma.Node.Transaction.Mempool.BlockEvent.html"},{"type":"type","title":"Anoma.Node.Transaction.Mempool.BlockEvent.t/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.BlockEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Mempool.ConsensusEvent","doc":"","ref":"Anoma.Node.Transaction.Mempool.ConsensusEvent.html"},{"type":"type","title":"Anoma.Node.Transaction.Mempool.ConsensusEvent.t/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.ConsensusEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Mempool.Tx","doc":"","ref":"Anoma.Node.Transaction.Mempool.Tx.html"},{"type":"type","title":"Anoma.Node.Transaction.Mempool.Tx.t/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.Tx.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Mempool.TxEvent","doc":"","ref":"Anoma.Node.Transaction.Mempool.TxEvent.html"},{"type":"type","title":"Anoma.Node.Transaction.Mempool.TxEvent.t/0","doc":"","ref":"Anoma.Node.Transaction.Mempool.TxEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Ordering","doc":"abordering genserver","ref":"Anoma.Node.Transaction.Ordering.html"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.append/1","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#append/1"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.block/3","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#block/3"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.block_spawn/2","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#block_spawn/2"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.blocking_read/2","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#blocking_read/2"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.blocking_write/2","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#blocking_write/2"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transaction.Ordering.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.init/1","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#init/1"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.order/1","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#order/1"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.read/1","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#read/1"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.start_link/1","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#start_link/1"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.this_module_filter/0","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#this_module_filter/0"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.tx_id_filter/1","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#tx_id_filter/1"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.write/1","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#write/1"},{"type":"type","title":"Anoma.Node.Transaction.Ordering.t/0","doc":"","ref":"Anoma.Node.Transaction.Ordering.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Ordering.OrderEvent","doc":"","ref":"Anoma.Node.Transaction.Ordering.OrderEvent.html"},{"type":"type","title":"Anoma.Node.Transaction.Ordering.OrderEvent.t/0","doc":"","ref":"Anoma.Node.Transaction.Ordering.OrderEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Ordering.TxIdFilter","doc":"I am a filter for matching ordered transaction ids.","ref":"Anoma.Node.Transaction.Ordering.TxIdFilter.html"},{"type":"function","title":"Anoma.Node.Transaction.Ordering.TxIdFilter.filter/2","doc":"","ref":"Anoma.Node.Transaction.Ordering.TxIdFilter.html#filter/2"},{"type":"type","title":"Anoma.Node.Transaction.Ordering.TxIdFilter.t/0","doc":"I store a value for filtering.","ref":"Anoma.Node.Transaction.Ordering.TxIdFilter.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transaction.Ordering.TxIdFilter.t/0","doc":"- `:id` - A binary","ref":"Anoma.Node.Transaction.Ordering.TxIdFilter.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transaction.Storage","doc":"abstorage genserver","ref":"Anoma.Node.Transaction.Storage.html"},{"type":"function","title":"Anoma.Node.Transaction.Storage.abwrite/3","doc":"","ref":"Anoma.Node.Transaction.Storage.html#abwrite/3"},{"type":"function","title":"Anoma.Node.Transaction.Storage.append/1","doc":"","ref":"Anoma.Node.Transaction.Storage.html#append/1"},{"type":"function","title":"Anoma.Node.Transaction.Storage.block_spawn/2","doc":"","ref":"Anoma.Node.Transaction.Storage.html#block_spawn/2"},{"type":"function","title":"Anoma.Node.Transaction.Storage.blocking_write/3","doc":"","ref":"Anoma.Node.Transaction.Storage.html#blocking_write/3"},{"type":"function","title":"Anoma.Node.Transaction.Storage.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transaction.Storage.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transaction.Storage.commit/2","doc":"","ref":"Anoma.Node.Transaction.Storage.html#commit/2"},{"type":"function","title":"Anoma.Node.Transaction.Storage.init/1","doc":"","ref":"Anoma.Node.Transaction.Storage.html#init/1"},{"type":"function","title":"Anoma.Node.Transaction.Storage.read/1","doc":"","ref":"Anoma.Node.Transaction.Storage.html#read/1"},{"type":"function","title":"Anoma.Node.Transaction.Storage.read_in_past/3","doc":"","ref":"Anoma.Node.Transaction.Storage.html#read_in_past/3"},{"type":"function","title":"Anoma.Node.Transaction.Storage.start_link/1","doc":"","ref":"Anoma.Node.Transaction.Storage.html#start_link/1"},{"type":"function","title":"Anoma.Node.Transaction.Storage.write/1","doc":"","ref":"Anoma.Node.Transaction.Storage.html#write/1"},{"type":"type","title":"Anoma.Node.Transaction.Storage.bare_key/0","doc":"","ref":"Anoma.Node.Transaction.Storage.html#t:bare_key/0"},{"type":"type","title":"Anoma.Node.Transaction.Storage.qualified_key/0","doc":"","ref":"Anoma.Node.Transaction.Storage.html#t:qualified_key/0"},{"type":"type","title":"Anoma.Node.Transaction.Storage.t/0","doc":"","ref":"Anoma.Node.Transaction.Storage.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Storage.HeightFilter","doc":"I am a filter which for height-matching.","ref":"Anoma.Node.Transaction.Storage.HeightFilter.html"},{"type":"function","title":"Anoma.Node.Transaction.Storage.HeightFilter.filter/2","doc":"","ref":"Anoma.Node.Transaction.Storage.HeightFilter.html#filter/2"},{"type":"type","title":"Anoma.Node.Transaction.Storage.HeightFilter.t/0","doc":"I store a value for filtering.","ref":"Anoma.Node.Transaction.Storage.HeightFilter.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transaction.Storage.HeightFilter.t/0","doc":"- `:height` - An integer","ref":"Anoma.Node.Transaction.Storage.HeightFilter.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transaction.Storage.WriteEvent","doc":"","ref":"Anoma.Node.Transaction.Storage.WriteEvent.html"},{"type":"type","title":"Anoma.Node.Transaction.Storage.WriteEvent.t/0","doc":"","ref":"Anoma.Node.Transaction.Storage.WriteEvent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Transaction.Supervisor","doc":"I am the supervisor for the transaction subsystem.","ref":"Anoma.Node.Transaction.Supervisor.html"},{"type":"function","title":"Anoma.Node.Transaction.Supervisor.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transaction.Supervisor.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transaction.Supervisor.init/1","doc":"","ref":"Anoma.Node.Transaction.Supervisor.html#init/1"},{"type":"function","title":"Anoma.Node.Transaction.Supervisor.start_link/1","doc":"","ref":"Anoma.Node.Transaction.Supervisor.html#start_link/1"},{"type":"module","title":"Anoma.Node.Utility.Consensus","doc":"A trivial consensus provider for the mempool.","ref":"Anoma.Node.Utility.Consensus.html"},{"type":"function","title":"Anoma.Node.Utility.Consensus.block_filter/0","doc":"","ref":"Anoma.Node.Utility.Consensus.html#block_filter/0"},{"type":"function","title":"Anoma.Node.Utility.Consensus.execute/1","doc":"","ref":"Anoma.Node.Utility.Consensus.html#execute/1"},{"type":"function","title":"Anoma.Node.Utility.Consensus.handle_cast/2","doc":"","ref":"Anoma.Node.Utility.Consensus.html#handle_cast/2"},{"type":"function","title":"Anoma.Node.Utility.Consensus.handle_info/2","doc":"","ref":"Anoma.Node.Utility.Consensus.html#handle_info/2"},{"type":"function","title":"Anoma.Node.Utility.Consensus.init/1","doc":"","ref":"Anoma.Node.Utility.Consensus.html#init/1"},{"type":"function","title":"Anoma.Node.Utility.Consensus.start/0","doc":"","ref":"Anoma.Node.Utility.Consensus.html#start/0"},{"type":"function","title":"Anoma.Node.Utility.Consensus.start_link/1","doc":"","ref":"Anoma.Node.Utility.Consensus.html#start_link/1"},{"type":"function","title":"Anoma.Node.Utility.Consensus.wait_for_block/1","doc":"","ref":"Anoma.Node.Utility.Consensus.html#wait_for_block/1"},{"type":"type","title":"Anoma.Node.Utility.Consensus.t/0","doc":"","ref":"Anoma.Node.Utility.Consensus.html#t:t/0"},{"type":"module","title":"Anoma.Node.Utility.Consensus.BlockFilter","doc":"I am a filter for Block events.","ref":"Anoma.Node.Utility.Consensus.BlockFilter.html"},{"type":"function","title":"Anoma.Node.Utility.Consensus.BlockFilter.filter/2","doc":"","ref":"Anoma.Node.Utility.Consensus.BlockFilter.html#filter/2"},{"type":"type","title":"Anoma.Node.Utility.Consensus.BlockFilter.t/0","doc":"","ref":"Anoma.Node.Utility.Consensus.BlockFilter.html#t:t/0"},{"type":"module","title":"Anoma.Node.Utility.Supervisor","doc":"I am the supervisor for the utility subsystem.","ref":"Anoma.Node.Utility.Supervisor.html"},{"type":"function","title":"Anoma.Node.Utility.Supervisor.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Utility.Supervisor.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Utility.Supervisor.init/1","doc":"","ref":"Anoma.Node.Utility.Supervisor.html#init/1"},{"type":"function","title":"Anoma.Node.Utility.Supervisor.start_link/1","doc":"","ref":"Anoma.Node.Utility.Supervisor.html#start_link/1"},{"type":"module","title":"Nock","doc":"Nock, a universal function on nouns.","ref":"Nock.html"},{"type":"function","title":"Nock.cons/2","doc":"","ref":"Nock.html#cons/2"},{"type":"function","title":"Nock.decrement_arm/0","doc":"","ref":"Nock.html#decrement_arm/0"},{"type":"function","title":"Nock.decrement_core/0","doc":"","ref":"Nock.html#decrement_core/0"},{"type":"function","title":"Nock.gas_meter/0","doc":"","ref":"Nock.html#gas_meter/0"},{"type":"function","title":"Nock.gas_meter/1","doc":"","ref":"Nock.html#gas_meter/1"},{"type":"function","title":"Nock.get_jet/1","doc":"","ref":"Nock.html#get_jet/1"},{"type":"function","title":"Nock.logics_core/0","doc":"","ref":"Nock.html#logics_core/0"},{"type":"function","title":"Nock.metered_nock/2","doc":"","ref":"Nock.html#metered_nock/2"},{"type":"function","title":"Nock.metered_nock/3","doc":"","ref":"Nock.html#metered_nock/3"},{"type":"function","title":"Nock.naive_nock/2","doc":"","ref":"Nock.html#naive_nock/2"},{"type":"function","title":"Nock.naive_nock/3","doc":"","ref":"Nock.html#naive_nock/3"},{"type":"function","title":"Nock.nock/2","doc":"","ref":"Nock.html#nock/2"},{"type":"function","title":"Nock.nock/3","doc":"","ref":"Nock.html#nock/3"},{"type":"function","title":"Nock.nock_0/1","doc":"","ref":"Nock.html#nock_0/1"},{"type":"function","title":"Nock.nock_1/1","doc":"","ref":"Nock.html#nock_1/1"},{"type":"function","title":"Nock.nock_2/2","doc":"","ref":"Nock.html#nock_2/2"},{"type":"function","title":"Nock.nock_3/1","doc":"","ref":"Nock.html#nock_3/1"},{"type":"function","title":"Nock.nock_4/1","doc":"","ref":"Nock.html#nock_4/1"},{"type":"function","title":"Nock.nock_5/2","doc":"","ref":"Nock.html#nock_5/2"},{"type":"function","title":"Nock.nock_6/3","doc":"","ref":"Nock.html#nock_6/3"},{"type":"function","title":"Nock.nock_7/2","doc":"","ref":"Nock.html#nock_7/2"},{"type":"function","title":"Nock.nock_8/2","doc":"","ref":"Nock.html#nock_8/2"},{"type":"function","title":"Nock.nock_9/2","doc":"","ref":"Nock.html#nock_9/2"},{"type":"function","title":"Nock.nock_10/3","doc":"","ref":"Nock.html#nock_10/3"},{"type":"function","title":"Nock.nock_11/2","doc":"","ref":"Nock.html#nock_11/2"},{"type":"function","title":"Nock.nock_11/3","doc":"","ref":"Nock.html#nock_11/3"},{"type":"function","title":"Nock.process_hint/1","doc":"","ref":"Nock.html#process_hint/1"},{"type":"function","title":"Nock.process_hint/2","doc":"","ref":"Nock.html#process_hint/2"},{"type":"function","title":"Nock.put_jet/2","doc":"","ref":"Nock.html#put_jet/2"},{"type":"function","title":"Nock.read_with_id/2","doc":"","ref":"Nock.html#read_with_id/2"},{"type":"function","title":"Nock.rm_core/0","doc":"","ref":"Nock.html#rm_core/0"},{"type":"function","title":"Nock.stdlib_core/0","doc":"","ref":"Nock.html#stdlib_core/0"},{"type":"function","title":"Nock.stdlib_layers/0","doc":"Gives the total numbers of layers in the standard library","ref":"Nock.html#stdlib_layers/0"},{"type":"type","title":"Nock.t/0","doc":"I contain environmental information on how Nock shall be evaluated.\n\nFor example Ι contain information on jettedness to\ndetermine if we should be using jets or not","ref":"Nock.html#t:t/0"},{"type":"module","title":"Nock.Bits","doc":"","ref":"Nock.Bits.html"},{"type":"function","title":"Nock.Bits.bit_list_to_integer/1","doc":"","ref":"Nock.Bits.html#bit_list_to_integer/1"},{"type":"function","title":"Nock.Bits.integer_to_bits/1","doc":"","ref":"Nock.Bits.html#integer_to_bits/1"},{"type":"function","title":"Nock.Bits.num_bits/2","doc":"","ref":"Nock.Bits.html#num_bits/2"},{"type":"module","title":"Nock.Cli","doc":"","ref":"Nock.Cli.html"},{"type":"function","title":"Nock.Cli.argument_option/0","doc":"","ref":"Nock.Cli.html#argument_option/0"},{"type":"function","title":"Nock.Cli.main/1","doc":"","ref":"Nock.Cli.html#main/1"},{"type":"module","title":"Nock.Cue","doc":"","ref":"Nock.Cue.html"},{"type":"function","title":"Nock.Cue.bit_width_tag/2","doc":"","ref":"Nock.Cue.html#bit_width_tag/2"},{"type":"function","title":"Nock.Cue.bit_width_tag/3","doc":"","ref":"Nock.Cue.html#bit_width_tag/3"},{"type":"function","title":"Nock.Cue.cue/1","doc":"","ref":"Nock.Cue.html#cue/1"},{"type":"function","title":"Nock.Cue.cue!/1","doc":"","ref":"Nock.Cue.html#cue!/1"},{"type":"function","title":"Nock.Cue.cue_tag/2","doc":"","ref":"Nock.Cue.html#cue_tag/2"},{"type":"function","title":"Nock.Cue.parse/1","doc":"","ref":"Nock.Cue.html#parse/1"},{"type":"function","title":"Nock.Cue.parse/2","doc":"","ref":"Nock.Cue.html#parse/2"},{"type":"function","title":"Nock.Cue.parse_single/2","doc":"","ref":"Nock.Cue.html#parse_single/2"},{"type":"function","title":"Nock.Cue.rub_no_index/2","doc":"","ref":"Nock.Cue.html#rub_no_index/2"},{"type":"type","title":"Nock.Cue.cue_tag/0","doc":"","ref":"Nock.Cue.html#t:cue_tag/0"},{"type":"type","title":"Nock.Cue.t/0","doc":"","ref":"Nock.Cue.html#t:t/0"},{"type":"module","title":"Nock.Jam","doc":"","ref":"Nock.Jam.html"},{"type":"function","title":"Nock.Jam.cache_noun/2","doc":"","ref":"Nock.Jam.html#cache_noun/2"},{"type":"function","title":"Nock.Jam.encode/2","doc":"","ref":"Nock.Jam.html#encode/2"},{"type":"function","title":"Nock.Jam.fetch_cache_noun/2","doc":"","ref":"Nock.Jam.html#fetch_cache_noun/2"},{"type":"function","title":"Nock.Jam.handle_back/3","doc":"","ref":"Nock.Jam.html#handle_back/3"},{"type":"function","title":"Nock.Jam.jam/1","doc":"","ref":"Nock.Jam.html#jam/1"},{"type":"function","title":"Nock.Jam.write/2","doc":"","ref":"Nock.Jam.html#write/2"},{"type":"function","title":"Nock.Jam.write_atom/2","doc":"","ref":"Nock.Jam.html#write_atom/2"},{"type":"function","title":"Nock.Jam.write_back_ref/2","doc":"","ref":"Nock.Jam.html#write_back_ref/2"},{"type":"function","title":"Nock.Jam.write_length/2","doc":"","ref":"Nock.Jam.html#write_length/2"},{"type":"type","title":"Nock.Jam.cache/0","doc":"","ref":"Nock.Jam.html#t:cache/0"},{"type":"type","title":"Nock.Jam.t/0","doc":"","ref":"Nock.Jam.html#t:t/0"},{"type":"module","title":"Nock.Jets","doc":"Jets for the Nock interpreter, taking a gate core. Not fully general.","ref":"Nock.Jets.html"},{"type":"function","title":"Nock.Jets.add/1","doc":"","ref":"Nock.Jets.html#add/1"},{"type":"function","title":"Nock.Jets.bex/1","doc":"","ref":"Nock.Jets.html#bex/1"},{"type":"function","title":"Nock.Jets.calculate_core_param/3","doc":"","ref":"Nock.Jets.html#calculate_core_param/3"},{"type":"function","title":"Nock.Jets.calculate_mug_of_core/2","doc":"We calculate the mug of a given core at a given gate.","ref":"Nock.Jets.html#calculate_mug_of_core/2"},{"type":"function","title":"Parameters - Nock.Jets.calculate_mug_of_core/2","doc":"- `index_in_core` - the index of the gate itself\n\n- `parent_layer` - the layer of the standard library. This should be\n  the same as the layer numbers found in `anoma.hoon`","ref":"Nock.Jets.html#calculate_mug_of_core/2-parameters"},{"type":"function","title":"Example - Nock.Jets.calculate_mug_of_core/2","doc":"In the Hoon repl one should write\n\n    dojo> |commit %anoma\n    >=\n    dojo> =anoma -build-file /=anoma=/lib/anoma/hoon\n    dojo> =>  anoma  !=(sub)\n    [9 47 0 31]\n\nNow in IEX\n\n    > Nock.Jets.calculate_mug_of_core(47, 1)\n    14801825384048474882","ref":"Nock.Jets.html#calculate_mug_of_core/2-example"},{"type":"function","title":"Nock.Jets.calculate_mug_of_layer/1","doc":"We calculate the mug of a given layer at any given gate.","ref":"Nock.Jets.html#calculate_mug_of_layer/1"},{"type":"function","title":"Parameters - Nock.Jets.calculate_mug_of_layer/1","doc":"- `parent_layer` - the layer of the standard library. This should be\n  the same as the layer numbers found in `anoma.hoon`","ref":"Nock.Jets.html#calculate_mug_of_layer/1-parameters"},{"type":"function","title":"Example - Nock.Jets.calculate_mug_of_layer/1","doc":"In the Hoon repl one should write\n\n    dojo> |commit %anoma\n    >=\n    dojo> =anoma -build-file /=anoma=/lib/anoma/hoon\n    dojo> =>  anoma  !=(sub)\n    [9 47 0 31]\n\nNow in IEX\n\n    > Nock.Jets.calculate_mug_of_layer(1)\n    17654928022549292273\n\nThis value should match Nock.@layer_1_contex_mug","ref":"Nock.Jets.html#calculate_mug_of_layer/1-example"},{"type":"function","title":"Nock.Jets.calculate_mug_of_param_core/3","doc":"Like `calculate_mug_of_core/2` except we work over a parameterized core.","ref":"Nock.Jets.html#calculate_mug_of_param_core/3"},{"type":"function","title":"Example - Nock.Jets.calculate_mug_of_param_core/3","doc":"> Nock.Jets.calculate_mug_of_param_core(767, 10, 4)\n    12605872635346981159\n\nFor our standard library, so far only layer 4 is parameterized","ref":"Nock.Jets.html#calculate_mug_of_param_core/3-example"},{"type":"function","title":"Nock.Jets.calculate_mug_of_param_layer/2","doc":"Like `calculate_mug_of_layer/1` except we work over a parameterized core.","ref":"Nock.Jets.html#calculate_mug_of_param_layer/2"},{"type":"function","title":"Example - Nock.Jets.calculate_mug_of_param_layer/2","doc":"> Nock.Jets.calculate_mug_of_param_layer(10, 4)\n    11284470320276584209\n\nFor our standard library, so far only layer 4 is parameterized","ref":"Nock.Jets.html#calculate_mug_of_param_layer/2-example"},{"type":"function","title":"Nock.Jets.cue/1","doc":"","ref":"Nock.Jets.html#cue/1"},{"type":"function","title":"Nock.Jets.dec/1","doc":"","ref":"Nock.Jets.html#dec/1"},{"type":"function","title":"Nock.Jets.div/1","doc":"","ref":"Nock.Jets.html#div/1"},{"type":"function","title":"Nock.Jets.gte/1","doc":"","ref":"Nock.Jets.html#gte/1"},{"type":"function","title":"Nock.Jets.gth/1","doc":"","ref":"Nock.Jets.html#gth/1"},{"type":"function","title":"Nock.Jets.jam/1","doc":"","ref":"Nock.Jets.html#jam/1"},{"type":"function","title":"Nock.Jets.lsh/1","doc":"","ref":"Nock.Jets.html#lsh/1"},{"type":"function","title":"Nock.Jets.lte/1","doc":"","ref":"Nock.Jets.html#lte/1"},{"type":"function","title":"Nock.Jets.lth/1","doc":"","ref":"Nock.Jets.html#lth/1"},{"type":"function","title":"Nock.Jets.met/1","doc":"","ref":"Nock.Jets.html#met/1"},{"type":"function","title":"Nock.Jets.mix/1","doc":"","ref":"Nock.Jets.html#mix/1"},{"type":"function","title":"Nock.Jets.mod/1","doc":"","ref":"Nock.Jets.html#mod/1"},{"type":"function","title":"Nock.Jets.mul/1","doc":"","ref":"Nock.Jets.html#mul/1"},{"type":"function","title":"Nock.Jets.nend/1","doc":"","ref":"Nock.Jets.html#nend/1"},{"type":"function","title":"Nock.Jets.rsh/1","doc":"","ref":"Nock.Jets.html#rsh/1"},{"type":"function","title":"Nock.Jets.sample/1","doc":"","ref":"Nock.Jets.html#sample/1"},{"type":"function","title":"Nock.Jets.shax/1","doc":"","ref":"Nock.Jets.html#shax/1"},{"type":"function","title":"Nock.Jets.sign/1","doc":"","ref":"Nock.Jets.html#sign/1"},{"type":"function","title":"Nock.Jets.sign_detatched/1","doc":"","ref":"Nock.Jets.html#sign_detatched/1"},{"type":"function","title":"Nock.Jets.sub/1","doc":"","ref":"Nock.Jets.html#sub/1"},{"type":"function","title":"Nock.Jets.verify/1","doc":"","ref":"Nock.Jets.html#verify/1"},{"type":"function","title":"Nock.Jets.verify_detatched/1","doc":"","ref":"Nock.Jets.html#verify_detatched/1"},{"type":"module","title":"Noun","doc":"The noun data structure.\n\nRepresented as Elixir cons cells, which might get annoying.","ref":"Noun.html"},{"type":"function","title":"Noun.atom_binary_to_integer/1","doc":"","ref":"Noun.html#atom_binary_to_integer/1"},{"type":"function","title":"Noun.atom_integer_to_binary/1","doc":"","ref":"Noun.html#atom_integer_to_binary/1"},{"type":"function","title":"Noun.atom_integer_to_binary/2","doc":"","ref":"Noun.html#atom_integer_to_binary/2"},{"type":"function","title":"Noun.axis/2","doc":"","ref":"Noun.html#axis/2"},{"type":"function","title":"Noun.condensed_print/1","doc":"","ref":"Noun.html#condensed_print/1"},{"type":"function","title":"Noun.equal/2","doc":"","ref":"Noun.html#equal/2"},{"type":"function","title":"Noun.index_to_offset/1","doc":"Calculates the index from the given access offset","ref":"Noun.html#index_to_offset/1"},{"type":"macro","title":"Noun.is_noun_atom/1","doc":"","ref":"Noun.html#is_noun_atom/1"},{"type":"macro","title":"Noun.is_noun_cell/1","doc":"","ref":"Noun.html#is_noun_cell/1"},{"type":"function","title":"Noun.is_zero/1","doc":"","ref":"Noun.html#is_zero/1"},{"type":"function","title":"Noun.list_nock_to_erlang/1","doc":"","ref":"Noun.html#list_nock_to_erlang/1"},{"type":"function","title":"Noun.list_nock_to_erlang_safe/1","doc":"I try to turn an Elixir term to a proper list.\nIf the term is a nock list, return {:ok, result}\nOtheriwse :error","ref":"Noun.html#list_nock_to_erlang_safe/1"},{"type":"function","title":"Noun.mug/1","doc":"","ref":"Noun.html#mug/1"},{"type":"function","title":"Noun.normalize_noun/1","doc":"","ref":"Noun.html#normalize_noun/1"},{"type":"function","title":"Noun.pad_trailing/2","doc":"","ref":"Noun.html#pad_trailing/2"},{"type":"function","title":"Noun.replace/3","doc":"","ref":"Noun.html#replace/3"},{"type":"function","title":"Noun.to_normalized_noun/1","doc":"","ref":"Noun.html#to_normalized_noun/1"},{"type":"type","title":"Noun.noun_atom/0","doc":"","ref":"Noun.html#t:noun_atom/0"},{"type":"type","title":"Noun.noun_cell/0","doc":"","ref":"Noun.html#t:noun_cell/0"},{"type":"type","title":"Noun.t/0","doc":"","ref":"Noun.html#t:t/0"},{"type":"module","title":"Noun.Format","doc":"Parsing and printing of nouns.","ref":"Noun.Format.html"},{"type":"function","title":"Noun.Format.parse/1","doc":"","ref":"Noun.Format.html#parse/1"},{"type":"function","title":"Noun.Format.parse_always/1","doc":"","ref":"Noun.Format.html#parse_always/1"},{"type":"function","title":"Noun.Format.parse_cell/1","doc":"","ref":"Noun.Format.html#parse_cell/1"},{"type":"function","title":"Noun.Format.parse_inner/1","doc":"","ref":"Noun.Format.html#parse_inner/1"},{"type":"function","title":"Noun.Format.parse_tail/1","doc":"","ref":"Noun.Format.html#parse_tail/1"},{"type":"function","title":"Noun.Format.print/1","doc":"","ref":"Noun.Format.html#print/1"},{"type":"function","title":"Noun.Format.print_tail/1","doc":"","ref":"Noun.Format.html#print_tail/1"},{"type":"protocol","title":"Noun.Nounable","doc":"","ref":"Noun.Nounable.html"},{"type":"function","title":"Noun.Nounable.to_noun/1","doc":"I turn the transaction into a noun","ref":"Noun.Nounable.html#to_noun/1"},{"type":"type","title":"Noun.Nounable.t/0","doc":"All the types that implement this protocol.","ref":"Noun.Nounable.html#t:t/0"},{"type":"behaviour","title":"Noun.Nounable.Kind","doc":"","ref":"Noun.Nounable.Kind.html"},{"type":"callback","title":"Noun.Nounable.Kind.from_noun/1","doc":"I convert the given `t:Noun.t/0` into the given structure","ref":"Noun.Nounable.Kind.html#c:from_noun/1"},{"type":"module","title":"CommitmentTree","doc":"A simple commitment tree.\n\nCurrently stores all commitments forever, and stores the full tree in memory,\npending future more sophisticated retention policies.  Does not yet store any\nanchors itself for the same reason--this is a complex policy level decision.\n\nHas a fixed depth.\n\nFiats that empty subtrees have a hash of 0 for simplicity.","ref":"CommitmentTree.html"},{"type":"function","title":"CommitmentTree.add/2","doc":"Adds commitments to the commitment tree, and returns the new tree and the anchor.\nTODO handle the tree's filling up","ref":"CommitmentTree.html#add/2"},{"type":"function","title":"CommitmentTree.init_storage/1","doc":"","ref":"CommitmentTree.html#init_storage/1"},{"type":"function","title":"CommitmentTree.new/2","doc":"Creates a new `CommitmentTree` struct.","ref":"CommitmentTree.html#new/2"},{"type":"function","title":"CommitmentTree.prove/2","doc":"","ref":"CommitmentTree.html#prove/2"},{"type":"type","title":"CommitmentTree.t/0","doc":"","ref":"CommitmentTree.html#t:t/0"},{"type":"module","title":"CommitmentTree.Node","doc":"","ref":"CommitmentTree.Node.html"},{"type":"function","title":"CommitmentTree.Node.new/2","doc":"Creates a new internal node.\nChildren is a tuple of size spec.splay, each element of which is either a binary or another node.","ref":"CommitmentTree.Node.html#new/2"},{"type":"function","title":"CommitmentTree.Node.new_empty/1","doc":"Creates a new internal node, all children of which are empty.","ref":"CommitmentTree.Node.html#new_empty/1"},{"type":"function","title":"CommitmentTree.Node.prove/3","doc":"Produces a proof for leaf #cursor of node, taking the form of a nested tuple,\nas described in proof.ex","ref":"CommitmentTree.Node.html#prove/3"},{"type":"type","title":"CommitmentTree.Node.t/0","doc":"","ref":"CommitmentTree.Node.html#t:t/0"},{"type":"module","title":"CommitmentTree.Proof","doc":"I represent a compact proof that a particular element is contained within the\ncommitment tree.","ref":"CommitmentTree.Proof.html"},{"type":"function","title":"CommitmentTree.Proof.new/2","doc":"","ref":"CommitmentTree.Proof.html#new/2"},{"type":"function","title":"CommitmentTree.Proof.verify/4","doc":"","ref":"CommitmentTree.Proof.html#verify/4"},{"type":"function","title":"CommitmentTree.Proof.verifyx/5","doc":"","ref":"CommitmentTree.Proof.html#verifyx/5"},{"type":"type","title":"CommitmentTree.Proof.t/0","doc":"","ref":"CommitmentTree.Proof.html#t:t/0"},{"type":"module","title":"CommitmentTree.Spec","doc":"A specification for a commitment tree.","ref":"CommitmentTree.Spec.html"},{"type":"function","title":"CommitmentTree.Spec.cairo_poseidon_cm_tree_spec/0","doc":"","ref":"CommitmentTree.Spec.html#cairo_poseidon_cm_tree_spec/0"},{"type":"function","title":"CommitmentTree.Spec.cm_tree_spec/0","doc":"","ref":"CommitmentTree.Spec.html#cm_tree_spec/0"},{"type":"function","title":"CommitmentTree.Spec.new/4","doc":"","ref":"CommitmentTree.Spec.html#new/4"},{"type":"type","title":"CommitmentTree.Spec.t/0","doc":"","ref":"CommitmentTree.Spec.html#t:t/0"},{"type":"module","title":"EventBroker","doc":"I am the EventBroker Application Module.\n\nI startup the PubSub system as an own OTP application. Moreover I provide\nall the API necessary for the use of the system. I contain all public\nfunctionality provided by the Broker and the Registry.","ref":"EventBroker.html"},{"type":"module","title":"Public API - EventBroker","doc":"I have the following public functionality:\n\n- `event/1`\n- `subscribe_me/1`\n- `unsubscribe_me/1`\n- `subscribe/2`\n- `unsubscribe/2`","ref":"EventBroker.html#module-public-api"},{"type":"function","title":"EventBroker.event/2","doc":"I am the Event Broker event function.\n\nI process any incoming events by sending them to all of Broker subscribers\nusing the `send/2` functionality.","ref":"EventBroker.html#event/2"},{"type":"function","title":"EventBroker.start/2","doc":"","ref":"EventBroker.html#start/2"},{"type":"function","title":"EventBroker.subscribe/3","doc":"I am the subscription function.\n\nGiven a PID and a list of filter specs, I ensure that all the actors\ncorresponding to each spec given in the list is launched and subscribed\nto each other in the appropriate order - e.g. given `[spec1, spec2]` I\nensure that agents implemented `spec1` and `spec2` are launched and that\nthe former is subscribed to the top broker, while the latter is subscribed\nto the former.\n\nI also do this in a minimal fashion, that is, if some starting subchain of\nfilter spec dependency has already been registered, I launch the minimal\nchain remaining to build the full dependency.\n\nNote that each filter actor is hence not only determined by the filtering\nfunctionality it has but also on the chain of dependencies it is spawned\nwith. Hence `[spec1, spec2]` corresponds to an agent different from\n`[spec2]`.\n\nAfterwards, I subscribe the given PID to the final filter agent in the\ndependency chain and register all the new agents in the map by putting\nthe filter agent PIDs as values to their dependency filter specification.\n\nIf I notice that any of the filter structures do not have an appropriate\npublic filter functionality exposed, I return the list of such modules\nback to the user and do nothing with respect to agent-spawning or\nregistration.\n\nFilter Agent spawning is handled via DynamicSupervisor.","ref":"EventBroker.html#subscribe/3"},{"type":"function","title":"EventBroker.subscribe_me/2","doc":"I am a subscription function specifically for `self()`\n\nI call `subscribe/2` where the first argument is `self()`","ref":"EventBroker.html#subscribe_me/2"},{"type":"function","title":"EventBroker.unsubscribe/3","doc":"I am the unsubscription function.\n\nGiven a PID and a list of filter specs, I get the PID of the related\nfilter agent by looking in my state, then ask it to unsubscribe the\ngiven PID from it. In case the agent has other subscribers, I return the\nbase state.\n\nOtherwise, it will shut down, prompting to recursively send unsubscription\nrequests to its parent filters and processing their termination\nappropriately in a synchronous manner.\n\nAfter all the requests have been sent and terminations recorded, I remove\nall agents which have shut down from my registry map and return `:ok`","ref":"EventBroker.html#unsubscribe/3"},{"type":"function","title":"EventBroker.unsubscribe_me/2","doc":"I am the unsubscription function specifically for `self()`\n\nI call `unsubscribe/2` where the first argument is `self()`","ref":"EventBroker.html#unsubscribe_me/2"},{"type":"type","title":"EventBroker.filter_spec_list/0","doc":"I am a filter dependency specification, I am a list of filter specs listed\nin the order in which the filter agents implementing said specs should be\nsubscribed to one another.","ref":"EventBroker.html#t:filter_spec_list/0"},{"type":"module","title":"EventBroker.Broker","doc":"I am a Broker module.\n\nI specify the behavior of the server acting as a central broker of the\nPubSub servive. My functionality is minimal. I wait for messages and\nrelay them to my subscribers.","ref":"EventBroker.Broker.html"},{"type":"function","title":"EventBroker.Broker.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"EventBroker.Broker.html#child_spec/1"},{"type":"function","title":"EventBroker.Broker.init/1","doc":"","ref":"EventBroker.Broker.html#init/1"},{"type":"function","title":"EventBroker.Broker.start_link/1","doc":"","ref":"EventBroker.Broker.html#start_link/1"},{"type":"type","title":"EventBroker.Broker.t/0","doc":"I am the type of the Event Broker.","ref":"EventBroker.Broker.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.Broker.t/0","doc":"- `:subscribers` - The set of pids showcasing subscribers.\n                   Default: Map.Set.new()","ref":"EventBroker.Broker.html#t:t/0-fields"},{"type":"module","title":"EventBroker.Event","doc":"I am an Event module for the Event Broker.\n\nI provide the standard event format to be distributed for the PubSub\nsystem. Unless the message is in my format it does not get processed.","ref":"EventBroker.Event.html"},{"type":"macro","title":"EventBroker.Event.new_with_body/1","doc":"","ref":"EventBroker.Event.html#new_with_body/1"},{"type":"type","title":"EventBroker.Event.t/0","doc":"I am the Event type for the Event Broker.\n\nMy fields determine the overall structure of the messages.","ref":"EventBroker.Event.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.Event.t/0","doc":"- `:source_module` - The module from which the message got sent.\n- `:body` - A body of the event.","ref":"EventBroker.Event.html#t:t/0-fields"},{"type":"behaviour","title":"EventBroker.Filter","doc":"I am a filter module for the Event Broker. I provide the callbacks for\nall the filters used in the PubSub system.","ref":"EventBroker.Filter.html"},{"type":"callback","title":"EventBroker.Filter.filter/2","doc":"","ref":"EventBroker.Filter.html#c:filter/2"},{"type":"module","title":"EventBroker.FilterAgent","doc":"I am a Filter Agent module.\n\nI implement the base server behavior of the spawned filter agent. In\ngeneral, I monitor subscribers of an individual filtering agent and\nsend whichever events I receive to them.","ref":"EventBroker.FilterAgent.html"},{"type":"function","title":"EventBroker.FilterAgent.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"EventBroker.FilterAgent.html#child_spec/1"},{"type":"function","title":"EventBroker.FilterAgent.init/1","doc":"","ref":"EventBroker.FilterAgent.html#init/1"},{"type":"function","title":"EventBroker.FilterAgent.start_link/1","doc":"","ref":"EventBroker.FilterAgent.html#start_link/1"},{"type":"type","title":"EventBroker.FilterAgent.t/0","doc":"I am the type of the Filter Agent.\n\nI contain the minimal info for a filter to work, namely the filter\nspecification to aplly to incoming messages and subscribers to send\nfiltered messages to.","ref":"EventBroker.FilterAgent.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.FilterAgent.t/0","doc":"- `:spec` - The filter specification. This is a structure of a module\n            with a public filter API for the agent to call.\n- `:subscribers` - The list of subscribers to send filtered messages to.\n                   Default: MapSet.new()","ref":"EventBroker.FilterAgent.html#t:t/0-fields"},{"type":"module","title":"EventBroker.Filters.LessTrivial","doc":"I represent a filter which filters a message based on the value I store\nin my struct.\n\nI either always return true or always return false.","ref":"EventBroker.Filters.LessTrivial.html"},{"type":"function","title":"EventBroker.Filters.LessTrivial.filter/2","doc":"","ref":"EventBroker.Filters.LessTrivial.html#filter/2"},{"type":"type","title":"EventBroker.Filters.LessTrivial.t/0","doc":"I store a value for filtering.","ref":"EventBroker.Filters.LessTrivial.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.Filters.LessTrivial.t/0","doc":"- `:value` - A boolean value.","ref":"EventBroker.Filters.LessTrivial.html#t:t/0-fields"},{"type":"module","title":"EventBroker.Filters.SourceModule","doc":"I filter an event based on its source module.","ref":"EventBroker.Filters.SourceModule.html"},{"type":"function","title":"EventBroker.Filters.SourceModule.filter/2","doc":"","ref":"EventBroker.Filters.SourceModule.html#filter/2"},{"type":"type","title":"EventBroker.Filters.SourceModule.t/0","doc":"I store the module representing the source of a message.","ref":"EventBroker.Filters.SourceModule.html#t:t/0"},{"type":"type","title":"Field - EventBroker.Filters.SourceModule.t/0","doc":"- `:module` - A module name.","ref":"EventBroker.Filters.SourceModule.html#t:t/0-field"},{"type":"module","title":"EventBroker.Filters.Trivial","doc":"I am the trivial filter. I always return true.","ref":"EventBroker.Filters.Trivial.html"},{"type":"function","title":"EventBroker.Filters.Trivial.filter/2","doc":"","ref":"EventBroker.Filters.Trivial.html#filter/2"},{"type":"type","title":"EventBroker.Filters.Trivial.t/0","doc":"","ref":"EventBroker.Filters.Trivial.html#t:t/0"},{"type":"module","title":"EventBroker.Registry","doc":"I am the Registry for the PubSub system.\n\nI am the central registry of all the topic subscirptions and filters. I\nam responsible for spawning filter agents, (un)subscribing to them, and\nkeeping track of relations between them.","ref":"EventBroker.Registry.html"},{"type":"function","title":"EventBroker.Registry.__struct__/0","doc":"I am the type of the registered filters, matching a filter agent to its\nPID.","ref":"EventBroker.Registry.html#__struct__/0"},{"type":"function","title":"EventBroker.Registry.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"EventBroker.Registry.html#child_spec/1"},{"type":"function","title":"EventBroker.Registry.init/1","doc":"","ref":"EventBroker.Registry.html#init/1"},{"type":"function","title":"EventBroker.Registry.start_link/1","doc":"","ref":"EventBroker.Registry.html#start_link/1"},{"type":"type","title":"EventBroker.Registry.registered_filters/0","doc":"","ref":"EventBroker.Registry.html#t:registered_filters/0"},{"type":"type","title":"EventBroker.Registry.t/0","doc":"I am the type of the Registry.\n\nMy main functionality is to keep track of all spawned filter actors.","ref":"EventBroker.Registry.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.Registry.t/0","doc":"- `:supervisor` - The name of the dynamic supervisor launched on start.\n- `:registered_filters` - The map whose keys are a filter-spec dependency\nlist and whose values are PID's of filter\nagents corresponding to said lists.\nDefault: %{}","ref":"EventBroker.Registry.html#t:t/0-fields"},{"type":"module","title":"EventBroker.Supervisor","doc":"I am the EventBroker Supervisor for PubSub.\n\nI start up 3 children, namely the Broker, the Registry, and the Dynamic\nSupervisor for the filters.","ref":"EventBroker.Supervisor.html"},{"type":"function","title":"EventBroker.Supervisor.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"EventBroker.Supervisor.html#child_spec/1"},{"type":"function","title":"EventBroker.Supervisor.init/1","doc":"","ref":"EventBroker.Supervisor.html#init/1"},{"type":"function","title":"EventBroker.Supervisor.start_link/1","doc":"","ref":"EventBroker.Supervisor.html#start_link/1"},{"type":"module","title":"Anoma.Utility","doc":"I provide utility functions for users.","ref":"Anoma.Utility.html"},{"type":"module","title":"Public API - Anoma.Utility","doc":"I possess the following public API:\n\n- message_label/1","ref":"Anoma.Utility.html#module-public-api"},{"type":"macro","title":"Anoma.Utility.defbug/2","doc":"I am the function definition macro for debugging.\n\nI mainly should be used on functions which satisfy:\n\n1) Needing to be private i.e. not expose API to other Engines.\n2) Important for core functionality and hence requiring documentation.\n\nGiven the two are satisfied, use me to define a function which becomes\npublic once in debug mode and otherwise remains private.\n\nI am to be used alongside the `docp/1` macro to allow for good\ndocumentation practices.","ref":"Anoma.Utility.html#defbug/2"},{"type":"macro","title":"Anoma.Utility.docp/1","doc":"I am a macro which allows to provide documentation to possibly private\nfunctions.\n\nIf the environment of the application is `:debug` I actually put the docs\ninto the compiled module. If not, I produce `nil`, which does not\ninteract with overall module environment.","ref":"Anoma.Utility.html#docp/1"},{"type":"function","title":"Anoma.Utility.message_label/1","doc":"Helps labeling for `Kino.Process.seq_trace/2`, for the Router abstraction","ref":"Anoma.Utility.html#message_label/1"},{"type":"module","title":"TestHelper.Nock","doc":"I am a testing module that has some common definitions for nock\nfunctions.","ref":"TestHelper.Nock.html"},{"type":"function","title":"TestHelper.Nock.counter_val_plus_one/1","doc":"","ref":"TestHelper.Nock.html#counter_val_plus_one/1"},{"type":"function","title":"TestHelper.Nock.increment_counter_val/1","doc":"","ref":"TestHelper.Nock.html#increment_counter_val/1"},{"type":"function","title":"TestHelper.Nock.zero_counter/1","doc":"","ref":"TestHelper.Nock.html#zero_counter/1"},{"type":"module","title":"TestHelper.TestMacro","doc":"I am a module populated by macros associated to Anoma Testing.\n\nMy use macro replaces ExUnit.case use macro with the caveat of ignoring\nthe Assertions imports.\n\nUse me in order to define various macros to be used in tests.","ref":"TestHelper.TestMacro.html"},{"type":"macro","title":"TestHelper.TestMacro.assert/2","doc":"I call the `assert` macro from ExUnit.Assertions\n\nIf the environment is :debug I pry on errors.","ref":"TestHelper.TestMacro.html#assert/2"},{"type":"macro","title":"TestHelper.TestMacro.assert_receive/3","doc":"I call the `assert_receive` macro from ExUnit.Assertions\n\nIf the environment is :debug I pry on errors.","ref":"TestHelper.TestMacro.html#assert_receive/3"},{"type":"function","title":"TestHelper.TestMacro.assertion_abstract/3","doc":"I catch a variable binding expression in debug mode and call `call_assert`\non it.\n\nIf the expression caught is variable-bining, after evaluating I also\ncall said binding at AST level to bind it outside try-rescue.\n\nIf the expression is not in debug mode, I simply call the assertion on\nthe expression.","ref":"TestHelper.TestMacro.html#assertion_abstract/3"},{"type":"function","title":"TestHelper.TestMacro.assertion_alias/2","doc":"I add the ExUnit.Assertions prefix to the function call on the AST level\nand apply it to the expression as a quoted structure.","ref":"TestHelper.TestMacro.html#assertion_alias/2"},{"type":"function","title":"TestHelper.TestMacro.call_assert/2","doc":"I call the try functionality to capture the error.","ref":"TestHelper.TestMacro.html#call_assert/2"},{"type":"function","title":"Pattern-Matching Variations - TestHelper.TestMacro.call_assert/2","doc":"- `call_assert(atom, [{:=, _, [left, _]}])` - Afterwards I bind the\n                                              left side variables.\n- `call_assert(atom, expr)` - Just call the capture.","ref":"TestHelper.TestMacro.html#call_assert/2-pattern-matching-variations"},{"type":"function","title":"TestHelper.TestMacro.message_parse/3","doc":"Depending on the given message, I call either `assert` or `refute` with\ndifferent arities.","ref":"TestHelper.TestMacro.html#message_parse/3"},{"type":"function","title":"TestHelper.TestMacro.quote_try/2","doc":"I quote the error-capturing of expressions.","ref":"TestHelper.TestMacro.html#quote_try/2"},{"type":"macro","title":"TestHelper.TestMacro.refute/2","doc":"I call the `refute` macro from ExUnit.Assertions\n\nIf the environment is :debug I pry on errors.","ref":"TestHelper.TestMacro.html#refute/2"},{"type":"macro","title":"TestHelper.TestMacro.refute_receive/3","doc":"I call the `assert_refute` macro from ExUnit.Assertions\n\nIf the environment is :debug I pry on errors.","ref":"TestHelper.TestMacro.html#refute_receive/3"},{"type":"function","title":"TestHelper.TestMacro.try_assert/2","doc":"I present a quoted expression to try depending on the input.","ref":"TestHelper.TestMacro.html#try_assert/2"},{"type":"function","title":"Pattern-Matching Variations - TestHelper.TestMacro.try_assert/2","doc":"- `try_assert(atom, [{:=, _, _}])` - I use the assertion, print the\n                                     binded variables to escape\n                                     warnings and then print the\n                                     original result\n- `try_assert(atom, expr)` - I use the assertion","ref":"TestHelper.TestMacro.html#try_assert/2-pattern-matching-variations"},{"type":"extras","title":"Anoma","doc":"# Anoma\n\nThis is an implementation of the Anoma protocol, whose specs can be\nfound [here](https://specs.anoma.net/alpha).","ref":"readme.html"},{"type":"extras","title":"Following Development - Anoma","doc":"Work is merged into `base` on a bi-weekly (once every two weeks)\nschedule.\n\nDevelopment can be followed in multiple ways:\n\n1. [Issues are put into the project overview](https://github.com/orgs/anoma/projects/19)\n   - This is a good way to see what work is assigned and the various\n     views into how goals are being met\n2. [Promise Graph from the project overview](https://specs.anoma.net/projects/anoma-19.html)\n   - This is the same information as `1.` but using our own promise\n     graph tooling. This is kept up to date hourly.\n3. [What's Cooking on Anoma](https://github.com/orgs/anoma/projects/20 \"A good view on how topics are progressing throughout a cycle\")\n4. [Issues](https://github.com/anoma/anoma/issues) and [pull requests](https://github.com/anoma/anoma/pulls)\n   - This is good for viewing new issues and work coming in, but the\n     other views are typically a better way to view this","ref":"readme.html#following-development"},{"type":"extras","title":"Dependencies - Anoma","doc":"To have a working Anoma Node the following dependencies are required:\n\n1. `cmake`\n2. `Erlang`\n3. `Elixir`\n4. `zig`\n5. `rust`","ref":"readme.html#dependencies"},{"type":"extras","title":"OSX - Anoma","doc":"```sh\nbrew install elixir\nbrew install zig\n```","ref":"readme.html#osx"},{"type":"extras","title":"Linux - Anoma","doc":"All the dependencies can be grabbed from your distro's package manager.","ref":"readme.html#linux"},{"type":"extras","title":"Installation - Anoma","doc":"To install the dependencies as well as Anoma run:\n\n```bash\nmix deps.get\nmix compile\n```\n\nTo start an Anoma instance run one of these:\n\n```bash\niex -S mix # starts an interactive shell\nmix run --no-halt # starts a non-interactive shell\n```\n\nSee the Contributing section for how to get the best use of the\ninteractive shell.","ref":"readme.html#installation"},{"type":"extras","title":"Contributing - Anoma","doc":"Please read the [contributor's guide](./documentation/contributing.livemd) for in\ndepth details about the codebase.","ref":"readme.html#contributing"},{"type":"extras","title":"Git - Anoma","doc":"This codebase follows a git style similar to\n[git](https://git-scm.com/) or\n[linux](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git).\n\nNew code should be based on `base`, and no attempt to keep it up to\nsync with `main` should be had. When one's topic is ready, just submit\na PR on github and a maintainer will handle any merge conflicts.\n\nThere are bi-weekly releases, so do not be afraid if a maintainer says\nthe PR is merged but it's still open, this just means that it's merged\ninto `next` or `main` and will be included in the next scheduled\nrelease.\n\nFor more information on a smooth git experience check out the [git\nsection in contributor's guide](./documentation/contributing/git.livemd)\n\nHappy hacking, and don't be afraid to submit patches.","ref":"readme.html#git"},{"type":"extras","title":"Analysis","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Analysis","ref":"analysis.html"},{"type":"extras","title":"Index - Analysis","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"analysis.html#index"},{"type":"extras","title":"Analysis - Analysis","doc":"Documents in this section cover analysis over the code in the repository.","ref":"analysis.html#analysis"},{"type":"extras","title":"Fema Analysis On the Pinger","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Fema Analysis On the Pinger","ref":"fema-analysis-pinger.html"},{"type":"extras","title":"Index - Fema Analysis On the Pinger","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"fema-analysis-pinger.html#index"},{"type":"extras","title":"Analysis - Fema Analysis On the Pinger","doc":"This document contains a [FEMA](https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis) analysis on `Anoma.Node.Pinger`.\n\nThe pinger module is responsible for producing blocks at a set time.\n\nIn order to get a good feeling of the errors, this document will:\n\n1. Cover the traces of it's public API\n2. Do a more indpeth analysis of the effects, inducing the key calls\n3. Disect how the module could fail\n4. Locate how the API could be misused and create a failure case\n5. Look at the codebase for potential areas where this could occur\n6. Note the nock-on effects on a failing actor on other actors in the `Anoma` system.\n7. Write out each bug in full effect.\n8. Provide a summary of the findings with the precieved severity level","ref":"fema-analysis-pinger.html#analysis"},{"type":"extras","title":"Pinger API Tracing - Fema Analysis On the Pinger","doc":"Let us startup the Anoma Environment to run the code in.\n\n```elixir\nalias Anoma.Node.{Mempool, Router, Pinger}\nalias Anoma.Storage\nalias Anoma.Node.Storage.Ordering\nimport TestHelper.Nock\n\nname = :anoma\nnode = Anoma.Node.state(name)\n:all_good\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:all_good\n```\n\nThe Pinger has 2 `public` methods that we can abuse `Anoma.Node.Pinger.start/1` and `Anoma.Node.Pinger.set_timer/2`.\n\nLet use begin by first tracing what all these methods do in depth\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.pinger.server)],\n  fn ->\n    # we should use the router, but pinger is special\n    Pinger.set_timer(node.pinger, 20)\n  end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 0 AS self();\nparticipant 1 AS Anoma.Node.Pinger HFn/uuQ5P5oDd3yBKS2rDz+Nx++XqLKOL+zJdO70aJg=;\n0->>1: CALL: set\n1->>0: INFO: tuple\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\"Timer set to 20\"\n```","ref":"fema-analysis-pinger.html#pinger-api-tracing"},{"type":"extras","title":"In Depth Analysis - Fema Analysis On the Pinger","doc":"Now that we have seen the rough API of the Pinger, let us now look deeper at how the interactions work, and see what we can derive.\n\nThe first bit to note is that `set_timer` does not actually trigger the pinger to start sending\n\nAnalyzing the code, we can see that if **state.time** is set properly, then the pinger will handle a self call of `:execute`.\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.pinger.server)],\n  fn ->\n    # we should use the router, but pinger is special\n    send(Process.whereis(node.pinger.server), :execute)\n    :timer.sleep(1)\n  end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 2 AS Anoma.Node.Mempool 4/XLsEdgkzoiXSBYoBHJexd5ax8K1Sp7feQki1HV45k=;\nparticipant 0 AS self();\nparticipant 1 AS Anoma.Node.Pinger HFn/uuQ5P5oDd3yBKS2rDz+Nx++XqLKOL+zJdO70aJg=;\n0->>1: INFO: execute\n1->>2: CALL: execute\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```","ref":"fema-analysis-pinger.html#in-depth-analysis"},{"type":"extras","title":"Potential Failure Modes - Fema Analysis On the Pinger","doc":"","ref":"fema-analysis-pinger.html#potential-failure-modes"},{"type":"extras","title":"Failure of use around the codebase - Fema Analysis On the Pinger","doc":"","ref":"fema-analysis-pinger.html#failure-of-use-around-the-codebase"},{"type":"extras","title":"Death of the Actor - Fema Analysis On the Pinger","doc":"If the actor dies, then the only effect is that blocks won't be producted like expected.\n\nIn production this is **critical** as the chain will halt.\n\nOn a developer's testing box this is rather benign, as block production should happen on demand, rather than on intervels.","ref":"fema-analysis-pinger.html#death-of-the-actor"},{"type":"extras","title":"Full Details of the Failure modes - Fema Analysis On the Pinger","doc":"","ref":"fema-analysis-pinger.html#full-details-of-the-failure-modes"},{"type":"extras","title":"Summary Of Failures - Fema Analysis On the Pinger","doc":"| Failure States | Severity | Comment                 |\n| -------------- | -------- | ----------------------- |\n| xyz            | low      | important for operation |","ref":"fema-analysis-pinger.html#summary-of-failures"},{"type":"extras","title":"Contributing","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Contributing","ref":"contributing.html"},{"type":"extras","title":"Index - Contributing","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"contributing.html#index"},{"type":"extras","title":"Contributing - Contributing","doc":"Documents in this section cover getting started and contributing back to `Anoma`.\n\nPlease feel free to contribute to these docs and improve them! For tips on how to write documents, please refer to the [Writing Documents](./contributing/writing-documents.livemd)","ref":"contributing.html#contributing"},{"type":"extras","title":"Logging","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Logging","ref":"logging.html"},{"type":"extras","title":"Index - Logging","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"logging.html#index"},{"type":"extras","title":"Logging - Logging","doc":"This document introduces the logging functionality internal to Anoma and showcases some some of its debugging features. First, let us set up a new environment.\n\n```elixir\nalias Anoma.Node.{Ordering, Mempool, Router, Storage}\nimport TestHelper.Nock\n\nstorage = %Storage{\n  qualified: AnomaTest.LoggerDoc.Qualified,\n  order: AnomaTest.LoggerDoc.Order\n}\n\nname = :loggerdoc\nsnapshot_path = [:my_special_nock_snaphsot | 0]\n\n{:ok, nodes} =\n  Anoma.Node.start_link_or_find_instance(\n    name: name,\n    use_rocks: false,\n    settings:\n      {:new_storage,\n       [\n         snapshot_path: snapshot_path,\n         storage_data: storage,\n         block_storage: :dump_blocks,\n         ping_time: :no_timer\n       ]\n       |> Anoma.Node.start_min()}\n  )\n\nnode = Anoma.Node.state(nodes)\n\n:ok\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```","ref":"logging.html#logging"},{"type":"extras","title":"Logger as an Engine - Logging","doc":"The Logger in Anoma is an engine which can be used as the usual logging device via connecting to other engines. The intended use of the Logging engine is to start it alongside the node letting the other engines store its address info. So, e.g. our primary `:anoma` node launched at application startup will have a dedicated Logging engine:\n\n```elixir\nlogger = node.logger\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%Anoma.Node.Router.Addr{\n  server: :\"Anoma.Node.Logger HjryahDk+vQ6qtFk7r6aeydM31heWNXRbSL0uhA+KmI=\",\n  id: %Anoma.Crypto.Id.Extern{\n    encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220, 144,\n      234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n    sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76, 223,\n      88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n  },\n  router: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208,\n        198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>,\n      sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20,\n        146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>\n    },\n    router: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\"\n  }\n}\n```\n\nMoreover, this address will be stored in appropriate fields of other engines such as the Executor:\n\n```elixir\nalias Anoma.Node.Router.Engine\n\nex_logger = Engine.get_state(node.executor).logger\nex_logger == logger\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\ntrue\n```\n\nAs an engine, it has its own dependencies for startup. In particular, we require the Logger having an access to:\n\n1. the Clock engine for timestamping\n2. Storage where we dump the info to\n\n```elixir\nEngine.get_state(logger)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%Anoma.Node.Logger{\n  clock: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Clock NztG/xI1ol8hcLhnaDft5j4nK9tJ0TcI43JiaRQET0g=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<247, 210, 98, 17, 246, 94, 217, 21, 214, 95, 6, 237, 31, 207, 149, 20, 45, 197,\n        197, 146, 40, 3, 198, 20, 242, 136, 62, 8, 172, 242, 0, 91>>,\n      sign: <<55, 59, 70, 255, 18, 53, 162, 95, 33, 112, 184, 103, 104, 55, 237, 230, 62, 39, 43,\n        219, 73, 209, 55, 8, 227, 114, 98, 105, 20, 4, 79, 72>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208,\n          198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>,\n        sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137,\n          20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>\n      },\n      router: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\"\n    }\n  },\n  storage: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Storage PFSZ/7snPaFarWcLK0dDNTlznyAo3F+G+tq1zmNfe+A=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<103, 181, 194, 163, 250, 93, 164, 234, 227, 159, 152, 54, 45, 216, 81, 68, 165, 66,\n        172, 210, 22, 27, 72, 168, 184, 202, 42, 249, 133, 43, 92, 120>>,\n      sign: <<60, 84, 153, 255, 187, 39, 61, 161, 90, 173, 103, 11, 43, 71, 67, 53, 57, 115, 159,\n        32, 40, 220, 95, 134, 250, 218, 181, 206, 99, 95, 123, 224>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208,\n          198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>,\n        sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137,\n          20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>\n      },\n      router: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\"\n    }\n  }\n}\n```","ref":"logging.html#logger-as-an-engine"},{"type":"extras","title":"Logging API - Logging","doc":"The Logger provides functionality to add new and request the stored info using\n\n* `add/3`\n* `get/1`\n* `get/2`\n\nThe `add` function awaits a logger address, an atom specifying the logging urgency and a message accompanying it. The engine then stores it using `Anoma.Storage.put` functionality.\n\n```elixir\nalias Anoma.Node.Logger\n\nLogger.add(logger, :info, \"This is a logger message\")\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nThe `get/1` function awaits a logger address, after which it outputs all the info that the logger has stored:\n\n```elixir\nLogger.get(logger)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.599.0>,\n     12815,\n     :info\n   ], \"This is a logger message\"}\n]\n```\n\nAll elements of the stored info have the same structure: they are 2-tuples. The left element is a list. Its first element is the external ID of our logger, followed by the PID of the process that sent the message (in this case `self`), a timestamp, as well as the supplied atom. The right element is the message.\n\nGenerally it is not the user who sends the logging messages but the engines themselves. Almost every public engine API has some logging that happens during function execution:\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.ordering.server)],\n  fn ->\n    Ordering.next_order(node.ordering)\n  end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 0 AS self();\nparticipant 2 AS Anoma.Node.Logger HjryahDk+vQ6qtFk7r6aeydM31heWNXRbSL0uhA+KmI=;\nparticipant 1 AS Anoma.Node.Ordering J+SRpK9QFPQakfr7mUzFfysUulMbQ9LD+Qc2a7l1uF8=;\n0->>1: CALL: next_order\n1->>2: ADD LEVEL: info\n1->>0: INFO: tuple\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n1\n```\n\nWe can now use `get/2` by using both the Loger address and the address of the engine whose logging info we want to see. This fetches only the info relevant to said engine.\n\n```elixir\nLogger.get(logger, node.ordering)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<88, 234, 42, 32, 205, 162, 194, 238, 222, 188, 180, 222, 111, 108, 226, 209, 156,\n         108, 68, 14, 149, 105, 186, 130, 229, 110, 153, 63, 140, 167, 53, 116>>,\n       sign: <<39, 228, 145, 164, 175, 80, 20, 244, 26, 145, 250, 251, 153, 76, 197, 127, 43, 20,\n         186, 83, 27, 67, 210, 195, 249, 7, 54, 107, 185, 117, 184, 95>>\n     },\n     19392,\n     :info\n   ], \"Requested next order: 1\"}\n]\n```\n\nNote that instead of a PID we now see the external ID of the engine. Logger checks whether what sent the request was a registered engine or some general process which sends a message. In the former case we use the external ID of the engine, in the latter just the PID. We can similarly use `get/2` with a PID instead of an address.\n\n```elixir\nLogger.get(logger, self())\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.599.0>,\n     12815,\n     :info\n   ], \"This is a logger message\"}\n]\n```\n\nWhile the count of all the logging messages is now up to 2:\n\n```elixir\nLogger.get(logger)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<88, 234, 42, 32, 205, 162, 194, 238, 222, 188, 180, 222, 111, 108, 226, 209, 156,\n         108, 68, 14, 149, 105, 186, 130, 229, 110, 153, 63, 140, 167, 53, 116>>,\n       sign: <<39, 228, 145, 164, 175, 80, 20, 244, 26, 145, 250, 251, 153, 76, 197, 127, 43, 20,\n         186, 83, 27, 67, 210, 195, 249, 7, 54, 107, 185, 117, 184, 95>>\n     },\n     19392,\n     :info\n   ], \"Requested next order: 1\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.599.0>,\n     12815,\n     :info\n   ], \"This is a logger message\"}\n]\n```","ref":"logging.html#logging-api"},{"type":"extras","title":"Using the Logger - Logging","doc":"Using the above functionality the user is able to debug the system in case of errors. Here is a trivial example of that based on an existing Mempool test. Suppose the user is testing Mempool capabilities, namely count iteration for block execution. However, they forget to use the zero counter. First the user sets up the Mempool:\n\n```elixir\nkey = 555\nstorage = Ordering.get_storage(node.ordering)\nincrement = increment_counter_val(key)\nMempool.hard_reset(node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nWe then reproduce the setting by incrementing the counter without incrementing using the zero counter and execute. Here we assume the uses simply did not notice that the zero counter has not been submitted.\n\n```elixir\npid_one = Mempool.tx(node.mempool, {:kv, increment}).pid\n\nMempool.execute(node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\n22:25:25.390 [error] Worker failed! :error\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:ok, 1}\n```\n\nWe encounter an error which is signalled by the logger. Namely our worker has failed. Let us check the appropriate worker log:\n\n```elixir\nLogger.get(logger, pid_one)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35620,\n     :error\n   ], \"Worker failed! :error\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35621,\n     :info\n   ],\n   \"Taking snapshot key :my_special_nock_snaphsot in storage %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Storage PFSZ/7snPaFarWcLK0dDNTlznyAo3F+G+tq1zmNfe+A=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<103, 181, 194, 163, 250, 93, 164, 234, 227, 159, 152, 54, 45, 216, 81, 68, 165, 66, 172, 210, 22, 27, 72, 168, 184, 202, 42, 249, 133, 43, 92, 120>>, sign: <<60, 84, 153, 255, 187, 39, 61, 161, 90, 173, 103, 11, 43, 71, 67, 53, 57, 115, 159, 32, 40, 220, 95, 134, 250, 218, 181, 206, 99, 95, 123, 224>>}, router: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208, 198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>, sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\"}}\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35582,\n     :info\n   ], \"Worker dispatched.\\n    Order id: 102439050089106441858870166176275840122\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35620,\n     :info\n   ], \"#PID<0.761.0>: making sure the snapshot is ready\"}\n]\n```\n\nHere we see that the worker has faced errors only at the end of its life-cycle. Before, it was succesfully waiting for the write ready message. Hence the user may try to probe the entire logging keyspace and notice, e.g. that there has only been one worker dispatched throughout the process:\n\n```elixir\nlogger\n|> Logger.get()\n|> Enum.filter(fn {_list, msg} ->\n  String.contains?(msg, \"Worker dispatched\")\nend)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35582,\n     :info\n   ], \"Worker dispatched.\\n    Order id: 102439050089106441858870166176275840122\"}\n]\n```\n\nWe can then probe the logger to check what exact transaction has been submitted:\n\n```elixir\nLogger.get(logger, node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35608,\n     :info\n   ],\n   \"Transaction added. New pool: [%Anoma.Transaction{transaction: {:kv, [[8, [1 | 0], [1, [1 | 555], 4, 12, [1 | 0], [0 | 6], 1, 555 | 0], 0 | 1], [[8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 118], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 238], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 958], 0 | 2], [6, [5, [1 | 0], 0 | 446], [0 | 0], 6, [0 | 3570], [1 | 0], 1 | 1], 1 | 1], 1 | 1], 1 | 1], 0 | 1], 8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 5, [1 | 0], 0 | 446], 0 | 1], [[1 | 0], [8, [1, 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 28], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 181, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 58], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 44, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 118], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 180, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 238], 0 | 2], [8, [7, [0 | 7], 9, 46, 0 | 1], 9, 2, 10, [6, 0 | 478], 0 | 2], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], 6, [5, [1 | 0], 0 | 447], [1 | 0], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [8, [7, [0 | 7], 9, 91, 0 | 1], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 9, 47, 0 | 1], 9, 2, 10, [6, 0 | 28], 0 | 2], [6, [6, [3, 0 | 26], [1 | 1], 1 | 0], [0 | 26], 0 | 0], [6, [6, [3, 0 | 54], [1 | 1], 1 | 0], [0 | 54], 0 | 0], [6, [6, [3, 0 | 110], [1 | 1], 1 | 0], [0 | 110], 0 | 0], [6, [5, [1 | 0], 0 | 222], [1 | 0], 6, [5, [1 | 1], 0 | 222], [1 | 1], 0 | 0], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], [6, [6, [3, 0 | 894], [1 | 1], 1 | 0], [0 | 894], 0 | 0], 6, [6, [3, 0 | 895], [1 | 1], 1 | 0], [0 | 895], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [8, [1 | 0], [1, 8, [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1, 0, 0 | 0], [1, 8, [[6, [6, [3, 0 | 12], [1 | 1], 1 | 0], [0 | 12], 0 | 0], [6, [5, [1 | 0], 0 | 26], [1 | 0], 6, [5, [1 | 1], 0 | 26], [1 | 1], 0 | 0], 6, [6, [3, 0 | 27], [1 | 1], 1 | 0], [0 | 27], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [1 | 0], [0 | 0] | 0], [1, 8, [7, [1 | 0], 8, [1, 0 | 0], [1, 1 | 0], 0 | 1], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[7, [8, [1, 0 | 0], [1, 8, [1, 0 | 0], 8, [1, 6, [6, [5, [1 | 0], 0 | 60], [6, [5, [1 | 0], 0 | 61], [1 | 0], 1 | 1], 1 | 1], [0 | 13], 9, 2, 10, [30, [8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 124], 0 | 2], 8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 125], 0 | 2], 10, [6, [4, 0 | 12], 8, [9, 20, 0 | 511], 9, 2, 10, [6, [0 | 29], 7, [0 | 3], 8, [8, [9, 10, 0 | 63], 9, 90, 10, [6, ...], 0 | 2], 9, 2, 10, [6, [0 | 28], 7, ...], 0 | 2], 0 | 2], 0 | 1], 9, 2, 0 | 1], 0 | 1], 11, [1953718630, 1, 7891309, [0 | 7] | 0], 0 | 1], [[8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [1, 8, [[0 | 50], 0 | 54], [1, 8, [[8, [0 | 60], 9, 2, 10, [6, 0 | 28], 0 | 2], 8, [0 | 61], 9, 2, 10, [6, 0 | 29], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 1], [8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 \" <> ...},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35620,\n     :info\n   ], \"Sending :write_ready to 1 processes\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35578,\n     :info\n   ],\n   \"Requested transaction fire.\\n      Executor: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Executor bMdE8VVjfHe6Cwwf7x7HPnKE4UIk0ppsTRd+3lFCMfo=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<124, 24, 139, 146, 134, 161, 98, 88, 227, 169, 92, 251, 165, 248, 140, 252, 237, 115, 81, 219, 226, 98, 33, 106, 80, 195, 115, 74, 84, 4, 91, 114>>, sign: <<108, 199, 68, 241, 85, 99, 124, 119, 186, 11, 12, 31, 239, 30, 199, 62, 114, 132, 225, 66, 36, 210, 154, 108, 77, 23, 126, 222, 81, 66, 49, 250>>}, router: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208, 198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>, sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\"}}.\\n      Id : 102439050089106441858870166176275840122\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35627,\n     :info\n   ], \"Requested execution\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35619,\n     :info\n   ],\n   \"Producing block. Transsactions: [%Anoma.Transaction{transaction: {:kv, [[8, [1 | 0], [1, [1 | 555], 4, 12, [1 | 0], [0 | 6], 1, 555 | 0], 0 | 1], [[8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 118], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 238], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 958], 0 | 2], [6, [5, [1 | 0], 0 | 446], [0 | 0], 6, [0 | 3570], [1 | 0], 1 | 1], 1 | 1], 1 | 1], 1 | 1], 0 | 1], 8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 5, [1 | 0], 0 | 446], 0 | 1], [[1 | 0], [8, [1, 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 28], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 181, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 58], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 44, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 118], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 180, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 238], 0 | 2], [8, [7, [0 | 7], 9, 46, 0 | 1], 9, 2, 10, [6, 0 | 478], 0 | 2], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], 6, [5, [1 | 0], 0 | 447], [1 | 0], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [8, [7, [0 | 7], 9, 91, 0 | 1], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 9, 47, 0 | 1], 9, 2, 10, [6, 0 | 28], 0 | 2], [6, [6, [3, 0 | 26], [1 | 1], 1 | 0], [0 | 26], 0 | 0], [6, [6, [3, 0 | 54], [1 | 1], 1 | 0], [0 | 54], 0 | 0], [6, [6, [3, 0 | 110], [1 | 1], 1 | 0], [0 | 110], 0 | 0], [6, [5, [1 | 0], 0 | 222], [1 | 0], 6, [5, [1 | 1], 0 | 222], [1 | 1], 0 | 0], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], [6, [6, [3, 0 | 894], [1 | 1], 1 | 0], [0 | 894], 0 | 0], 6, [6, [3, 0 | 895], [1 | 1], 1 | 0], [0 | 895], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [8, [1 | 0], [1, 8, [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1, 0, 0 | 0], [1, 8, [[6, [6, [3, 0 | 12], [1 | 1], 1 | 0], [0 | 12], 0 | 0], [6, [5, [1 | 0], 0 | 26], [1 | 0], 6, [5, [1 | 1], 0 | 26], [1 | 1], 0 | 0], 6, [6, [3, 0 | 27], [1 | 1], 1 | 0], [0 | 27], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [1 | 0], [0 | 0] | 0], [1, 8, [7, [1 | 0], 8, [1, 0 | 0], [1, 1 | 0], 0 | 1], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[7, [8, [1, 0 | 0], [1, 8, [1, 0 | 0], 8, [1, 6, [6, [5, [1 | 0], 0 | 60], [6, [5, [1 | 0], 0 | 61], [1 | 0], 1 | 1], 1 | 1], [0 | 13], 9, 2, 10, [30, [8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 124], 0 | 2], 8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 125], 0 | 2], 10, [6, [4, 0 | 12], 8, [9, 20, 0 | 511], 9, 2, 10, [6, [0 | 29], 7, [0 | 3], 8, [8, [9, 10, 0 | 63], 9, 90, 10, [6, ...], 0 | 2], 9, 2, 10, [6, [0 | 28], 7, ...], 0 | 2], 0 | 2], 0 | 1], 9, 2, 0 | 1], 0 | 1], 11, [1953718630, 1, 7891309, [0 | 7] | 0], 0 | 1], [[8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [1, 8, [[0 | 50], 0 | 54], [1, 8, [[8, [0 | 60], 9, 2, 10, [6, 0 | 28], 0 | 2], 8, [0 | 61], 9, 2, 10, [6, 0 | 29], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 1], [8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, \" <> ...},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35626,\n     :info\n   ],\n   \"New state: %Anoma.Node.Mempool{logger: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Logger HjryahDk+vQ6qtFk7r6aeydM31heWNXRbSL0uhA+KmI=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220, 144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>, sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76, 223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>}, router: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208, 198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>, sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\"}}, key: {[<<1, 0, 1>>, <<178, 121, 76, 200, 168, 235, 151, 217, 13, 146, 94, 167, 184, 24, 103, 4, 71, 232, 222, 187, 242, 43, 201, 206, 9, 72, 38, 141, 71, 183, 193, 79, 96, 47, 11, 197, 9, 79, 186, 87, 134, 20, 214, 119, 17, ...>>], [<<1, 0, 1>>, <<178, 121, 76, 200, 168, 235, 151, 217, 13, 146, 94, 167, 184, 24, 103, 4, 71, 232, 222, 187, 242, 43, 201, 206, 9, 72, 38, 141, 71, 183, 193, 79, 96, 47, 11, 197, 9, 79, 186, 87, 134, 20, 214, 119, ...>>, <<36, 1, 192, 242, 2, 210, 117, 50, 63, 64, 182, 132, 19, 234, 40, 110, 126, 171, 134, 180, 88, 105, 105, 47, 126, 67, 230, 51, 62, 178, 221, 247, 75, 170, 114, 47, 112, 111, 123, 98, 201, 20, 79, ...>>, <<223, 174, 98, 120, 166, 199, 34, 129, 230, 158, 40, 40, 33, 31, 249, 41, 170, 201, 126, 28, 198, 156, 91, 16, 253, 170, 10, 56, 182, 211, 191, 77, 97, 146, 141, 133, 159, 124, 136, 47, 187, 243, ...>>, <<204, 66, 196, 29, 80, 253, 242, 26, 205, 16, 230, 113, 34, 45, 70, 56, 234, 19, 31, 223, 202, 193, 40, 12, 38, 108, 131, 166, 205, 90, 133, 22, 187, 76, 37, 36, 38, 153, 233, 73, 59, ...>>, <<104, 67, 12, 187, 88, 97, 241, 255, 194, 211, 109, 188, 102, 212, 84, 123, 203, 147, 232, 40, 217, 155, 0, 7, 199, 117, 127, 22, 56, 130, 50, 229, 138, 217, 153, 5, 243, 245, 68, 53, ...>>, <<188, 187, 184, 79, 202, 69, 74, 205, 222, 203, 13, 210, 93, 28, 238, 52, 170, 124, 15, 72, 142, 36, 153, 167, 88, 93, 141, 235, 178, 245, 63, 225, 248, 31, 236, 117, 145, 193, 70, ...>>, <<35, 138, 180, 228, 184, 64, 111, 151, 24, 72, 177, 78, 7, 82, 185, 141, 129, 128, 249, 46, 61, 166, 209, 175, 202, 195, 140, 234, 161, 251, 202, 156, 95, 135, 50, 251, 104, 117, ...>>]}, topic: %Anoma.Node.Router.Addr{server: nil, id: %Anoma.Crypto.Id.Extern{encrypt: <<190, 53, 205, 235, 5, 226, 41, 27, 52, 24, 129, 130, 166, 110, 247, 96, 38, 104, 62, 8, 193, 71, 72, 220, 200, 81, 64, 249, 236, 17, 96, 89>>, sign: <<220, 94, 47, 24, 186, 196, 237, 131, 1, 55, 84, 239, 201, 26, 56, 163, 239, 46, 23, 104, 7, 183, 111, 117, 235, 229, 167, 14, 178, 32, 27, 137>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\"}, round: 1, transactions: [], block_storage: :loggerdoc_blocks, executor: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Executor bMdE8VVjfHe6Cwwf7x7HPnKE4UIk0ppsTRd+3lFCMfo=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<124, 24, 139, 146, 134, 161, 98, 88, 227, 169, 92, 251, 165, 248, 140, 252, 237, 115, 81, 219, 226, 98, 33, 106, 80, 195, 115, 74, 84, 4, 91, 114>>, sign: <<108, 199, 68, 241, 85, 99, 124, 119, 186, 11, 12, 31, 239, 30, 199, 62, 114, 132, 225, 66, 36, 210, 154, 108, 77, 23, 126, 222, 81, 66, 49, 250>>}, router: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208, 198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>, sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKg\" <> ...}\n]\n```\n\n```elixir\nlogger\n|> Logger.get(node.mempool)\n|> Enum.filter(fn {_list, msg} ->\n  String.contains?(msg, \"Transaction added\")\nend)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35608,\n     :info\n   ],\n   \"Transaction added. New pool: [%Anoma.Transaction{transaction: {:kv, [[8, [1 | 0], [1, [1 | 555], 4, 12, [1 | 0], [0 | 6], 1, 555 | 0], 0 | 1], [[8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 118], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 238], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 958], 0 | 2], [6, [5, [1 | 0], 0 | 446], [0 | 0], 6, [0 | 3570], [1 | 0], 1 | 1], 1 | 1], 1 | 1], 1 | 1], 0 | 1], 8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 5, [1 | 0], 0 | 446], 0 | 1], [[1 | 0], [8, [1, 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 28], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 181, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 58], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 44, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 118], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 180, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 238], 0 | 2], [8, [7, [0 | 7], 9, 46, 0 | 1], 9, 2, 10, [6, 0 | 478], 0 | 2], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], 6, [5, [1 | 0], 0 | 447], [1 | 0], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [8, [7, [0 | 7], 9, 91, 0 | 1], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 9, 47, 0 | 1], 9, 2, 10, [6, 0 | 28], 0 | 2], [6, [6, [3, 0 | 26], [1 | 1], 1 | 0], [0 | 26], 0 | 0], [6, [6, [3, 0 | 54], [1 | 1], 1 | 0], [0 | 54], 0 | 0], [6, [6, [3, 0 | 110], [1 | 1], 1 | 0], [0 | 110], 0 | 0], [6, [5, [1 | 0], 0 | 222], [1 | 0], 6, [5, [1 | 1], 0 | 222], [1 | 1], 0 | 0], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], [6, [6, [3, 0 | 894], [1 | 1], 1 | 0], [0 | 894], 0 | 0], 6, [6, [3, 0 | 895], [1 | 1], 1 | 0], [0 | 895], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [8, [1 | 0], [1, 8, [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1, 0, 0 | 0], [1, 8, [[6, [6, [3, 0 | 12], [1 | 1], 1 | 0], [0 | 12], 0 | 0], [6, [5, [1 | 0], 0 | 26], [1 | 0], 6, [5, [1 | 1], 0 | 26], [1 | 1], 0 | 0], 6, [6, [3, 0 | 27], [1 | 1], 1 | 0], [0 | 27], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [1 | 0], [0 | 0] | 0], [1, 8, [7, [1 | 0], 8, [1, 0 | 0], [1, 1 | 0], 0 | 1], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[7, [8, [1, 0 | 0], [1, 8, [1, 0 | 0], 8, [1, 6, [6, [5, [1 | 0], 0 | 60], [6, [5, [1 | 0], 0 | 61], [1 | 0], 1 | 1], 1 | 1], [0 | 13], 9, 2, 10, [30, [8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 124], 0 | 2], 8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 125], 0 | 2], 10, [6, [4, 0 | 12], 8, [9, 20, 0 | 511], 9, 2, 10, [6, [0 | 29], 7, [0 | 3], 8, [8, [9, 10, 0 | 63], 9, 90, 10, [6, ...], 0 | 2], 9, 2, 10, [6, [0 | 28], 7, ...], 0 | 2], 0 | 2], 0 | 1], 9, 2, 0 | 1], 0 | 1], 11, [1953718630, 1, 7891309, [0 | 7] | 0], 0 | 1], [[8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [1, 8, [[0 | 50], 0 | 54], [1, 8, [[8, [0 | 60], 9, 2, 10, [6, 0 | 28], 0 | 2], 8, [0 | 61], 9, 2, 10, [6, 0 | 29], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 1], [8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 \" <> ...}\n]\n```\n\nAssuming the user knows the Nock code for increments and zero counters, they will be able to determine why the error occured exactly.\n\nHere we have showcased several ways in which the Logging engine can be used. It sends error messages directly to the user when encountered, stores major info re worker and engine actions, as well as allowing the user to prompt the logging messages using the usual filtering mechanisms.\n\nNote that the logging functionality is easily added into working engines and hence the contributors can readily add more detailed logging at their convenience. Similarly, the keyspace storing can be more thorought, containing more info on the sending agents. Moreover, note that the better the user is acquainted with the actual logging messages, the more efficient the debigging.","ref":"logging.html#using-the-logger"},{"type":"extras","title":"TOC","doc":"# TOC","ref":"toc.html"},{"type":"extras","title":"Index - TOC","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"toc.html#index"},{"type":"extras","title":"TOC - TOC","doc":"This notebook organizes a set of lessons to help you get started with Anoma!\n\nThis book uses livebook, it is best viewed from within it! However most sections can be viewed fine in github or your text editor.","ref":"toc.html#toc"},{"type":"extras","title":"User","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# User","ref":"user.html"},{"type":"extras","title":"Index - User","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"user.html#index"},{"type":"extras","title":"User Guide - User","doc":"Welcome to the Anoma documentation for users.\n\nThese documents contain pertinent information about your local Anoma node.","ref":"user.html#user-guide"},{"type":"extras","title":"Data","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Data","ref":"data.html"},{"type":"extras","title":"Index - Data","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"data.html#index"},{"type":"extras","title":"Where Anoma saves State - Data","doc":"Anoma follows [XDG](https://en.wikipedia.org/wiki/Freedesktop.org) conventions for state stored on the operating system:\n\n1. Database dumps and Database tables are stored in `$XDG_DATA_HOME/anoma_env`\n2. Configuration files are stored in `$XDG_CONFIG_HOME/anoma_env`","ref":"data.html#where-anoma-saves-state"},{"type":"extras","title":"Configuration Files - Data","doc":"Currently Anoma stores a file `config.toml` with minimal settings for your Anoma node.","ref":"data.html#configuration-files"},{"type":"extras","title":"Configuration Format - Data","doc":"TODO write about each field or link to a relavent section","ref":"data.html#configuration-format"},{"type":"extras","title":"Sending in a custom configuration file - Data","doc":"TODO explain how to do this","ref":"data.html#sending-in-a-custom-configuration-file"},{"type":"extras","title":"Data Files - Data","doc":"Anoma stores a few different files in the `$XDG_DATA_HOME`\n\n1. [Mnesia](https://en.wikipedia.org/wiki/Mnesia) tables backed by [RocksDB](https://en.wikipedia.org/wiki/RocksDB)\n2. Anoma dump files.\n\nThe `dump` file contains all information necessary to restore `Anoma` to the time when the `dump` command was used on `Anoma`.\n\nBeware this will overwrite the local [Mnesia](https://en.wikipedia.org/wiki/Mnesia) tables.\n\nThe Mnesia tables are created every time one runs Anoma.\n\nThese Mnesia tables contain chain information that the Anoma execution environment can query.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nTo learn more about our data format, please checkout the developer's section on [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd).","ref":"data.html#data-files"},{"type":"extras","title":"Launching with a given dump file - Data","doc":"TODO write how to send in the CLI arguments to restore a dump","ref":"data.html#launching-with-a-given-dump-file"},{"type":"extras","title":"Anoma VM interface","doc":"# Anoma VM interface","ref":"vm_interface.html"},{"type":"extras","title":"Index - Anoma VM interface","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"vm_interface.html#index"},{"type":"extras","title":"The Executor context - Anoma VM interface","doc":"The Executor context proceeds according to one of several modes:\n\n* `kv` mode: updates keys in a simple key-value store, and\n* `rm` mode: assembles resource machine transactions to be passed to the\n  resource machine context.\n\nAn additional mode is planned for the shielded resource machine, when\nintegrated; and `kv` mode is an early prototype of what will evolve into\nthe content-addressed blob storage facility.\n\n`kv` and `rm` modes share the same execution interface: they expect a Nock\n`gate`. A `gate` is a function-like object with the following form:\n\n```\n[code [sample context]]\n```\n\n`code` is a Nock formula intended to be run with the gate as subject, while\n`sample` is a placeholder for arguments to the gate. `context` contains any\nadditional code or data referenced; this includes at least the standard\nlibrary, but may be larger than it.\n\nIn both `kv` and `rm` modes, the submitted transaction is a gate, and the\nargument placed in the sample is its opaque order ID. The output expected\nis the following tuple:\n\n```\n[[read-keyspaces write-keyspaces] second-gate]\n```\n\nIn `kv` mode, `read-keyspaces` and `write-keyspaces` are subspaces of the\nkey-value store which the transaction plans to read or write, respectively.\nThe VM may use this information to place locks or otherwise prepare for\ntransaction execution. It is an error to read outside the declared\n`read-keyspaces` or write outside the declared `write-keyspaces`\n\nIn `rm` mode, `read-keyspaces` and `write-keyspaces` are always the entire\n`rm` keyspace. Every `rm` transaction updates the commitment and nullifier\ntrees.\n\nThe scry operation is illegal in the execution of the first gate, because\nthe transaction has not declared its read locks yet.\n\nThe second gate may perform the scry operation. It is more properly termed\na `trap` as it takes no arguments. However, its scries are restricted to\nthe `read-keyspaces` returned along with it.\n\nThe scry operation blocks until its read lock is released by the VM. It may\nfail, causing the whole transaction to fail, if it reads an invalid or\ndisallowed key.\n\nThe second gate's output is a list of key-value pairs to update in `kv`\nmode, and a resource machine transaction in `rm` mode.","ref":"vm_interface.html#the-executor-context"},{"type":"extras","title":"The Resource Machine context - Anoma VM interface","doc":"When the VM's resource machine implementation processes a resource\ntransaction, this includes the execution of resource logics in each\nresource. Shielded resource transactions will proceed similarly, but\nwithin the shielded VM rather than the Nock VM.\n\nA resource logic is also a gate, and the arguments it takes are the tuple\n\n```\n[self resource-transaction]\n```\n\nwhere `self` is a copy of the entire resource running the logic, and\n`resource-transaction` is the Nock serialization of the entire resource\ntransaction (which includes all resources, in the transparent resource\nmachine).\n\nIts output is a simple boolean: `0` for success, `1` for failure.","ref":"vm_interface.html#the-resource-machine-context"},{"type":"extras","title":"Gas metering - Anoma VM interface","doc":"All Nock execution is metered simply: starting with a meter value of 0,\nincrementing by 1 for each recursion back into simple Nock evaluation,\nand incrementing by a defined per-jet constant for each jet invoked.","ref":"vm_interface.html#gas-metering"},{"type":"extras","title":"Examples over Testing","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Examples over Testing","ref":"examples-over-testing.html"},{"type":"extras","title":"Index - Examples over Testing","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"examples-over-testing.html#index"},{"type":"extras","title":"Intro - Examples over Testing","doc":"In complex software projects, there are a variety of automated tools employed to make sure the system works as intended. The two most popular examples are `tests` and `type systems`. As of the time of this writing, the `Anoma` codebase has embraced both of these; having a `73%` test coverage and the majority of functions with type signatures!\n\nThis article will focus on the downside of `testing` in elixir, and give a compelling argument for `examples` over testing!","ref":"examples-over-testing.html#intro"},{"type":"extras","title":"What are Examples - Examples over Testing","doc":"The word `testing` in the context of software development is widely understood, however the term `examples` does not have the same level of recognition.\n\nIn order to clarify the meaning within `Anoma`, we will take [Glamorous Toolkit](https://gtoolkit.com/)'s definition of example, as they have created a well-thought-out system that successfully replaces most `tests` with `examples`\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n[According to Glamorous Toolkit examples are](https://book.gtoolkit.com/examples-6k9vwuau8psg5ghsgb64zriih):\n\n\"a way of demonstrating how to use the system and check that it is operating correctly.\n\nThey are similar to SUnit tests in that they make assertions to confirm that the system is operating correctly, but unlike SUnit tests, which typically don't return anything, they answer an object which is useful in its own right.\"\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFor the purposes of discussion, we can consider [SUnit](https://en.wikipedia.org/wiki/SUnit) and [ExUnit](https://hexdocs.pm/ex_unit/ExUnit.html) to be the same. Meaning that there are large overlaps in the practical function between `examples` and `tests`.","ref":"examples-over-testing.html#what-are-examples"},{"type":"extras","title":"Downsides of testing in Elixir - Examples over Testing","doc":"To get a feeling for what `examples` can offer the codebase, we should first discuss the downsides with how `Anoma` interacts with tests.\n\n1. Tests are not loaded into `IEx` at startup.\n2. To run tests by hand, we need to copy paste:\n   1. Imports.\n   2. `setup_all` logic.\n   3. the test up until the point we care about.\n3. Tests can't be abstracted in the test module without breaking copy and pasting.\n4. Tests can't have dialyzer run over them.\n5. `IEx` does not re-run tests on demand, one has to recompile the test after already running the tests\n6. [LSP](https://en.wikipedia.org/wiki/Language_Server_Protocol) seems to not be able to calculate references of values to tests due to them not being compiled.","ref":"examples-over-testing.html#downsides-of-testing-in-elixir"},{"type":"extras","title":"How would Examples work in Elixir? - Examples over Testing","doc":"Before we go and talk about addressing the issues with testing, let us first envision how we would go about making examples. Below are rules that we can apply to creating our very first examples.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n1. They belong in a module `example/e `. Where `module-name` is the module one is interested in testing.\n2. Any piece of logic that is relied upon by other parts, is an example.\n3. If any code spawns actors, they should either register themselves or be memoized.\n4. We should run asserts on data whenever possible.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFor demonstration purposes, let us take the most common kinds of tests we have and imagine what they would look like as examples\n\n1. The first kind of test is testing non actors.\n2. The second kind of test is testing stateful actors.\n\nTests in the first category tend to care about the form of data and making assertions about said data, while the second category is more about testing the interactions between multiple actors and the final state they produce.\n\nThe translation of tests in classification `2.` into examples can be split into two phases:\n\n1. The first phase will cover translating the `setup` state as global examples. This is not perfect but maintains the same semantics as the test.\n2. The second phase will make the global setup logic specific per example, making stateful examples return the final network state.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"examples-over-testing.html#how-would-examples-work-in-elixir"},{"type":"extras","title":"Examplifying non Actors - Examples over Testing","doc":"A good example we can use, is a test in our `resource` test file.\n\n```elixir\ndefmodule AnomaTest.Resource do\n  test \"commitments and nullifiers\" do\n    keypair_a = Sign.new_keypair()\n    keypair_b = Sign.new_keypair()\n\n    a_r1 = new_with_npk(keypair_a.public)\n    a_r2 = new_with_npk(keypair_a.public)\n    b_r0 = new_with_npk(keypair_b.public)\n\n    # just in case\n    assert a_r1 != a_r2\n\n    c_a_r1 = commitment(a_r1)\n    c_a_r2 = commitment(a_r2)\n    c_b_r0 = commitment(b_r0)\n\n    n_a_r1 = nullifier(a_r1, keypair_a.secret)\n    n_a_r2 = nullifier(a_r2, keypair_a.secret)\n    n_b_r0 = nullifier(b_r0, keypair_b.secret)\n\n    assert c_a_r1 |> commits_to(a_r1)\n    refute c_a_r1 |> commits_to(a_r2)\n    refute c_a_r1 |> commits_to(b_r0)\n\n    refute c_a_r2 |> commits_to(a_r1)\n    assert c_a_r2 |> commits_to(a_r2)\n    refute c_a_r2 |> commits_to(b_r0)\n\n    refute c_b_r0 |> commits_to(a_r1)\n    refute c_b_r0 |> commits_to(a_r2)\n    assert c_b_r0 |> commits_to(b_r0)\n\n    assert n_a_r1 |> nullifies(a_r1)\n    refute n_a_r1 |> nullifies(a_r2)\n    refute n_a_r1 |> nullifies(b_r0)\n\n    refute n_a_r2 |> nullifies(a_r1)\n    assert n_a_r2 |> nullifies(a_r2)\n    refute n_a_r2 |> nullifies(b_r0)\n\n    refute n_b_r0 |> nullifies(a_r1)\n    refute n_b_r0 |> nullifies(a_r2)\n    assert n_b_r0 |> nullifies(b_r0)\n  end\n\n  test \"nullify with wrong key\" do\n    keypair_a = Sign.new_keypair()\n    keypair_b = Sign.new_keypair()\n\n    a_resource = new_with_npk(keypair_a.public)\n    wrong_nullifier = nullifier(a_resource, keypair_b.secret)\n\n    refute wrong_nullifier |> nullifies(a_resource)\n  end\nend\n```\n\nThe crux of this module is creating some resources, and testing that they behave properly!\n\nHowever since tests are not composable, we have to waste time recreating more resources in another test!\n\nIf we were to reimagine this test as an example it would look something like this.\n\n```elixir\ndefmodule Example.EResource do\n  # Memoize it as we want it to always be the same!\n  defmemo(keypair_a(), do: Sign.new_keypair())\n  defmemo(keypair_b(), do: Sign.new_keypair())\n\n  # new_with_npk gives new resources, so memo again\n  defmemo(a_resource(), do: new_with_npk(keypair_a().public))\n  defmemo(b_resource(), do: new_with_npk(keypair_b().public))\n  defmemo(a2_resource(), do: new_with_npk(keypair_a().public))\n\n  # Now we get interesting\n  def commit_a() do\n    commitment = commitment(a_resource())\n    assert commitment |> commits_to(a_resource())\n    refute commitment |> commits_to(b_resource())\n    commitment\n  end\n\n  def commit_a2() do\n    commitment = commitment(a2_resource())\n    assert commitment |> commits_to(a2_resource())\n    refute commitment |> commits_to(a_resource())\n    assert commitment != commit_a()\n    commitment\n  end\n\n  def commit_b() do\n    commitment = commitment(a2_resource())\n    assert commitment |> commits_to(b_resource())\n    refute commitment |> commits_to(a_resource())\n    commitment\n  end\n\n  def nullifier_a() do\n    nullifier = nullifies(a_resource(), keypair_a().private)\n    assert nullifier |> nullifies(a_resource())\n    refute nullifier |> nullifies(b_resource())\n    nullifier\n  end\n\n  def nullifier_a2() do\n    nullifier = nullifies(a_resource(), keypair_a2().private)\n    assert nullifier |> nullifies(a2_resource())\n    refute nullifier |> nullifies(a_resource())\n    assert nullifier != nullifier_a()\n    nullifier\n  end\n\n  def nullifier_b() do\n    nullifier = nullifies(b_resource(), keypair_b().private)\n    assert nullifier |> nullifies(b_resource())\n    refute nullifier |> nullifies(a_resource())\n    nullifier\n  end\n\n  def invalid_nullifier() do\n    nullifier = nullifies(a_resource(), keypair_b().private)\n    refute nullifier |> nullifies(a_resource())\n    nullifier\n  end\nend\n```\n\nAlthough this code is `5` more lines of code, it has many strong properties:\n\n1. Each component is now a top level name. Meaning we can now play with `nullifier_a` in `IEx`. No copy and pasting needed!\n2. We can add type signatures for each definition, to ensure we have type checking and writing down our own intents!\n3. We didn't need to unnecessarily generate extra keys, and resources. We can reuse them!\n4. We are writing properties about the data we wish to have.\n5. Any other example files can rely on this example file! (hint maybe our next example will use this one)\n\nPoint `4.` should be expanded upon. In a test, one is testing many things at once, but what makes examples strong is that we are denoting the dynamic properties we wish data to respect! Because we are doing this on a data basis, it becomes easy to later come back to these and add new facts to the examples.\n\nTests discourage this, as they have a singular purpose they exist for, they do not encourage good behavior!\n\nFurther, if we were to not do a 1 to 1 extraction, we could factor some of the data here to `Signature` examples as well! We will see how this principle works out in practice in the next section.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"examples-over-testing.html#examplifying-non-actors"},{"type":"extras","title":"Examplifying stateful code - Examples over Testing","doc":"```elixir\ndefmodule AnomaTest.Node.Executor.Worker do\n  use ExUnit.Case, async: true\n\n  setup_all do\n    storage = %Storage{\n      qualified: AnomaTest.Worker.Qualified,\n      order: AnomaTest.Worker.Order\n    }\n\n    {:ok, router, _} = Anoma.Node.Router.start()\n\n    {:ok, storage} =\n      Anoma.Node.Router.start_engine(router, Storage, storage)\n\n    {:ok, ordering} =\n      Anoma.Node.Router.start_engine(router, Ordering, table: storage)\n\n    snapshot_path = [:my_special_nock_snaphsot | 0]\n\n    env = %Nock{snapshot_path: snapshot_path, ordering: ordering}\n\n    [env: env]\n  end\n\n  test \"worker evaluates resource transaction\", %{env: env} do\n    import Anoma.Resource\n    alias Anoma.Resource.ProofRecord\n    alias Anoma.Resource.Transaction\n\n    id = System.unique_integer([:positive])\n\n    storage = Ordering.get_storage(env.ordering)\n\n    Storage.ensure_new(storage)\n    Ordering.reset(env.ordering)\n\n    keypair = Anoma.Crypto.Sign.new_keypair()\n\n    in_resource = %{\n      new_with_npk(keypair.public)\n      | label: \"space bucks\",\n        quantity: 10\n    }\n\n    nf_in = nullifier(in_resource, keypair.secret)\n    pf_in = ProofRecord.prove(in_resource)\n\n    out_resource = %{\n      new_with_npk(keypair.public)\n      | label: \"space bucks\",\n        quantity: 10\n    }\n\n    cm_out = commitment(out_resource)\n    pf_out = ProofRecord.prove(out_resource)\n\n    rm_tx = %Transaction{\n      commitments: [cm_out],\n      nullifiers: [nf_in],\n      proofs: [pf_in, pf_out],\n      delta: %{}\n    }\n\n    rm_tx_noun = Transaction.to_noun(rm_tx)\n    rm_executor_tx = [[1 | rm_tx_noun], 0 | 0]\n\n    spawn = Task.async(Worker, :run, [id, {:rm, rm_executor_tx}, env])\n    Ordering.new_order(env.ordering, [Order.new(0, id, spawn.pid)])\n\n    send(spawn.pid, {:write_ready, 0})\n    assert :ok == Task.await(spawn)\n  end\nend\n```\n\nThis test has a few parts, one part is a `test_setup` and another part is the actual testing code itself.\n\nI will reimagine this module in two phases. The first respecting the fact that `setup_all` is unique and is efficient as it spawns only 1 network for the entire module. The second will instead make the node specific to each example that relies upon it. Returning the network as the interesting object.\n\n```elixir\ndefmodule Example.Worker.Phase1 do\n\n  defmemo router() do\n    assert {:ok, router, _} = Router.start()\n    router\n  end\n\n  def raw_storage() do\n    storage = %Storage{\n      qualified: AnomaTest.Worker.Qualified,\n      order: AnomaTest.Worker.Order\n    }\n  end\n\n  defmemo storage() do\n     {:ok, storage} = Router.start_engine(router(), Storage, raw_storage())\n     storage\n  end\n\n  defmemo ordering() do\n    {:ok, ordering} = Router.start_engine(router(), Ordering, table: storage())\n     ordering\n  end\n\n  def env() do\n   %Nock{snapshot_path: Enock.snapshot_path(), ordering: ordering}\n  end\n\n  # Let's get an unique number\n  defmemo unique_id() do\n    System.unique_integer([:positive])\n  end\n\n  def successfully_fire_trans() do\n    Storage.ensure_new(storage())\n    Ordering.reset(ordering())\n\n    spawn = Task.async(Worker, :run, [id, {:rm, space_trans_candidate()}, env()])\n    Ordering.new_order(ordering(), [Order.new(0, id, spawn.pid)])\n\n    send(spawn.pid, {:write_ready, 0})\n    assert :ok == Task.await(spawn)\n    :ok\n  end\nend\n\ndefmodule Example.ProofRecord do\n  def proved_spacebucks_a() do\n    ProofRecord.prove(Eresource.space_bucks_10_a())\n  end\n\n  def proved_spacebucks_b() do\n    ProofRecord.prove(Eresource.space_bucks_10_b())\n  end\nend\n\ndefmodule Example.Transaction do\n  def balanced_space_transaction() do\n    trans = %Transaction{\n      commitments: [EResource.commitment_space_bucks_a()]\n      nullifiers: [ERsource.nullifier_space_bucks_b()],\n      proofs: [proved_spacebucks_a(), proved_spacebucks_b()]\n    }\n    # This wans't in the original test!\n    assert verify(trans)\n    trans\n  end\n\n  def space_trans_candidate() do\n    Transaction.to_noun(balanced_space_transaction())\n    [[1 | rm_tx_noun], 0 | 0]\n  end\nend\n```\n\nNotice we ended up calling a lot of examples from `EResource`. Some of the examples already existed even without this test (we really had `spacebucks` already in the codebase! Duplicated in the `Worker` and in `Resource`).\n\nFurther most of the logic that recreates `resources` are better placed in the actual `Example.EResource` file, as they are relevant examples for someone who is looking for resources. Why would they look at the worker to see examples of the Resources? Likewise, people who are looking at the worker code, would want to look at worker logic, not resource logic!\n\nWe can see the benefits examples offer even stateful tests:\n\n1. Most of the boilerplate of creating unrelated types are confined in the proper modules!\n2. There may be an example off hand which satisfies what we want (we already had spacebucks in `EResource`)\n3. Rephrasing a test as an example doesn't lose any information. the actual example is simply not interesting!\n4. We can run the stateful tests from IEx and even pry into it without any issues!\n\nWith these benefits of mind let us see if `Phase2` can improve point `3.` a bit:\n\n```elixir\ndefmodule Example.Worker.Phase2 do\n  def router() do\n    assert {:ok, router, _} = Router.start()\n    router\n  end\n\n  def raw_storage() do\n    storage = %Storage{\n      qualified: AnomaTest.Worker.Qualified,\n      order: AnomaTest.Worker.Order\n    }\n  end\n\n  def storage(router) do\n    {:ok, storage} = Router.start_engine(router, Storage, raw_storage())\n    storage\n  end\n\n  def ordering(router, storage) do\n    {:ok, ordering} = Router.start_engine(router, Ordering, table: storage)\n    ordering\n  end\n\n  def env(ordering) do\n    %Nock{snapshot_path: Enock.snapshot_path(), ordering: ordering}\n  end\n\n  def network() do\n    router = router()\n    storage = storage(router)\n    %Node{router: router, ordering: ordering(router, storage), storage: storage}\n  end\n\n  # Let's get an unique number\n  defmemo unique_id() do\n    System.unique_integer([:positive])\n  end\n\n  def successfully_fire_trans() do\n    net = network()\n    env = env(net.ordering)\n    spawn = Task.async(Worker, :run, [id, {:rm, space_trans_candidate()}, env])\n    Ordering.new_order(net.ordering, [Order.new(0, id, spawn.pid)])\n\n    send(spawn.pid, {:write_ready, 0})\n    assert :ok == Task.await(spawn)\n    net\n  end\nend\n```\n\nIn Phase2 we abstracted out some examples, so that they are no longer standalone examples.\n\nSadly `storage`, `router`, `env` and `ordering` are no longer examples, but are generator functions for the data we care about. (maybe we can restore this somehow!)\n\nHowever, notice that the return of `sucessfully_fire_trans/0`, now returns the network!\n\nThis means that if we wanted, we can use this environment for further tests. Such as making sure nullifiers don't insert twice\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\ndef failed_trans() do\n  net = succesfully_fire_trans()\n  env = env(net.ordering)\n  spawn = Task.async(Worker, :run, [id, {:rm, space_trans_candidate()}, env])\n  Ordering.new_order(net.ordering, [Order.new(0, id, spawn.pid)])\n  assert :error == Task.await(spawn)\n  for nullifier <- space_trans_candidate().nullifiers do\n    assert in_nullifer_set(env, nullifier)\n  end\n  net\nend\n```\n\nBesides reuse we get the following advantages in `Phase2`:\n\n1. If we had visualization tooling, we can take the result of `successfully_fire_trans/0` and view all the views of the data. Meaning that if we made tooling that charts simulated latency, connected node graphs, successful and failed transactions, we would be able to chart them all and visually see the difference between this one and `failed_trans/0`.\n2. We can inspect the state of the network querying for new facts we did not know about before. And consider if any facts are interesting enough to assert that the property holds in the particular example.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"examples-over-testing.html#examplifying-stateful-code"},{"type":"extras","title":"Temporary Setbacks - Examples over Testing","doc":"One small annoyance, is that in order to run the tests, we have to currently by hand put the examples in a test file to make sure they are ran.\n\nThis can be offset by a macro that scrapes the examples modules and automatically registers the tests. So this is not a hard issue for the `example` style.","ref":"examples-over-testing.html#temporary-setbacks"},{"type":"extras","title":"Addressing testing issues - Examples over Testing","doc":"Now that we have a concrete idea of what `examples` look like, let us see how they fix our problems with tests:\n\n1. Tests are not loaded into `IEx` at startup.\n   * They are in the lib folder, they are loaded!\n2. To run tests by hand, we need to copy paste:\n   * No copy and pasting required, we can pry and avoid copy and paste!\n3. Tests can't be abstracted in the test module without breaking copy and pasting.\n   * We can abstract as much as we want\n4. Tests can't have dialyzer run over them.\n   * We can run dialyzer and even type our examples!\n5. `IEx` does not re-run tests on demand, one has to recompile the test after already running the tests\n   * We can re-run the example whenever we want\n6. [LSP](https://en.wikipedia.org/wiki/Language_Server_Protocol) seems to not be able to calculate references of values to tests due to them not being compiled.\n   * LSP should work as it's compiled like everything else.","ref":"examples-over-testing.html#addressing-testing-issues"},{"type":"extras","title":"Outstanding questions - Examples over Testing","doc":"The most straight forward strategy would be:\n\n1. Take each test module and convert it to tests.\n2. Once most of the modules are done, convert all stateful tests into `phase2`.\n\nHowever there are open questions:\n\n1. How slow is node setup? Will `phase2` make tests run longer than 2 seconds (unacceptable)?\n2. How long until we have a macro that auto registers the examples so they can be ran with `mix test`?\n3. How will our usage of `examples` evolve over time?\n4. How to deal with tests that make socket files then deletes them after all is done? Will Phase2 make this question obsolete?\n5. Can the process be improved? [One of the Authors of GT has a paper about converting `JUnit` to `JExample`. This can probably inform our own transition and ideas on creating examples](https://scg.unibe.ch/archive/masters/Haen09a.pdf)","ref":"examples-over-testing.html#outstanding-questions"},{"type":"extras","title":"Git","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Git","ref":"git.html"},{"type":"extras","title":"Index - Git","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"git.html#index"},{"type":"extras","title":"Git - Git","doc":"Git is a decent version control(VC) system, however there are ways to\nmake the VC process a lot smoother.\n\nThis document is best viewed from within liveview, as the charts do not render on github currently.","ref":"git.html#git"},{"type":"extras","title":"Terminology - Git","doc":"* `topic` - this is any branch that serves to fix some problem in the\n  codebase\n\n* `feature` - some new concept to the codebase. Many topics can serve\n  to fulfill one feature.\n\n* `release` - A release of the code. This is a git `tag` on `main`\n  that signifies a new version of the software. This typically bumps\n  base to the latest release as well\n\n* `base` - the base branch one should base work off of\n\n* `main` - sometimes called `master`, is the branch that prepares for\n  a release.\n\n* `next` - a branch that has a superset of features that will be\n  included in the next release\n\n* `maint` - a maintnance branch that will be updated if bugs are found\n\n* `integreation branch` - a topic that merges a bunch of other topics","ref":"git.html#terminology"},{"type":"extras","title":"Naming conventions - Git","doc":"Name your topic like `name/feature` to avoid clashing with other\npeople's topics.\n\nThere are some standard branches that do not follow this pattern but\nthose are described in the `Terminology` section of this document","ref":"git.html#naming-conventions"},{"type":"extras","title":"General Principles - Git","doc":"These are some general principles which should help maintainers easily\nintegrate your code, and have your work help out other devs on the\ncodebase.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#general-principles"},{"type":"extras","title":"Do not include unrelated changes into your commits - Git","doc":"* For example, if you see some unrelated bug in the same file as your\n  own, don't fix it in your general commit, make a new topic based on\n  when the bug was introduced and merge that into your topic if it\n  impacts your topic.\n\n* This makes reviewing much easier as the reviewer can read your\n  commit message and see changes only related to that included\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#do-not-include-unrelated-changes-into-your-commits"},{"type":"extras","title":"Make topics early and often! - Git","doc":"This allows your work to be incrementally integrated into a\nrelease. If you put all your work into one topic, bug fixes and all,\nthen the following will occur\n\n1. The changes will not be reviewed properly\n\n   * On big projects with tight deadlines, sometimes some feature\n     *X* is wanted. However if *X* is a single topic with a messy\n     history, the only options are either to scrap the feature or\n     accept it as is poor code in all.\n   * If this was properly split up parts of *X* could be merged\n     now, with the more controversial features being held up in\n     *next*, without having to sacrifice the quality of the\n     codebase.\n\n2. Other team members can not share similar work\n\n   * Often a lot of different tasks, may find the same\n     deficiencies in the codebase.\n\n   * For a real example, let's take the following commit and topic\n\n     ```example\n     802ab9e * anoma/mariari/nock-testing-file Move the helper functions\n     73bfd7d * v0.3.0\n      2 files changed, 44 insertions(+), 34 deletions(-)\n     lib/test_helper/nock.ex | 43 +++++++++++++++++++++++++++++++++++++++++++\n     test/nock_test.exs      | 35 +----------------------------------\n     ```\n\n     Here we find that we `mariari` moved some testing functions from\n     `test/` to `lib/`, as elixir tests don't share code in the best\n     way. This allows other files in `test/` to reuse the same\n     functions that were previously found in `test/nock_test.exs`.  In\n     fact there are multiple topics that ended up using this. Both the\n     executor topic and worker topic\n\n     * `8de0c7e anoma/mariari/worker`\n       * `1d6bc99 anoma/mariari/executor`\n\n     both needed this. Since the worker relies upon the executor,\n     they both don't merge in this topic separately, but if they\n     were separate they would want to share this change.\n\n* If these changes were orchestrated by different people, then\n  they would have made this change twice! Meaning that in the git\n  history the work has been done in different commits! This means\n  that when it comes time to merge in work, there will be a\n  conflict between these two. Rather than being able to reuse\n  other's work and save other devs time, this will come up when\n  reviewers read the code, with unrelated changes, or when the\n  maintainers try to merge things together and find annoying\n  conflicts\n\n1. Work can not be incrementally included\n2. Others might just do the work before you\n\n* If one is too slow on finishing their topic and making it one big\n  commit, then someone else might redo the same work and put it up\n  for review, but instead of them reusing your code, they wrote it\n  from scratch, wasting both your time and their time.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#make-topics-early-and-often"},{"type":"extras","title":"Base topics on base - Git","doc":"Basing code on `main` has the following errors:\n\n1. Code merged in main before a release may turn out to have issues\n2. Git merges and conflict resolutions lead to spurious base points\n3. Other topics can not reuse your code\n4. Useless temporal history is had\n\nBasing on someone's topic that you require and will merge in anyways\nis fine.\n\n<!-- livebook:{\"break_markdown\":true} -->","ref":"git.html#base-topics-on-base"},{"type":"extras","title":"Code merged in main before a release may turn out to have issues - Git","doc":"Imagine main has the following history\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'base'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch Topic-Y\ncommit id: \"4381bd3\"\ncheckout base\nmerge Topic-Y id: \"52b44a6\"\n```\n\nand your code hapens to be base on 52b44a6, then the history will look something like:\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'my-cool-feature'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch Topic-Y\ncommit id: \"4381bd3\"\ncheckout my-cool-feature\nmerge Topic-Y id: \"52b44a6: main merge feature-y\"\ncommit id: \"7dabf44\"\n```\n\nLater before a release, we find out that *Topic-Y* has issues, and any\ncode that is based on *Topic-Y* will have to sit this release\nout. Normally to check for this, the protocol is quite simple we just:\n\n1. Do not include any topics that are based on *Topic-Y* or merges\n   *Topic-Y* into the release\n2. Pull any topic based on *Topic-Y* from `main`\n\nbecomes muddied, as if one's topic was based on `main` after *Topic-Y*\nis in, then it's unclear if that topic is unaffected.\n\nThus *my-cool-feature* may be cut from the release, even if it was\nperfectly fine and did not rely on *Topic-Y*.\n\n<!-- livebook:{\"break_markdown\":true} -->","ref":"git.html#code-merged-in-main-before-a-release-may-turn-out-to-have-issues"},{"type":"extras","title":"Git merges and conflict resolutions lead to spurious base points - Git","doc":"Further, if we have two topics *my-feature-x* and *my-feature-y* based\non `main`, then the history would look something like this\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'base'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch main\nbranch ray/mnesia-attach\ncommit id: \"97bef7\"\ncheckout main\nmerge ray/mnesia-attach id: \"13b3e4a\"\n\n\ncheckout base\nbranch proper-topic\ncommit id: \"8087564: add a new feature\"\n\ncheckout main\nbranch topic-x\ncommit id: \"bc4b2a1: new cool feature\"\n\ncheckout main\nmerge proper-topic id: \"2dd991a\"\n\ncheckout main\nbranch topic-y\ncommit id: \"546a8f9: add feature: conflicts X!\"\n\ncheckout main\nmerge topic-x id: \"90d91e7\"\nmerge topic-y id: \"0438922\"\n```\n\nIn a textual form this looks like:\n\n```\n0438922 *   main Merge branch 'topic-y'\n        |\\\n546a8f9 | * topic-y Added a feature that conflcits with X!\n90d91e7 * |   Merge branch 'topic-x'\n        |\\ \\\n        | |/\n        |/|\nbc4b2a1 | * topic-x Added a cool feature\n2dd991a * |   Merge branch 'proper-topic'\n        |\\ \\\n        | |/\n        |/|\n8087564 | * proper-topic Add a new feature\n13b3e4a * |   Merge branch 'ray/mnesia-attach'\n        |\\ \\\n        | |/\n        |/|\n97b6ef7 | * ray/mnesia-attach mnesia:\n        |/\n73bfd7d * v0.3.0 base\n\n```\n\nWhen *topic-x* and *topic-y* have a conflict, the shared base of their base is\n\n```bash\n4 taichi@Gensokyo:~/Documents/Work/Repo/anoma-all git:main: % git merge-base topic-x topic-y\n13b3e4a215ea6222a1b1092ad242d3fa31e7040b\n```\n\nwhich is `13b3e4a * | Merge branch 'ray/mnesia-attach'` and not\n`73bfd7d * v0.3.0 anoma/base`, meaning that when a conflict is shown\nin the merge `0438922`, then the diff from a 3 way diff will show the\nmnesia changes, potentially making it unclear to others way the\npotentially issues may be.\n\n<!-- livebook:{\"break_markdown\":true} -->","ref":"git.html#git-merges-and-conflict-resolutions-lead-to-spurious-base-points"},{"type":"extras","title":"Other topics can not reuse your code - Git","doc":"It is a bad idea to base code on `main`, as `main` contains random\nmerged topics before a release. This makes it so other topics who wish\nto use yours also has to merge all the random topics on `main`.\n\nThis is easy to see with the following example:\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'simple-config'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\nbranch major-changes\ncommit id: \"97bef7: structural changes\"\ncheckout simple-config\nmerge major-changes id: \"5b16844: merge into main\"\ncommit id: \"f098de0: general config\"\n```\n\nHere we have a topic `major-changes` that makes all sorts of changes,\nand since we based our code off main, these are all included in\nsimple-config-change.\n\nHowever imagine we wish to overhaul the configuration a bit\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'configuration-upgrade'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\ncommit id: \"f098de0: Basic config changes\"\n```\n\nNow if we wish to merge in `simple-config-change` we have\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'configuration-upgrade'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\n\nbranch simple-config\ncheckout configuration-upgrade\nbranch major-changes\ncommit id: \"97bef7: structural changes\"\n\ncheckout configuration-upgrade\ncommit id: \"f098de0: Basic config changes\"\n\ncheckout simple-config\nmerge major-changes id: \"5b16844: merge into main\"\ncommit id: \"f098de0: general config\"\n\ncheckout configuration-upgrade\nmerge simple-config id: \"f6230df\"\n```\n\nBesides having a spurious main merged into our topic now, we are\nforced to deal with `major-changes` causing various conflicts with\nyour topic, making this merge untenable.\n\nMeaning that this code has to be recreated in `configuration-upgrade`\ninstead of reusing `simple-config-change`, fixing the problem in 2\nplaces, and having a conflict when it comes time for a release.\n\n<!-- livebook:{\"break_markdown\":true} -->","ref":"git.html#other-topics-can-not-reuse-your-code"},{"type":"extras","title":"Useless temporal history is had - Git","doc":"As we can see in the previous examples, when we base off of `main`, we\nend up in a scenario, where the date in which someone is branching is\nbaked into the code. As maintainers we don't care about when the code\nwas made, just the fact that it was. Thus this is a bit of history\nthat simply adds noise\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#useless-temporal-history-is-had"},{"type":"extras","title":"Merge other people's topics into yours - Git","doc":"If you need some work that is already merged into `next` or `main`,\nsimply merge that topic into yours! Since the bases are well situated,\nyou will only deal with reasonable conflicts that you should have\ncontext for.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#merge-other-people-s-topics-into-yours"},{"type":"extras","title":"Base bug fixes on the commit that introduced the bug - Git","doc":"Basing a bug fix on when the bug is introduced is superior than basing\nit on the latest release, as this means that it can be merged into any\n`maint` branches we may have.\n\nFor example:\n\n```\n73bfd7d * v0.3.0 Anoma 0.3.0\n...\n10f8636 * v0.2.0 Anoma 0.2.0\n...\n34fcd78 * v0.1.0 Release v0.1.0\n```\n\nif a bug was found in a topic between `v0.1.0` and `v0.2.0`, and we\nbased it on when the bug was found we can merge it on `v0.2.0` and\nhave `v0.2.1` release from there. And have a `v0.3.1` release as well.\n\n```\n2373834 *   v0.2.1 Merge branch 'bug-fix' into HEAD\n        |\\\nda24431 | * bug-fix fix bug\n10f8636 * | v0.2.0 Anoma 0.2.0\n```\n\n```\n19c6f03 *   v0.3.1 Merge branch 'bug-fix' into HEAD\n        |\\\nda24431 | * bug-fix fix bug\n73bfd7d * | v0.3.0 Anoma 0.3.0\n```\n\nnotice how we can merge this in with no conflicts!","ref":"git.html#base-bug-fixes-on-the-commit-that-introduced-the-bug"},{"type":"extras","title":"Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Hoon","ref":"hoon-1.html"},{"type":"extras","title":"Index - Hoon","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"hoon-1.html#index"},{"type":"extras","title":"Hoon - Hoon","doc":"Currently the quickest way to write resource logics is to have Hoon\nsetup and working. Checkout the [Hoon section for more information](../hoon.livemd)","ref":"hoon-1.html#hoon"},{"type":"extras","title":"IEx","doc":"# IEx","ref":"iex.html"},{"type":"extras","title":"Index - IEx","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"iex.html#index"},{"type":"extras","title":"Running multiple IEX's in the same Image/Environments - IEx","doc":"It is sometimes useful to have multiple terminals/IEX's in the same\nrunning system, or perhaps to connect to a running deploy Anoma\nInstance. We can connect to other IEX instances in this way:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```bash\nMIX_ENV=test iex --sname b@localhost --cookie anoma -S mix\n# open a new terminal\nMIX_ENV=test iex --remsh b@localhost --sname c@localhost --cookie anoma -S mix\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis also allows you to connect from [livebook](https://livebook.dev)\nby using the above cookie `anoma` under the `runtime` config of\nlivebook.","ref":"iex.html#running-multiple-iex-s-in-the-same-image-environments"},{"type":"extras","title":"Mnesia Vs Actor State","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Mnesia Vs Actor State","ref":"mnesia-vs-actor-state.html"},{"type":"extras","title":"Index - Mnesia Vs Actor State","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"mnesia-vs-actor-state.html#index"},{"type":"extras","title":"Where should state be stored - Mnesia Vs Actor State","doc":"One interesting thing about our system is that in the [user data](./../user/data.livemd) section of our documentation we talk about how Anoma's state is stored in [RocksDB](https://en.wikipedia.org/wiki/RocksDB) tables on disc. And that we have some kind of `dump` format that goes along with the tables.\n\nThe `dump` format stores 2 kinds of information:\n\n1. Actor State\n2. [Mnesia](https://en.wikipedia.org/wiki/Mnesia) State\n\nAs discussed in the [user data documentation](./../user/data.livemd), loading a `dump` file overwrites the DB. However what we did not cover is what the differences are between [Mnesia](https://en.wikipedia.org/wiki/Mnesia) storage and Actor storage.","ref":"mnesia-vs-actor-state.html#where-should-state-be-stored"},{"type":"extras","title":"Mnesia Storage - Mnesia Vs Actor State","doc":"The philosophy for what is stored in Mnesia should be: \"Is this something the user should be able to query and write code over\". Since Anoma is a distributed operating system project, many of the answers should be yes. The user should be able to make full fledged progrmas on Anoma and extend the system.","ref":"mnesia-vs-actor-state.html#mnesia-storage"},{"type":"extras","title":"Actor Storage - Mnesia Vs Actor State","doc":"Actor storage on the other hand are for things we don't wish the user to be able to query. Thus implementaiton details about the execution should be omitted from user visible storage, and would be better served stored on the Actor.\n\nA good example of this is the old ordering logic.\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  typedstruct do\n    field(:table, Router.Addr.t())\n    field(:next_order, non_neg_integer(), default: 1)\n    field(:hash_to_order, %{key() => non_neg_integer()}, default: %{})\n    field(:logger, Router.Addr.t(), enforce: false)\n  end\n```\n\nIn this example, we store things like specific order information, the live router addresses for storage and for the logger. None of this is relevant to the users and are just coincidental with how we wrote the system.","ref":"mnesia-vs-actor-state.html#actor-storage"},{"type":"extras","title":"Observer","doc":"<!-- livebook:{\"file_entries\":[{\"name\":\"2024-01-08-172805_1016x497_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-173044_1845x1082_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174448_1283x720_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174522_1420x684_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174628_443x186_scrot.png\",\"type\":\"attachment\"},{\"name\":\"Application_view.jpg\",\"type\":\"attachment\"}],\"persist_outputs\":true} -->\n\n# Observer","ref":"observer.html"},{"type":"extras","title":"Index - Observer","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"observer.html#index"},{"type":"extras","title":"How To use Observer - Observer","doc":"It is sometimes useful to have multiple terminals/IEX's in the same\nrunning system, or perhaps to connect to a running deploy Anoma\nInstance. We can connect to other IEX instances in this way:","ref":"observer.html#how-to-use-observer"},{"type":"extras","title":"Viewing Anoma - Observer","doc":"One can view Anoma by going to the Applications view of the Observer pane and clicking on anoma\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/Application_view.jpg)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis view is quite nice because if we spawn a process, we can see it attach\n\n```elixir\nalias Anoma.Storage\nalias Anoma.Node.Storage.Communicator, as: Scom\nalias Anoma.Node.Executor.Communicator, as: Ccom\nalias Anoma.Node.Mempool.Communicator, as: Mcom\nimport TestHelper.Nock\n\nstorage = %Anoma.Storage{\n  qualified: Anoma.Qualified,\n  order: Anoma.Order\n}\n\nname = :anoma\nsnapshot_path = [:my_special_nock_snaphsot | 0]\nnode = Anoma.Node.com_names(name)\nkey = 555\nzero = zero_counter(key)\npid_zero = Mcom.tx(node.mempool, zero).pid\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.4479.0>\n```\n\nThen we can see this same process as a child to one of the pools\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-172805_1016x497_scrot.png)","ref":"observer.html#viewing-anoma"},{"type":"extras","title":"Looking at Mnesia Tables - Observer","doc":"One can go to the Table view, and click view to turn it from `ets` tables to `mnesia` tables.\n\nNow you should be able to see this:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174522_1420x684_scrot.png)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nIf we click on a table like the one highlighted we can see the values in the table\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174448_1283x720_scrot.png)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nClick on the data inside of here gives us an inspector pane of the data\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174628_443x186_scrot.png)","ref":"observer.html#looking-at-mnesia-tables"},{"type":"extras","title":"Style Guide","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Style Guide","ref":"style-guide.html"},{"type":"extras","title":"Index - Style Guide","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"style-guide.html#index"},{"type":"extras","title":"Structural Rules - Style Guide","doc":"A module is **documented** if\n\n* It has nonempty module documentation.\n* All of its public functions capable of having documentation have nonempty documentation.\n* All of its public functions capable of having types assigned have assigned types.\n* All types have type documentation.\n\n#### Rule 1.1\n\nAny module which is specified under the Node directory ought to be **documented**.\n\n#### Rule 1.2\n\nAny public function which is used in a public function by a module specified under the Node directory ought to have nonempty documentation.\n\n#### Rule 1.3\n\nDocumentation should be given in first person.\n\n#### Rule 1.4\n\nIf `foo` uses `bar` in the same module in the Node dir then `foo` is placed higher than `bar` in the module.\n\nExceptions might exist but should be noted explicitly in PR and commit messages.\n\n#### Rule 1.5 (CQRS)\n\nIf `foo` uses Router or GenServer functionality, it should be a `call` if and only if either\n\n1. The underlying state is unchanged by calling `foo`\n2. There are synchronizaton requirements that `foo` has to fullfill.\n\n#### Rule 1.6\n\nIf `foo` uses `call` functionality then the corresponding `handle_call` shall have body\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n{:reply, do_foo(...), state}\n```\n\nwith `do_foo` implementing core logic.\n\nIf `foo` has synchronization requirements, the return of `do_foo` should only contain information regarding the\nsuccess or failure of the operation.\n\n#### Rule 1.7\n\nCalling a callback function from another callback functions is _not_ allowed.\n\n#### Rule 1.8\n\nEvery actor module should have mandatory `Public RPC API`, `GenServer Behavior`, and `GenServer Implementation` sections with following formatting:\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  ############################################################\n  #                      Public RPC API                      #\n  ############################################################\n```\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  ############################################################\n  #                    GenServer Behavior                    #\n  ############################################################\n```\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  ############################################################\n  #                  GenServer Implementation                #\n  ############################################################\n```\n\nwhere\n\n* `Public RPC API` contains public functions using `call` or `cast` functionality\n* `GenServer Behavior` contains all callback functions `handle_call`, `handle_cast`, `handle_info`, and `handle_continue`\n* `GenServer Implementation` contains all functions explicitly used in the `GenServer Behavior` sections.\n\nExtra functions can be contained in the latter section or can further be separated into `Helper` functions.\n\n#### Rule 1.9\n\nActor module may have an optional `Logging Info` section with following formatting:\n\n```\n  ############################################################\n  #                     Logging Info                         #\n  ############################################################\n```\n\nthat contains functions related to logging.","ref":"style-guide.html#structural-rules"},{"type":"extras","title":"Module Documentation - Style Guide","doc":"#### Rule 2.1\n\nModule documentation starts with stating its core purpose in one sentence followed by a new line. If it is related to an Engine X mentioned in the specs, specify that it is an implementation.\n\n* `I am the Storage Engine implementing the Local Key Value Storage Engine.`\n* `I am the Dumper Engine.` (in case the names match)\n* `I am the Blah module which implements foo functionality.`\n\n#### Rule 2.2\n\nModule documentation ought to have an API section separated by a `","ref":"style-guide.html#module-documentation"},{"type":"extras","title":"Public API` line followed by a line: `I have the following public functionality:` followed by a list of functions or subsections of lists of functions. All public module functions should appear in this section. - Style Guide","doc":"A subsection named `Section Name` should be formatted as `#### Section Name` followed by a short description of the section and a list of functions.\n\nThe format for the list is: if a module has public function `foo` of `n` entries we list it as ``` - `foo/n` ```.  Every line - except those in the function list - should be separated by a newline. Functions should be grouped by argument number with fewer argument numbers on top.\n\nIf subsections were used yet not all functions feature in their lists, the rest of the functions should appear in the `#### Other` subsection placed at the end.\n\n* ```","ref":"style-guide.html#public-api-line-followed-by-a-line-i-have-the-following-public-functionality-followed-by-a-list-of-functions-or-subsections-of-lists-of-functions-all-public-module-functions-should-appear-in-this-section"},{"type":"extras","title":"Public API - Style Guide","doc":"I have the following public functionality:\n\n  #### Transaction Functions\n\n  - `new_transaction/3`\n  - `fire_new_transaction/3`\n  - `new_transaction/4`\n  - `fire_new_transaction/4`\n\n  #### Other\n\n  - `snapshot/1`\n  - `subscribe/2`\n  ```","ref":"style-guide.html#public-api"},{"type":"extras","title":"Example - Style Guide","doc":"<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  defmodule Anoma.Node.Clock do\n    @moduledoc \"\"\"\n    I am the Clock module implementing the Local Wall Clock Engine.\n\n    I provide info on the time elapsed in milliseconds after the node launched\n    and the epoch from which it has been calculated using monotonic time.\n\n    The current implementation launches the epoch by asking for the system\n    monotonic time at the point of an Anoma node launch. This is recommended\n    as all my public API uses system monotonic time to give measurements.","ref":"style-guide.html#example"},{"type":"extras","title":"Public API - Style Guide","doc":"I have the following public functionality:\n\n    - `get_time/1`\n    - `get_epoch/1`\n    \"\"\"\n```","ref":"style-guide.html#public-api"},{"type":"extras","title":"Type Documentation - Style Guide","doc":"#### Rule 3.1\n\nThe type documentation should start with stating the purpose of the type in one sentence.\n\n* ``` I control options for `launch_min/2` ```\n* `I am the type of the Executor Engine`\n\n#### Rule 3.2\n\nEvery product type documentation should have a `","ref":"style-guide.html#type-documentation"},{"type":"extras","title":"Fields` section followed by a list of field atoms with their descriptions. - Style Guide","doc":"The list should be formatted as follows:\n\nGiven a field `:field` we list it as ``` - `:field` - ``` followed by a short description. This is followed by a sentence `Enforced: bool` where `bool` is either `true` or `false`. If it has a default value, should be also followed by `Default: value`.\n\n* ```","ref":"style-guide.html#fields-section-followed-by-a-list-of-field-atoms-with-their-descriptions"},{"type":"extras","title":"Fields - Style Guide","doc":"- `:intents_topic` - The address of the intents topic to which the engine broadcasts.\n  - `:intents` - The set of intents to be solved. Default: `MapSet.new/0`\n  - `:logger` - The address of the Logger Engine used for logging. Enforced: false.\n  ```\n\n#### Rule 3.3\n\nEvery sum type documentation should have an `","ref":"style-guide.html#fields"},{"type":"extras","title":"Options` section followed by a list of field atoms with their descriptions. - Style Guide","doc":"The list should be formatted as follows:\n\nGiven an option `:option` we list it as ``` - `:option` - ``` followed by a short description.\n\n* ```","ref":"style-guide.html#options-section-followed-by-a-list-of-field-atoms-with-their-descriptions"},{"type":"extras","title":"Options - Style Guide","doc":"- `:use_rocksdb` - See `t:Anoma.Node.configuration/0` for more\n  information.\n  - `:supervisor` - This flag determine if we use a supervisor and if\n  so what options. See `t:Supervisor.option/0 ` for supervisor options.\n  - `:testing` - This flag notes if we are testing the node. This gets\n    fed directly into the type `t:Anoma.Node.configuration/0` for\n    `Anoma.Node.start_link/1`. Please consult the\n    `t:Anoma.Node.configuration/0` documentation for the full effect\n    this has on the node.\n  ```","ref":"style-guide.html#options"},{"type":"extras","title":"Example - Style Guide","doc":"<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  typedstruct do\n    @typedoc \"\"\"\n    I am the type of the Pinger Engine.\n\n    I store minimal info required to ask the mempool to execute, namely the\n    mempool address and the time specified by the user.\n\n    - `:mempool` - The Mempool Engine address which is called to execute.\n    - `:time` - The time that should be elapsed between the calls to\n                execute or an atom saying that no timer should be set.\n                Default: `:no_timer`\n    \"\"\"\n\n    field(:mempool, Router.Addr.t())\n    field(:time, non_neg_integer() | atom(), default: :no_timer)\n  end\n\n  @typedoc \"\"\"\n  I control options for `launch_min/2`.","ref":"style-guide.html#example"},{"type":"extras","title":"Options - Style Guide","doc":"- `:use_rocksdb` - See `t:Anoma.Node.configuration/0` for more\n  information.\n  - `:supervisor` - This flag determine if we use a supervisor and if\n  so what options. See `t:Supervisor.option/0 ` for supervisor options.\n  - `:testing` - This flag notes if we are testing the node. This gets\n    fed directly into the type `t:Anoma.Node.configuration/0` for\n    `Anoma.Node.start_link/1`. Please consult the\n    `t:Anoma.Node.configuration/0` documentation for the full effect\n    this has on the node.\n  \"\"\"\n  @type launch_option ::\n          {:use_rocksdb, boolean()}\n          | {:supervisor, [Supervisor.option()]}\n          | {:testing, boolean()}\n```","ref":"style-guide.html#options"},{"type":"extras","title":"Function Documentation - Style Guide","doc":"#### Rule 4.1\n\nThe function documentation should begin with stating its purpose in one sentence. If the function is an implementation of a specs-related function, it should mention this by name.\n\n* `I am delete_key function, implementing DeleteValueKVStorage functionality.`\n* `Given a server S and time T, I change the timer set for the struct\n  connected to S setting it to T.`\n\n#### Rule 4.2\n\nIf a documented function has functions of same arity in the same module which pattern match arguments differently, they should be listed in a `","ref":"style-guide.html#function-documentation"},{"type":"extras","title":"Pattern-Match Variations` section in the following format: - Style Guide","doc":"If function `foo` has a variation `foo(x1, ... , xn)` where `x1,...,xn` are some Elixir object capable of being pattern-matched to, we present it in a list as `- foo(x1, ... ,xn) -` followed by a short description.\n\nIf the arguments are not pattern-matched, provide the variable names as in the definition.\n\n* ```","ref":"style-guide.html#pattern-match-variations-section-in-the-following-format"},{"type":"extras","title":"Pattern-Matching Variations - Style Guide","doc":"- `init(%Clock{})` - I initialize the Engine with the given state.\n\n  - `init(args)` - I expect a keylist and check for the :start key then\n                   launch the Clock with said setting.\n  ```\n\n#### Rule 4.3\n\nAny function application which a non-constant output and an appropriate EModule example, it should have a reference to the appropriate example function in the codebase.","ref":"style-guide.html#pattern-matching-variations"},{"type":"extras","title":"Example - Style Guide","doc":"<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  @doc \"\"\"\n  I am the initialization function of the Clock Engine.","ref":"style-guide.html#example"},{"type":"extras","title":"Pattern-Matching Variations - Style Guide","doc":"- `init(%Clock{})` - I initialize the Engine with the given state.\n\n  - `init(args)` - I expect a keylist and check for the :start key then\n                   launch the Clock with said setting.\n  \"\"\"\n  def init(%Clock{} = state) do\n    {:ok, state}\n  end\n\n  @spec init(list({:start, integer()})) :: {:ok, Clock.t()}\n  def init(args) do\n    {:ok, %Clock{start: args[:start]}}\n  end\n```","ref":"style-guide.html#pattern-matching-variations"},{"type":"extras","title":"Testing","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Testing","ref":"testing.html"},{"type":"extras","title":"Index - Testing","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"testing.html#index"},{"type":"extras","title":"Testing - Testing","doc":"Testing is important for the Anoma Project.\n\nThese series of documents cover how best to traverse tests throughout the project.","ref":"testing.html#testing"},{"type":"extras","title":"Running Tests","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Running Tests","ref":"running-tests.html"},{"type":"extras","title":"Index - Running Tests","doc":"1. [Toc](./../../toc.livemd)\n2. [User](./../../user.livemd)\n   1. [Data](./../../user/data.livemd)\n3. [Contributing](./../../contributing.livemd)\n   1. [Understanding Any Module](./../../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../../contributing/style-guide.livemd)\n   3. [Writing Documents](./../../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../../contributing/examples-over-testing.livemd)\n   5. [Git](./../../contributing/git.livemd)\n   6. [Hoon](./../../contributing/hoon.livemd)\n   7. [Iex](./../../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../../contributing/observer.livemd)\n   10. [Testing](./../../contributing/testing.livemd)\n       1. [Running Tests](./../../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../../visualization.livemd)\n   1. [Actors](./../../visualization/actors.livemd)\n5. [Hoon](./../../hoon.livemd)\n   1. [Calling](./../../hoon/calling.livemd)\n   2. [Dumping](./../../hoon/dumping.livemd)\n   3. [Setting Up](./../../hoon/setting-up.livemd)\n6. [Analysis](./../../analysis.livemd)\n   1. [Fema Analysis Pinger](./../../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../../logging.livemd)\n8. [Vm_interface](./../../vm_interface.livemd)","ref":"running-tests.html#index"},{"type":"extras","title":"Intent - Running Tests","doc":"This document is aimed at allowing any developer to run tests in a more ergonomic way than simply running:\n\n```shell\n% mix test\n```\n\nNamely, this document covers running tests inside `IEX` and being able to do so on demand.","ref":"running-tests.html#intent"},{"type":"extras","title":"Setting up IEX - Running Tests","doc":"To Run tests within IEx. One simply calls `Mix.Tasks.Test.run/1` within their IEX session.\n\nHowever attempting to do this by default will result in the following error:\n\n```shell\n iex --sname mariari --cookie mariari -S mix\n```\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\nMix.Tasks.Test.run([])\n```\n\n````\n** (Mix.Error) \"mix test\" is running in the \"dev\" environment. If you are running tests from within another command, you can either:\n\n  1. set MIX_ENV explicitly:\n\n      MIX_ENV=test mix test.another\n\n  2. set the :preferred_envs for \"def cli\" in your mix.exs:\n\n      def cli do\n        [preferred_envs: [\"test.another\": :test]]\n      end\n\n    (mix 1.15.5) lib/mix.ex:577: Mix.raise/2\n    (mix 1.15.5) lib/mix/tasks/test.ex:486: Mix.Tasks.Test.do_run/3\n    #cell:nsl6gqly4w45ei6b:1: (file)\n    ```\n````\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThe error text hints at a suggestion on how to solve the problem.\n\n```shell\nMIX_ENV=iex iex --sname mariari --cookie mariari -S mix\n```\n\nI recommend using the `iex` environment over the `test` environment that is shwon in the error, as in the `Anoma` project, we set the `test` environment to have `Config.config/2` to have the following settings:\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\nconfig :logger,\n  level: :error\n```\n\nWhich means that some logging details you may care about may not be reported to you by default.\n\nNow that we have the environment setup if we try running this again we get:\n\n```elixir\nMix.Tasks.Test.run([])\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\nFinished in 0.00 seconds (0.00s async, 0.00s sync)\n0 failures\n\nRandomized with seed 670138\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nRunning the command has a few effects:\n\n1. It behaves the same as `mix test` running every single test in the project.\n2. It loads in the test modules, meaning we now have access to all modules in `AnomaTest`.\n3. `ExUnit` is now started up, meaning we can run tests with `ExUnit.run/0` now.\n\nFor larger projects `1.` may be prohibitive as tests may take quite a while to run!","ref":"running-tests.html#setting-up-iex"},{"type":"extras","title":"Running Individual Modules For the First Time - Running Tests","doc":"To run an individual module, one simply needs to invoke the `ExUnit` framework themselves.\n\nA good example of this at play is the following example:\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\niex(mariari@YU-NO)1> ExUnit.start\n:ok\niex(mariari@YU-NO)2> c \"test/node/mempool_test.exs\"\n[AnomaTest.Node.Mempool]\niex(mariari@YU-NO)3> ExUnit.run\n\n14:46:45.846 [error] Worker failed! :error\n\n14:46:45.849 [error] Worker failed! :error\n.....\nFinished in 0.3 seconds (0.3s async, 0.00s sync)\n5 tests, 0 failures\n\nRandomized with seed 670138\n%{total: 5, failures: 0, excluded: 0, skipped: 0}\n```\n\nWe can see here that I've started up ExUnit with `ExUnit.start/0`, then I've manually compiled the module I wanted to run `c ...` and then I ran `ExUnit.run/0`.\n\nThe side effect of running tests this way is that only `AnomaTest.Node.Mempool` is in scope. The other tests are not.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThe behavior of `ExUnit.run/0` is quite configurable, see `ExUnit.configure/1` for a lot of options on filtering what tests are run.","ref":"running-tests.html#running-individual-modules-for-the-first-time"},{"type":"extras","title":"ReRunning Tests - Running Tests","doc":"One may be surprised at the first time they try to rerun tests, as they will run into the following anomaly:\n\n```elixir\nMix.Tasks.Test.run([])\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\nFinished in 0.00 seconds (0.00s async, 0.00s sync)\n0 failures\n\nRandomized with seed 670138\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nNo tests were run again! This can be rather annoying as we often make changes to code and wish to see if they break certain tests!\n\nA way around this is by recompiling the given module then running again\n\n```iex\niex 7> r AnomaTest.Node.Mempool\nwarning: redefining module AnomaTest.Node.Mempool (current version defined in memory)\n  test/node/mempool_test.exs:1: AnomaTest.Node.Mempool (module)\n\n{:reloaded, [AnomaTest.Node.Mempool]}\niex(mariari@YU-NO)8> Mix.Tasks.Test.run([])\n\n14:58:09.255 [error] Worker failed! :error\n\n14:58:09.256 [error] Worker failed! :error\n.....\nFinished in 0.3 seconds (0.3s async, 0.00s sync)\n5 tests, 0 failures\n```","ref":"running-tests.html#rerunning-tests"},{"type":"extras","title":"Running individual tests - Running Tests","doc":"In the Writing tests document we layout a guideline that shows how to write tests that can easily be ran in the repl over and over.\n\nThanks to this design, running individual tests is quite simple!\n\nAll one has to do is follow these simple instructions:\n\n1. copy the Imports from the test file one sees\n2. copy all code within the `setup_all`\n3. (optional) import `ExUnit.Assertions`\n4. run the tets by hand.\n\n```elixir\ndefmodule AnomaTest.LiveBook.Example do\n  use ExUnit.Case, async: true\n\n  import TestHelper.Nock\n\n  setup_all do\n    name = :hi\n\n    [name: name]\n  end\n\n  test \"first\", %{} do\n    assert 2 == 2\n  end\n\n  test \"logic\", %{name: name} do\n    fi = :erlang.atom_to_binary(name)\n    assert fi == fi\n  end\n\n  describe \"group\" do\n    test \"second\", %{name: name} do\n      assert name == name\n    end\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nwarning: unused import TestHelper.Nock\n  documentation/contributing/testing/running-tests.livemd#cell:nzkdwbfnnuijteho:4\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.Example, <<70, 79, 82, 49, 0, 0, 16, ...>>, {:\"test group second\", 1}}\n```\n\nIf we take `AnomaTest.LiveBook.Example` as our exmaple, then we can run the individual tests like the following.\n\n```elixir\n# Copy the imports\nimport TestHelper.Nock\n\n# Copy the setup_all\n\nname = :hi\n\n[name: name]\n\n# Now run the test\n\nAnomaTest.LiveBook.Example.\"test first\"(%{name: name})\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nTest names are odd in that they are not simple atoms, they are typically the word `test` then the string name given to the test. Hence `test \"first\"` became `AnomaTest.LiveBook.Example.\"test first\"/1`.\n\nTo run the group, we need to prepend the group name as well.\n\n```elixir\nAnomaTest.LiveBook.Example.\"test group second\"(%{name: name})\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nWhat is very nice about this setup is that we can run the tests piecewise by copy and pasting the logic to the point that we care about. For example let us run the `AnomaTest.LiveBook.Example.\"test logic\"/1` test by hand.\n\n```elixir\nfi = :erlang.atom_to_binary(name)\n\nassert fi == fi\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nerror: undefined function assert/1 (there is no such import)\n  documentation/contributing/testing/running-tests.livemd#cell:6wdtc4fkrz3iatat:3\n\n```\n\nThe assert code fails as we forgot to import `ExUnit.Assertions`. If we import this file then the entire copy and paste will run!\n\n```elixir\nimport ExUnit.Assertions\nfi = :erlang.atom_to_binary(name)\n\nassert fi == fi\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\ntrue\n```\n\nThis is very useful in debugging, as we may have a test that is composed of `n` steps, and we may wish to run it partially up until some known state, then modify the code live.\n\nThis means that instead of having to rerun tests from scractch over and over again like in Rust or CPP, you can effectively have all the state of the test live in your repl, and change specific code you wish to test, and simply run the command that fails and see how your code changes affect any particular given state.","ref":"running-tests.html#running-individual-tests"},{"type":"extras","title":"Conclusion - Running Tests","doc":"Running tests in Elixir is nice and somewhat simple!\n\nWe have covered how to:\n\n1. Run tests within `IEX`\n2. re-running tests in `IEX`\n3. running individual tests fully\n4. Running individual tests partially","ref":"running-tests.html#conclusion"},{"type":"extras","title":"Writing Tests","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Writing Tests","ref":"writing-tests.html"},{"type":"extras","title":"Index - Writing Tests","doc":"1. [Toc](./../../toc.livemd)\n2. [User](./../../user.livemd)\n   1. [Data](./../../user/data.livemd)\n3. [Contributing](./../../contributing.livemd)\n   1. [Understanding Any Module](./../../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../../contributing/style-guide.livemd)\n   3. [Writing Documents](./../../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../../contributing/examples-over-testing.livemd)\n   5. [Git](./../../contributing/git.livemd)\n   6. [Hoon](./../../contributing/hoon.livemd)\n   7. [Iex](./../../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../../contributing/observer.livemd)\n   10. [Testing](./../../contributing/testing.livemd)\n       1. [Running Tests](./../../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../../visualization.livemd)\n   1. [Actors](./../../visualization/actors.livemd)\n5. [Hoon](./../../hoon.livemd)\n   1. [Calling](./../../hoon/calling.livemd)\n   2. [Dumping](./../../hoon/dumping.livemd)\n   3. [Setting Up](./../../hoon/setting-up.livemd)\n6. [Analysis](./../../analysis.livemd)\n   1. [Fema Analysis Pinger](./../../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../../logging.livemd)\n8. [Vm_interface](./../../vm_interface.livemd)","ref":"writing-tests.html#index"},{"type":"extras","title":"Conventions - Writing Tests","doc":"Since the [figuring out](./../../contributing/understanding-any-module.livemd) page demonstrates that well laid out test files are the key to understanding how modules work, it is important to write tests so this can always be achieved.\n\nThe following sections will lay out how we can achieve this.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#conventions"},{"type":"extras","title":"Make sure names from the test matches setup_all - Writing Tests","doc":"```elixir\nExUnit.start()\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\n```elixir\ndefmodule AnomaTest.LiveBook.Nam do\n  use ExUnit.Case\n\n  setup_all do\n    special = 3\n    [special: special]\n  end\n\n  test \"this is acceptable\", %{special: special} do\n    assert special == 3\n  end\n\n  test \"this test is not acceptable\", %{special: spec} do\n    assert spec == 3\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.Nam, <<70, 79, 82, 49, 0, 0, 14, ...>>,\n {:\"test this test is not acceptable\", 1}}\n```\n\nIf this convention is not followed, then the user can not simply be\ncopy and paste the lines to figure out how to use the module.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#make-sure-names-from-the-test-matches-setup_all"},{"type":"extras","title":"Write setup_all to not crash on reevaluation - Writing Tests","doc":"```elixir\ndefmodule AnomaTest.LiveBook.NoCrash do\n  use ExUnit.Case\n\n  setup_all do\n    name = :intent_example\n\n    unless Process.whereis(name) do\n      Anoma.Node.Intent.init(name)\n    end\n\n    [intent_pool: name]\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nwarning: Anoma.Node.Intent.init/1 is undefined (module Anoma.Node.Intent is not available or is yet to be defined)\n  documentation/contributing/testing.livemd#cell:qbrtwwd53rvqgtpz:8: AnomaTest.LiveBook.NoCrash.__ex_unit_setup_all_0/1\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.NoCrash, <<70, 79, 82, 49, 0, 0, 11, ...>>,\n {:__ex_unit_setup_all_0, 1}}\n```\n\n* Here we check if the process is running. This way if it is\n  already in IEX we simply don't disturb it but rename it to point\n  to the correct one we wish to operate over.\n* If we did not do this check the other commands may fail and IEX\n  may not be trapped to continue.\n* `mix test` will not catch this\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#write-setup_all-to-not-crash-on-reevaluation"},{"type":"extras","title":"Try to make tests idempotent - Writing Tests","doc":"Let us demonstrate this point, by making a simple queue service.\n\n```elixir\ndefmodule Queue do\n  use GenServer\n\n  def init(_init) do\n    {:ok, :queue.new()}\n  end\n\n  def start_link(arg) do\n    GenServer.start_link(__MODULE__, arg, name: arg)\n  end\n\n  def reset(queue) do\n    GenServer.cast(queue, :reset)\n  end\n\n  def enqueue(queue, name) do\n    GenServer.cast(queue, {:enqueue, name})\n  end\n\n  def pop(queue) do\n    GenServer.call(queue, :pop)\n  end\n\n  def handle_cast(:reset, _pool) do\n    {:noreply, :queue.new()}\n  end\n\n  def handle_cast({:enqueue, val}, pool) do\n    {:noreply, :queue.cons(val, pool)}\n  end\n\n  def handle_call(:pop, _from, queue) do\n    {:reply, :queue.get_r(queue), :queue.drop_r(queue)}\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, Queue, <<70, 79, 82, 49, 0, 0, 18, ...>>, {:handle_call, 3}}\n```\n\n```elixir\ndefmodule AnomaTest.LiveBook.Idempotent do\n  use ExUnit.Case\n\n  setup_all do\n    name = :queue_name\n\n    unless Process.whereis(name) do\n      Queue.start_link(name)\n    end\n\n    [queue: name]\n  end\n\n  test \"reset\", %{queue: name} do\n    # Make sure we get reliable results!\n    Queue.reset(name)\n    Queue.enqueue(name, 5)\n    Queue.enqueue(name, 4)\n    assert 5 == Queue.pop(name)\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.Idempotent, <<70, 79, 82, 49, 0, 0, 15, ...>>, {:\"test reset\", 1}}\n```\n\nHere before getting values from the queue, we make sure it's fresh by resetting it.\n\nIn the `Queue` case it's contrived, however a lot of genservers in the codebase work like this!\n\nSomething important to note is that `mix test` will not catch this!\n\nSo please try to keep tests isolated from each other.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#try-to-make-tests-idempotent"},{"type":"extras","title":"Try to Name Values - Writing Tests","doc":"For debugging purposes, it is best to name values, and so you can rerun values on command, or help the debugging process.","ref":"writing-tests.html#try-to-name-values"},{"type":"extras","title":"Understanding any code in Anoma","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Understanding any code in Anoma","ref":"understanding-any-module.html"},{"type":"extras","title":"Index - Understanding any code in Anoma","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"understanding-any-module.html#index"},{"type":"extras","title":"Figuring out what a module does - Understanding any code in Anoma","doc":"Α good start is by calling `h` on the module from within one's IEX\ninstance.\n\n```elixir\nrequire IEx.Helpers\nimport IEx.Helpers\n# the above two lines are not requried for the REPL!\nh(Anoma.Node)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\n                                   Anoma.Node\n\nI act as a registry for Anoma Nodes","ref":"understanding-any-module.html#figuring-out-what-a-module-does"},{"type":"extras","title":"Required Arguments - Understanding any code in Anoma","doc":"• name - name for this process\n  • snapshot_path : [atom() | 0]\n    • A snapshot location for the service (used in the worker)\n\n  • storage : Anoma.Storage.t() - The Storage tables to use\n  • block_storage - a location to store the blocks produced","ref":"understanding-any-module.html#required-arguments"},{"type":"extras","title":"Optional Arguments - Understanding any code in Anoma","doc":"• jet : Nock.jettedness() - how jetted the system should be\n  • old_storage : boolean - states if the storage should be freshly made\n    • by default it is false","ref":"understanding-any-module.html#optional-arguments"},{"type":"extras","title":"Registered names - Understanding any code in Anoma","doc":"","ref":"understanding-any-module.html#registered-names"},{"type":"extras","title":"Created Tables - Understanding any code in Anoma","doc":"• storage.qualified\n  • storage.order\n  • block_storage\n```\n\nHowever, this typically doesn't show off how one uses said\nmodule. Thankfully, the codebase is setup in such a way that one can\nalways interactively play with any given module.\n\nThis is done by simply checking out the tests folder, and finding the\nmodule you wish to learn to learn about.\n\nFor example, let us learn about the mempool. In the codebase currently\nthis can be found here:\n\n* `test/node/mempool_test.exs`,\n\nnote that even if this gets out of date, you should be able to do this with any file!\n\nThe first thing one can do to run things interactively is by taking\nall the imports of the file and running it locally\n\nIn this case I input the following from the file into IEX.\n\nI also make sure to include an extra `import ExUnit.Assertions` so\nthat assertions can be copied and pasted to IEX\n\n```elixir\n# output redacted for length\nalias Anoma.Storage\nalias Anoma.Node.Ordering\nalias Anoma.Node.Mempool\nalias Anoma.Node.Router\n\nimport TestHelper.Nock\n\nimport ExUnit.Assertions\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nExUnit.Assertions\n```\n\nAfter the imports are done, then we copy the `setup_all` if this section\nexists\n\n```elixir\n# setup_all do\nstorage = %Anoma.Storage{\n  qualified: AnomaTest.Mempool.Qualified,\n  order: AnomaTest.Mempool.Order\n}\n\nname = :mempool\nsnapshot_path = [:my_special_nock_snaphsot | 0]\n\nnode = Anoma.Node.state(name)\n\nunless Process.whereis(:mempool_mempool_com) do\n  Anoma.Node.start_link(\n    name: name,\n    snapshot_path: snapshot_path,\n    storage: storage,\n    block_storage: :mempool_blocks\n  )\nend\n\nnode\n# end\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%Anoma.Node{\n  logger: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Logger 0UFKnKepVKxm8B1uH/QkoKh0hLuVQ8TrRGf+4dFY+Zw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<49, 47, 91, 248, 87, 123, 100, 79, 0, 37, 176, 239, 240, 27, 218, 11, 63, 251, 170,\n        244, 75, 20, 116, 142, 149, 64, 1, 81, 42, 139, 210, 44>>,\n      sign: <<209, 65, 74, 156, 167, 169, 84, 172, 102, 240, 29, 110, 31, 244, 36, 160, 168, 116,\n        132, 187, 149, 67, 196, 235, 68, 103, 254, 225, 209, 88, 249, 156>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  clock: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Clock qoWUQLrfe8KstPBZsIN9e6Escpvdu5LbUUCS1SoGVYw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<141, 195, 214, 28, 18, 243, 25, 172, 222, 0, 152, 202, 137, 215, 147, 57, 71, 196,\n        13, 93, 148, 71, 58, 222, 4, 173, 137, 126, 228, 55, 181, 48>>,\n      sign: <<170, 133, 148, 64, 186, 223, 123, 194, 172, 180, 240, 89, 176, 131, 125, 123, 161, 44,\n        114, 155, 221, 187, 146, 219, 81, 64, 146, 213, 42, 6, 85, 140>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  pinger: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Pinger QeQQ09SN+5MeUCoc5hrKec7jJhKcrtSt+g879DFP0aY=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<98, 214, 175, 27, 239, 163, 208, 126, 208, 197, 212, 140, 32, 152, 249, 1, 180,\n        245, 181, 143, 171, 251, 99, 160, 21, 174, 16, 128, 35, 100, 227, 75>>,\n      sign: <<65, 228, 16, 211, 212, 141, 251, 147, 30, 80, 42, 28, 230, 26, 202, 121, 206, 227, 38,\n        18, 156, 174, 212, 173, 250, 15, 59, 244, 49, 79, 209, 166>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  mempool_topic: %Anoma.Node.Router.Addr{\n    server: nil,\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<111, 103, 214, 144, 51, 40, 198, 132, 2, 11, 19, 47, 228, 153, 121, 250, 201, 147,\n        248, 105, 164, 121, 218, 177, 11, 155, 204, 208, 20, 202, 55, 12>>,\n      sign: <<248, 79, 247, 60, 208, 85, 198, 79, 222, 145, 122, 214, 201, 141, 145, 255, 218, 208,\n        168, 250, 173, 25, 37, 111, 214, 134, 93, 99, 36, 0, 154, 28>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  },\n  mempool: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Mempool KNPB2ijsWnfve4L8Iuq434po8eFCJNK+EvKQ4Vd2Tqw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<167, 148, 18, 166, 207, 244, 170, 202, 95, 3, 187, 9, 217, 157, 97, 177, 208, 76,\n        163, 136, 148, 60, 160, 248, 68, 61, 142, 67, 47, 229, 82, 30>>,\n      sign: <<40, 211, 193, 218, 40, 236, 90, 119, 239, 123, 130, 252, 34, 234, 184, 223, 138, 104,\n        241, 225, 66, 36, 210, 190, 18, 242, 144, 225, 87, 118, 78, 172>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  executor_topic: %Anoma.Node.Router.Addr{\n    server: nil,\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<250, 161, 209, 10, 200, 171, 194, 37, 114, 235, 167, 193, 45, 245, 92, 157, 121,\n        106, 195, 86, 139, 58, 214, 217, 105, 181, 51, 76, 178, 55, 240, 37>>,\n      sign: <<188, 255, 80, 242, 172, 114, 141, 55, 239, 90, 234, 3, 38, 172, 76, 203, 220, 62, 127,\n        225, 249, 184, 214, 101, 227, 76, 95, 88, 235, 190, 14, 58>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  },\n  executor: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Executor zdsJtoPjG67QStGoPdiqdjF8wYg5J8Op5i1Bx9V2HCc=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<161, 173, 246, 156, 52, 73, 176, 104, 173, 192, 224, 111, 212, 231, 14, 136, 230,\n        151, 241, 237, 239, 180, 127, 69, 59, 149, 86, 210, 133, 246, 106, 20>>,\n      sign: <<205, 219, 9, 182, 131, 227, 27, 174, 208, 74, 209, 168, 61, 216, 170, 118, 49, 124,\n        193, 136, 57, 39, 195, 169, 230, 45, 65, 199, 213, 118, 28, 39>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  ordering: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Ordering oCXn2nJdaIIF+wTv8PreeZ56RXH6TKNVH2Vk+EP4FzI=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<137, 234, 55, 245, 216, 126, 69, 133, 161, 185, 181, 4, 138, 160, 234, 238, 82,\n        157, 113, 175, 169, 23, 67, 177, 90, 99, 60, 94, 0, 237, 51, 53>>,\n      sign: <<160, 37, 231, 218, 114, 93, 104, 130, 5, 251, 4, 239, 240, 250, 222, 121, 158, 122,\n        69, 113, 250, 76, 163, 85, 31, 101, 100, 248, 67, 248, 23, 50>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  router: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n        128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n      sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n        24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  }\n}\n```\n\nFrom here we can run any tests in the file by copying those as well!\n\nWhat is even better is that we can copy parts of tests to setup an\narea to play with the code to figure out what is going well with our\nother tools.\n\nThis is a great way for learning any API in the codebase as you can\nget hands on what each function and message does.\n\n```elixir\n# test \"successful process\", %{node: node} do\nkey = 555\nstorage = Ordering.get_storage(node.ordering)\nincrement = increment_counter_val(key)\nzero = zero_counter(key)\n\n:ok =\n  Router.call(\n    node.router,\n    {:subscribe_topic, node.executor_topic, :local}\n  )\n\nMempool.hard_reset(node.mempool)\n\npid_zero = Mempool.tx(node.mempool, {:kv, zero}).pid\n\nMempool.execute(node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:ok, 1}\n```\n\nFurther since the data is live, we can use tools like `:observer` to\nview the processes, and see general state dumping commands.\n\nFor databases I've found that `Anoma.Mnesia` is a good tool along with\n`:observer` for seeing what is currently in database table.","ref":"understanding-any-module.html#created-tables"},{"type":"extras","title":"Writing Documents","doc":"<!-- livebook:{\"file_entries\":[{\"name\":\"writing-docs-configure-system.png\",\"type\":\"attachment\"},{\"name\":\"writing-docs-kroki.png\",\"type\":\"attachment\"},{\"name\":\"writing-docs-smart-box.png\",\"type\":\"attachment\"}],\"persist_outputs\":true} -->\n\n# Writing Documents","ref":"writing-documents.html"},{"type":"extras","title":"Index - Writing Documents","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"writing-documents.html#index"},{"type":"extras","title":"The writing from within Anoma - Writing Documents","doc":"One of the more important parts of the Anoma project is understanding how the codebase works, and how it evolves.\n\nA good way to start on this process is by reading and writing documentation and making visual tools to better solidify knowledge for oneself and others.\n\nTo better do this, the codebase as a few levels of documentations:\n\n1. The specs (link TBA)\n2. These livebook documents\n3. Module level documentation\n\n`1.` is what specifies what `Anoma` is abstractly.\n\n`2.` serves the purpose of general knowledge transfer. Some documents serve to provide newcomers with information about various parts of Anoma's development process, others provide visual presentations to various parts of the codebase, while even others provide indepth analys of the codebase.\n\n`3.` is documents regarding module and function specifics. This is often augmented by `2.` for better context and examples.","ref":"writing-documents.html#the-writing-from-within-anoma"},{"type":"extras","title":"Making a new document - Writing Documents","doc":"To create a new document, it is simple as creating a new `.livemd` file in the folder location you wish it to be organized under.\n\nThus a file at `documentation/contributing/testing/foo.livemd` would be organized under the section `contribution/testing/`.\n\nThe file can either be made in livebook itself, or via the host operating system.","ref":"writing-documents.html#making-a-new-document"},{"type":"extras","title":"Connect to Anoma - Writing Documents","doc":"One should connect the document to a locally running IEX instance of Anoma.\n\nThis let's you take advantage of the pre-installed `kino` tools, and lets you generate documentation/diagrams over real Anoma Code.\n\nThis can be achieved by click on runtime settings:\n\n \n \n \n\nFrom here, click on configure and connect it to your running Anoma instance.","ref":"writing-documents.html#connect-to-anoma"},{"type":"extras","title":"Making diagrams - Writing Documents","doc":"Diagrams are an import piece of documentation.\n\nAll the standard livebook tools can be used, but Anoma has some extra dependencies that can help creating documentation.\n\nNamely under, the `+Smart` section, we can generate out various kinds of documents:\n\n![](files/writing-docs-smart-box.png)\n\nThe diagram will give you [Kroki diagrams](https://kroki.io/), and the UI will look something like this:\n\n![](files/writing-docs-kroki.png)\n\nHowever currently, due to a bug, writing text in the `Diagram source` will not change the generated diagram.\n\nIt is important to click the pencil icon, and edit it by hand.","ref":"writing-documents.html#making-diagrams"},{"type":"extras","title":"Generating the index - Writing Documents","doc":"To have an Index for a document, one must have a section named `Index`.\n\nOnce one has the `Index`, one can generate it by running `mix toc` or `make docs`.\n\nBecause livebook does not pull the files for changes, you may have to close the book and open it back up to have the relevant sections be up to date.\n\n<!-- livebook:{\"branch_parent_index\":5} -->","ref":"writing-documents.html#generating-the-index"},{"type":"extras","title":"Controlling the index sections - Writing Documents","doc":"To control the order of the index, the project has a file that controls the ordering.\n\n```elixir\n\"doc_order.exs\" |> File.read!() |> IO.puts()\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {\"documentation\",\n   [\n     {\"toc\", []},\n     {\"contributing\",\n      [\n        {\"understanding-any-module\", []},\n        {\"writing-documents\", []}\n      ]},\n     {\"visualization\", []},\n     {\"hoon\", []}\n   ]}\n]\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nThis is a priority list of documents, so the higher up a document is, the higher it will be presented in the `index`.\n\nRunning `mix toc` takes this into account. Note that to make sure your changes are reflected, run **mix clean** to make sure the wanted order is generated.","ref":"writing-documents.html#controlling-the-index-sections"},{"type":"extras","title":"Visualizing Anoma","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Visualizing Anoma","ref":"visualization.html"},{"type":"extras","title":"Index - Visualizing Anoma","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"visualization.html#index"},{"type":"extras","title":"Note on this section - Visualizing Anoma","doc":"This section provides extra visual diagrams on various components of\nAnoma, and serves to give an intuitive understanding on how Anoma\nworks.","ref":"visualization.html#note-on-this-section"},{"type":"extras","title":"The Actors","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# The Actors","ref":"actors.html"},{"type":"extras","title":"Index - The Actors","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"actors.html#index"},{"type":"extras","title":"An overview of Anoma - The Actors","doc":"A good overview of Actors can be seen by looking at the supervision tree of Anoma itself.\n\n```elixir\n{_, [pid1, pid2]} = Process.info(Process.whereis(:anoma), :links)\nKino.Process.render_sup_tree(pid2, direction: :left_right)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\ngraph LR;\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 1(Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 2(Anoma.Node.Clock plaqCqOIQ4LLCT9MAmEMV+qkqZq4+qZV2KSpqSxRZu0=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 3(Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 4(Anoma.Node.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 5(Anoma.Node.Executor po4ivXyVtjQ9jvTtra0D2DbKIpM8YOClCmfk8JLp31k=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 6(Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 7(Anoma.Node.Pinger Oc96nqV6/0FFT/JULG5Ep+Z1c62/8f1Bi0gY9CVmJhs=):::worker\nclassDef root fill:#c4b5fd, stroke:#374151, stroke-width:4px;\nclassDef supervisor fill:#c4b5fd, stroke:#374151, stroke-width:1px;\nclassDef worker fill:#93c5fd, stroke:#374151, stroke-width:1px;\nclassDef notstarted color:#777, fill:#d9d9d9, stroke:#777, stroke-width:1px;\n\n\n```","ref":"actors.html#an-overview-of-anoma"},{"type":"extras","title":"Mempool - The Actors","doc":"A good view of visualizing Anoma can be seen through running the\nmempool, as it orchastrates the other actors in Anoma to act\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFirst we will create a transaction and see how that changes the base supervision tree before executing\n\n```elixir\nalias Anoma.Node.Ordering\nalias Anoma.Node.Mempool\nalias Anoma.Node.Router\nimport TestHelper.Nock\n\nname = :anoma\nnode = Anoma.Node.state(name)\nkey = 555\nzero = zero_counter(key)\npid_zero = Mempool.tx(node.mempool, {:kv, zero}).pid\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.438.0>\n```\n\nThe previous evaluations PID can be seen in the diagram below!\n\n```elixir\n{_, [pid1, pid2]} = Process.info(Process.whereis(:anoma), :links)\nKino.Process.render_sup_tree(pid2, direction: :left_right)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\ngraph LR;\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 1(Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 2(Anoma.Node.Clock plaqCqOIQ4LLCT9MAmEMV+qkqZq4+qZV2KSpqSxRZu0=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 3(Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 4(Anoma.Node.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 5(Anoma.Node.Executor po4ivXyVtjQ9jvTtra0D2DbKIpM8YOClCmfk8JLp31k=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 6(Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 7(Anoma.Node.Pinger Oc96nqV6/0FFT/JULG5Ep+Z1c62/8f1Bi0gY9CVmJhs=):::worker\nclassDef root fill:#c4b5fd, stroke:#374151, stroke-width:4px;\nclassDef supervisor fill:#c4b5fd, stroke:#374151, stroke-width:1px;\nclassDef worker fill:#93c5fd, stroke:#374151, stroke-width:1px;\nclassDef notstarted color:#777, fill:#d9d9d9, stroke:#777, stroke-width:1px;\n\n\n```\n\nNow let us see what happens between the actors when we run the mempool\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.mempool.server)],\n  fn ->\n    Mempool.execute(node.mempool)\n  end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 3 AS code_server;\nparticipant 7 AS mnesia_locker;\nparticipant 6 AS mnesia_tm;\nparticipant 8 AS Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=;\nparticipant 2 AS Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=;\nparticipant 4 AS Anoma.Node.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=;\nparticipant 1 AS Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=;\nparticipant 0 AS self();\nparticipant 5 AS #35;PID<0.438.0>;\n0->>1: CALL: execute\n1->>2: ADD LEVEL: info\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>4: CALL: next_order\n4->>1: INFO: tuple\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>2: ADD LEVEL: info\n1->>4: CALL: new_order\n4->>1: INFO: tuple\n1->>2: ADD LEVEL: info\n1->>5: INFO: write_ready\n1->>2: ADD LEVEL: info\n1->>6: INFO: tuple\n6->>1: INFO: mnesia_tm\n1->>7: INFO: tuple\n7->>1: INFO: mnesia_locker\n1->>7: INFO: release_tid\n1->>6: INFO: delete_transaction\n1->>2: ADD LEVEL: info\n1->>2: ADD LEVEL: info\n1->>8: CAST: cast\n1->>0: INFO: tuple\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:ok, 1}\n```\n\nAs we can see, we get a fairly solid overview of what actors sent what messages\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nWe can also see what processes startup when we start an execution\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.mempool.server)],\n  fn -> Mempool.tx(node.mempool, {:kv, increment_counter_val(555)}).pid() end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.1147.0>\n```\n\n```elixir\nKino.Process.render_seq_trace(\n  :all,\n  fn -> Anoma.Node.Logger.add(node.logger, :info, \"help\") end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```","ref":"actors.html#mempool"},{"type":"extras","title":"Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Hoon","ref":"hoon-2.html"},{"type":"extras","title":"Index - Hoon","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"hoon-2.html#index"},{"type":"extras","title":"About This Guide - Hoon","doc":"This guide hopefully serves you to be able to reason about the nock\ncode in Anoma. It is written for a non Hoon audience, so if you are\nfamiliar with Hoon, you may find use in the Nock code as there is a\nbig emphesis on nock itself, rather than just Hoon. If you are not\nfamiliar with Hoon, this merely shows you how to use the\n[Urbit](https://urbit.org/) environment to aid Nock code.\n\nA good general guide to Hoon can be found [At the Hoon School](https://developers.urbit.org/guides/core/hoon-school).\nHopefully the documention here serves as a good companion piece for\nanyone interested in Nock, Hoon, or Anoma.","ref":"hoon-2.html#about-this-guide"},{"type":"extras","title":"Calling","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Calling","ref":"calling.html"},{"type":"extras","title":"Index - Calling","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"calling.html#index"},{"type":"extras","title":"Calling Conventions - Calling","doc":"For this section, it is assumed that one is comfortable with the techniques outlined in the [dumping guide](./dumping.livemd), in particular familiarity with:\n\n1. [dottar(.*)](https://developers.urbit.org/reference/hoon/rune/dot#-dottar)\n2. [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis)\n\nis had, if one is uncomfortable with what is shown here, it would be a good idea to skim back over the [dumping guide](./dumping.livemd) for more information.\n\nWith that disclaimer out of the way, let us talk about calling conventions.","ref":"calling.html#calling-conventions"},{"type":"extras","title":"Basic Nock Calls - Calling","doc":"There are a few ways to call Nock functions, recall that the structure of a functions look like this:\n\n```nock\n[function sample environment-defined-in]\n```\n\n* _Function_ is some nock logic we wish to run\n* _Sample_ is the default argument of the function if non is given\n* _Environment-defined-in_ is the environment the function is defined in and relies upon.\n\nA good basic example can be seen below:\n\n```hoon\n[[0 6] 777 999]\n```\n\nThis function has an arbitrary environment of `999` and a sample of `777`. The logic itself simply grabs the sample from the environment.\n\nA good visualization of the indexing can be seen below\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n2 --> 4\n2 --> 5\n3 --> 6\n3 --> 7\n```\n\nwhere we have in our concrete example\n\n| Index | Nock              |\n| ----- | ----------------- |\n| 1     | `[[0 6] 777 999]` |\n| 2     | `[0 6]`           |\n| 3     | `[777 999]`       |\n| 4     | `0`               |\n| 5     | `6`               |\n| 6     | `777`             |\n| 7     | `999`             |\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThus if we wish to call our code example, the most basic way is by invoking nock `9`. Continuing our example from above, let us see the most basic call of it.\n\n```hoon\n> .*  [[0 6] 777 999]  [9 2 0 1]\n777\n```\n\nTo better understand what the `9` is doing let us ask us the nock structure of it\n\n```hoon\n> ;;  nock  [9 2 0 1]\n[%9 p=2 q=[%0 p=1]]\n```\n\nHere we can see the `9` takes 2 arguments, a `p=2` and a `q=[0 1]` argument.\n\nThe `q=[0 1]` argument goes off first. The point of this is to determine what module/layer (called an [core](https://developers.urbit.org/reference/glossary/core) in hoon) the particular function (called a [gate](https://developers.urbit.org/reference/glossary/gate) in hoon) belongs to.\n\nFrom here the `p=2` is the location of the function/[gate](https://developers.urbit.org/reference/glossary/gate).\n\nIn our example we know the function is indexed at 2, so thus we simply call the logic with the environment it's defined inside, meaning we simply get out the `6`th index which we have observed above is 777\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n`[9 2 0 1]` isn't too interesting on it's own, all we have managed to do, is make fancy default values.\n\nHowever, since the logic we are running indexs into the sample, all we have to do is fine a formula that replaces the sample with the desired value\n\n```hoon\n> .*  [[0 6] 777 999]  [9 2 10 [6 1 888] 0 1]\n888\n> ;;  nock  [9 2 10 [6 1 888] 0 1]\n[%9 p=2 q=[%10 p=[p=6 q=[%1 p=888]] q=[%0 p=1]]]\n```\n\nAbove we do exactly that, all it took was adding a simple `10 [6 1 888]`, however let us analyze what this does.\n\n`%10` is better known as replace at axis, the axis is the first value of `[6 1 888]` which in this case is position `6`. We then run the formula `[1 888]` which is simply saying return the constant `888`, then `10` finishes and replaced position `6` with the result, giving the logic located at `2` (I.E. `[0 6]`) the new sample to run against.\n\nSince the `%9`'s `q=...` has the replaced value, this ends up being the context for the `p=2` to run inside, and thus we have a computation that is effectively:\n\n```hoon\n> .*  [[0 6] 888 999] [9 2 0 1]\n888\n```\n\nWe will in the next section see how Hoon functions are defined, as they give further detail in how we use instruction `9`.","ref":"calling.html#basic-nock-calls"},{"type":"extras","title":"Hoon Gates: What are they really? - Calling","doc":"Something interesting is comparing the `9` described here to [dumping the indicies found in the dumping guide](./dumping.livemd#dumping-indexing-offsets).\n\nNamely we saw:\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nWhat is incongruous, is that we described `9` as calling a function, but in the dumping section, we make it seem like it's effectively only doing indexing to bring the name ready to be called.\n\nThis all has to do with how hoon stores nock functions, they do something quite clever.\n\nInstead of just storing the function as code itself, it stores it similarly to this\n\n```hoon\n[[1 [[0 6] 777 999]] 666 909]\n```\n\nWhere we store a nock function that evaluates to the code, the `1` instruction is simply that, when we evaluate this form we get\n\n```hoon\n> .*  [[1 [[0 6] 777 999]] 666 909]  [9 2 0 1]\n[[0 6] 777 999]\n```\n\nfor which we can now call it\n\n```hoon\n> .*  .*  [[1 [[0 6] 777 999]] 666 909]  [9 2 0 1]  [9 2 0 1]\n777\n```\n\nIn this case, it doesn't do much, but it makes sense if we look at a real example.\n\n```hoon\n> .*  add:anoma  [0 2]\n[ 6\n  [5 [1 0] 0 12]\n  [0 13]\n  9\n  2\n  10\n  [6 [8 [9 342 0 7] 9 2 10 [6 0 28] 0 2] 4 0 13]\n  0\n  1\n]\n```\n\nOn this example I want to focus on the `dec` call `[8 [9 342 0 7] 9 2 10 ...]`. We know this is dec, as we already know it's offset inside layer 1 is `342`, but it's located at `7` as we've pushed `add` with its sample to the tree, making layer 1's index go to 7 (see the [section on how indicies change](./dumping.livemd#how-index-of-layers-change)) relative to `add`.\n\nWhat is very interesting, is that since the [gate](https://developers.urbit.org/reference/glossary/gate) evaluates to the nock function we wish, we can follow it up with the simple `[9 2 10 [6 ...] 0 ...]` pattern we found before.\n\nMeaning that we have decoupled indexing with calling. If Hoon did not do this, then we are in an awkward position that the `[9 342 0 7]` somehow has to get `0 7` index before running the application change `0 28`, complicating the formula. Making it a simple constant function allows the formulas to stay manageable.\n\nSome other minor notes. The call: `[9 2 10 [6 0 28] 0 2]` ends with `0 2` instead of `0 1` because we have bushed with `8`, more on this later.\n\nWe will continue to expand this in the next section, but first let us learn how to evaluate code in the context of Anoma as the standard environment.","ref":"calling.html#hoon-gates-what-are-they-really"},{"type":"extras","title":"Evaluating Calls in The Anoma Context - Calling","doc":"For actually writing code for Anoma, the dump of dec that we saw:\n\n```\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nwould not actually run in the Anoma standard library. This is because it is assuming the current environment which has the Hoon standard library.\n\n```hoon\n> .*  anoma  [7 [0 46] 9 342 0 15]\ndojo: hoon expression failed\n```\n\nRather than by hand editing the `7 [0 46]` out, we can instead tell Hoon that the context of the computation is in Anoma, and this is done through [tisgar(=>)](https://developers.urbit.org/reference/hoon/rune/tis#-tisgar).\n\nA good example can be seen here:\n\n```hoon\n> =>  anoma  !=(dec)\n[9 342 0 15]\n```\n\nWhich gives us the correct computation to run dec on Anoma.\n\n```hoon\n> =>  anoma  .*  .  [9 342 0 15]\n[ [ 6\n    [5 [1 0] 0 6]\n...\n:: dec core emitted\n\n> =>  anoma  .*  .*  .  [9 342 0 15]  [9 2 10 [6 1 777] 0 1]\n776\n```","ref":"calling.html#evaluating-calls-in-the-anoma-context"},{"type":"extras","title":"What a Hoon function call actually does - Calling","doc":"So far this document has only outlined calling Hoon functions by hand, but what does the cannonical application form generate?\n\n```hoon\n> =>  anoma  (dec 3)\n2\n```\n\nWell we can ask [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) what this expression means\n\n```hoon\n> =>  anoma  !=((dec 3))\n[8 [9 342 0 15] 9 2 10 [6 7 [0 3] 1 3] 0 2]\n> ;;  nock  =>  anoma  !=((dec 3))\n[ %8\n  p=[%9 p=342 q=[%0 p=15]]\n  q=[%9 p=2 q=[%10 p=[p=6 q=[%7 p=[%0 p=3] q=[%1 p=3]]] q=[%0 p=2]]]\n]\n```\n\nLet us break down this expression\n\n1. `[%8 p=[9 342 ...] q=[9 2 ...]]`\n   * `8` simply does a push on subject, with the `p` getting consed onto the environment. We've seen this `p` before, it is simply the formula for `dec`.\n   * Thus after the `p` we have `[dec anoma]` filling the environment\n   * This is now the context for the `q=`\n2. `[%9 p=2 q=[%10 ...]]`\n   * We've seen this `[9 2 10 [6 ...] ...]` call before, like before the function within the current layer is located at 2. However what is different is the specifics of the `q`\n3. `[%10 p=[p=6 q=[%7 p=[%0 p=3] q=[%1 p=3]]] q=[0 2]]`\n   * This 10 is a replace at axis 6 like we have seen before, but let us note the `q=[0 2]`.\n   * Most example's we've seen have been `[0 1]`, this example has a `[0 2]` as the first `%8` pushed the `dec` function onto the environment, meaning that the function we wish to replace `6` of is really at index 2!\n   * An important note is that this rule expands to a replace where the `q` and `p` are ran on the original environment.\n   * This means that `q=[%7 ...]` gets to run in the environment where the surrounding environment still exists\n4. `[%7 p=[%0 p=3] q=[%1 p=3]]`\n   * Here are where things get interesting, `%7` is simply composition, thus `p` is ran on the environment then `q` is.\n   * This is important because the `p=[%0 p=3]` simply restores the original environment\n     ```hoon\n     > .*  999  [8 [1 1] 0 1]\n     [1 999]\n     > .*  999  [8 [1 1] 0 3]\n     999\n     ```\n   * Meaning that computation `q` can be ran as if the `%8` never happened.\n   * The Hoon compiler is sometimes smart and will optimize out the `%7`\n5. `[%1 p=3]`\n   * We simply put 3 as the argument\n   * Dec now runs with 3 as we expect.\n\nThus as we can see, the calling convention of Hoon is not very complicated, and is mostly sensible about trying to preserve the environments things are called in.","ref":"calling.html#what-a-hoon-function-call-actually-does"},{"type":"extras","title":"Paramarterized Modules: Or How Gates are just Cores - Calling","doc":"A common occurence in our standard library is the use of paramartized modules. However something interesting to note is that on the [gate](https://developers.urbit.org/reference/glossary/gate) documentation, it mentions\n\n> A [gate](https://developers.urbit.org/reference/glossary/gate) is [core](https://developers.urbit.org/reference/glossary/core) with one arm named $ (buc). They are often called Hoon functions because they have many of the same properties of functions from other programming languages.\n\nMeaning that every time we have been calling `add` we've really been calling a module with a function named $ inside\n\n```hoon\n> =>  anoma  $:add\n0\n```\n\nThus the calling conventions we've discussed above are exactly the same for modules!\n\nLet us look at the `lsh` function for confirmation\n\n```hoon\n> =>  anoma  !=(block)  ::  layer 4\n[9 10 0 1]\n> =>  anoma  !=(lsh:block)\n[7 [9 10 0 1] 9 90 0 1]\n> =>  anoma  !=((lsh:block 3 4))\n[8 [7 [9 10 0 1] 9 90 0 1] 9 2 10 [6 [7 [0 3] 1 3] 7 [0 3] 1 4] 0 2]\n```\n\nWe can see here that block is located at index `10` inside of the anoma environment. Also note the `9` call, we are calling block to bring it to the front!\n\nnext we check `lsh` which is located `90` within it, nothing out of the ordinary. We use `%7` to compose the indexing into the structure, which is reasonable.\n\nWhen we call `lsh` on `3` and `4` the result is exactly like we expect, we generate out the `%8` call that we disected above.\n\nSo we can already call the `lsh` function as if no paramartized was had. This makes sense as we know that each [gate](https://developers.urbit.org/reference/glossary/gate) has a sample that it takes if no substitution is had.\n\nNow let us replace the default block value with `999` (note you don't want to run this, it'll be too slow)\n\n```hoon\n> =>  anoma  !=((~(lsh block 999) 3 4))\n[ 8\n  [8 [9 10 0 1] 9 90 10 [6 7 [0 3] 1 999] 0 2]\n  9\n  2\n  10\n  [6 [7 [0 3] 1 3] 7 [0 3] 1 4]\n  0\n  2\n]\n```\n\nThe only difference that was had was in in  `[8 [9 10 0 1] 9 90 10 [6 7 [0 3] 1 999] 0 2]`. The rest of the formula stayed the same.\n\nHowever looking at this change, this should not be very shocking, as we have analyzed with the function above, we are simply pushing `block` to the front of the env with the `[8 [9 10 0 1] ...]`, leaing the environment being `[block anoma]`, then we simply wish to call `90` where `lsh` is located with the `6` index of the `block` environment being set to `999`.\n\nNote the `6` index is a gate's argument which we can see with this call:\n\n```hoon\n> =>  anoma  !=(block-size:block)\n[7 [9 10 0 1] 0 6]\n```\n\nThen we simply compute the rest of `lsh` with the default value being 999. Using a non large number we can see how this changes the results.\n\n```hoon\n> =>  anoma  (~(lsh block 1) 3 4)\n256\n> =>  anoma  (~(lsh block 0) 3 4)\n32\n> =>  anoma  (lsh:block 3 4)\n32\n```","ref":"calling.html#paramarterized-modules-or-how-gates-are-just-cores"},{"type":"extras","title":"Dumping","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Dumping\n\n```elixir\nMix.install([\n  {:kino_vega_lite, \"~> 0.1.10\"}\n])\n```","ref":"dumping.html"},{"type":"extras","title":"Index - Dumping","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"dumping.html#index"},{"type":"extras","title":"Dumping Nock - Dumping","doc":"Given a functioning Hoon environment with Anoma loaded, we can now start [dumping](https://en.wikipedia.org/wiki/Core_dump) various data in the environment.\n\nThis guide hopefully serves as a good way to give you the tools needed to [dump](https://en.wikipedia.org/wiki/Core_dump) anything for yourself.","ref":"dumping.html#dumping-nock"},{"type":"extras","title":"Dumping Functions - Dumping","doc":"[Dumping](https://en.wikipedia.org/wiki/Core_dump) any [Hoon gate](https://developers.urbit.org/reference/glossary/gate) is relatively easy.\n\nHowever, first we need to learn how to get Hoon to let us use Nock properly. A good way is by reading the [dot(.)](https://developers.urbit.org/reference/hoon/rune/dot) section, as [runes](https://developers.urbit.org/reference/hoon/rune) starting with `.` deal with nock operations.\n\nIn particular we wish to focus on [dottar(.*)](https://developers.urbit.org/reference/hoon/rune/dot#-dottar), which deals with calling nock on some expression.\n\nWe won't go into detail about calling functions in this section, however there is another section that focuses solely on how to call functions and how it works in Nock.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nSpeaking of functions, we should know just a few things about the layout of functions, and their important indicies.\n\nFunctions in Hoon are laid out as the following:\n\n```nock\n[function sample environment-defined-in]\n```\n\n* _Function_ is some nock logic we wish to run\n* _Sample_ is the default argument of the function if non is given\n* _Environment-defined-in_ is the environment the function is defined in and relies upon.\n\nA good basic example can be seen below:\n\n```hoon\n[[0 6] 777 999]\n```\n\nThis function has an arbitrary environment of `999` and a sample of `777`. The logic itself simply grabs the sample from the environment.\n\nA good visualization of the indexing can be seen below\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n2 --> 4\n2 --> 5\n3 --> 6\n3 --> 7\n```\n\nwhere we have in our concrete example\n\n| Index | Nock              |\n| ----- | ----------------- |\n| 1     | `[[0 6] 777 999]` |\n| 2     | `[0 6]`           |\n| 3     | `[777 999]`       |\n| 4     | `0`               |\n| 5     | `6`               |\n| 6     | `777`             |\n| 7     | `999`             |\n\nWith some basics out of the way, let us get to [dumping](https://en.wikipedia.org/wiki/Core_dump) hoon functions!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nWe shall dump the most basic of functions, decrement!\n\nWe can do this simply by bringing decrement to the front of the environment, and getting it in the function form of `[function sample environment]` we saw before. We can do this by simply stating the name of the function we wish, and then get the function out of it by getting the second index!\n\nNote that Hoon uses `function:module` (`f:mn:...:m1`) form.\n\n```nock\n.*  dec:anoma  [0 2]\n[6 [5 [1 0] 0 6] [0 0] 8 [1 0] 8 [1 6 [5 [0 30] 4 0 6] [0 6] 9 2 10 [6 4 0 6] 0 1] 9 2 0 1]\n```\n\nThe logic here doesn't particularly matter, but here we have the nock definiton of decrement, which is wonderful!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis can be done to any function, regardless of how nested the modules are\n\n```hoon\n> .*  lsh:block:anoma  [0 2]\n[ 8\n  [9 4 0 255]\n  9\n  2\n  10\n  [6 [0 29] 7 [0 3] 8 [9 4 0 31] 9 2 10 [6 7 [0 3] 8 [9 4 0 255] 9 2 10 [6 [7 [0 3] 9 182 0 7] 0 28] 0 2] 0 2]\n  0\n  2\n]\n```","ref":"dumping.html#dumping-functions"},{"type":"extras","title":"Casting to Nock, a useful tool - Dumping","doc":"A good way to visualize the dump, is by casting the result to nock\n\n```hoon\n> ;;  nock  [9 2 0 1]\n[%9 p=2 q=[%0 p=1]\n```\n\nthe `p`'s and `q`'s are arguments and the `%9` and `%0` are the nock instructions being ran.\n\nFrom here, the [instruction set can be consluted for the meaning of any particular instruction](https://developers.urbit.org/reference/nock/definition#instructions).\n\n```hoon\n> ;;  nock  .*  dec.anoma  [0 2]\n[ %6\n  p=[%5 p=[%1 p=0] q=[%0 p=6]]\n  q=[%0 p=0]\n  r=[%8 p=[%1 p=0] q=[%8 p=[%1 p=[6 [5 [0 30] 4 0 6] [0 6] 9 2 10 [6 4 0 6] 0 1]] q=[%9 p=2 q=[%0 p=1]]]]\n]\n```","ref":"dumping.html#casting-to-nock-a-useful-tool"},{"type":"extras","title":"Dumping Types - Dumping","doc":"Types in Hoon are just functions!\n\nA good example can be found by looking at the resource-type\n\n```hoon\n> .*  resource:resource-machine  [0 2]\n[ 8\n  [ [8 [7 [0 7] 9 47 0 1] 9 2 10 [6 0 28] 0 2]\n    [6 [6 [3 0 26] [1 1] 1 0] [0 26] 0 0]\n    [6 [6 [3 0 54] [1 1] 1 0] [0 54] 0 0]\n    [6 [6 [3 0 110] [1 1] 1 0] [0 110] 0 0]\n    [6 [5 [1 0] 0 222] [1 0] 6 [5 [1 1] 0 222] [1 1] 0 0]\n    [6 [6 [3 0 446] [1 1] 1 0] [0 446] 0 0]\n    [6 [6 [3 0 894] [1 1] 1 0] [0 894] 0 0]\n    6\n    [6 [3 0 895] [1 1] 1 0]\n    [0 895]\n    0\n    0\n  ]\n  8\n  [5 [0 14] 0 2]\n  0\n  6\n]\n```\n\nThis however does not show how to dump the structure of a type well enough, however this can be fixed by simply just calling it!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\ncalling a type leads to something like this\n\n```hoon\n> (resource:resource-machine)\n[   logic\n  < 1|xpg\n    [ [ roots=it(@)\n        commitments=it(@)\n        nullifiers=it(@)\n        proofs=it(#4)\n        delta=it([denom=@ sign=?(%.y %.n) amount=@])\n        extra=@\n        preference=%~\n      ]\n      [ roots=it(@)\n        commitments=it(@)\n        nullifiers=it(@)\n          proofs\n        it( ^#4\n          [   logic\n            < 1|xpg\n              [ [ roots=it(@)\n                  commitments=it(@)\n                  nullifiers=it(@)\n                  proofs=it(#4)\n                  delta=it([denom=@ sign=?(%.y %.n) amount=@])\n                  extra=@\n                  preference=%~\n                ]\n                [ roots=it(@)\n                  commitments=it(@)\n                  nullifiers=it(@)\n                  proofs=it(#4)\n                  delta=it([denom=@ sign=?(%.y %.n) amount=@])\n                  extra=@\n                  preference=%~\n                ]\n                ?(%.y %.n)\n              ]\n            >\n            label=@t\n            quantity=@\n            data=@\n            eph=?(%.y %.n)\n            nonce=@\n            npk=@\n            rseed=@\n          ]\n        )\n        delta=it([denom=@ sign=?(%.y %.n) amount=@])\n        extra=@\n        preference=%~\n      ]\n      ?(%.y %.n)\n    ]\n  >\n  label=''\n  quantity=0\n  data=0\n  eph=%.y\n  nonce=0\n  npk=0\n  rseed=0\n]\n```\n\nWhich just gives the default values. If the result is hard to read, then no problem, just forget the type information!\n\n```\n> `*`(resource:resource-machine)\n[[[0 15] [0 0 0 0 0 0 0] [0 0 0 0 0 0 0] 0] 0 0 0 0 0 0 0]\n```\n\nHere we simply jsut cast it to the any type, forgetting all information, and we can now see the format of the empty resource.","ref":"dumping.html#dumping-types"},{"type":"extras","title":"Dump Modules - Dumping","doc":"Dumping modules is the same as dumping functions, it's just a matter that one's terminal will be flooded\n\n```hoon\n> .*  resource-machine  [0 2]\n[ [1 0]\n...\n  0\n  1\n]\n```\n\nThus feel free to dump away. This is only useful when trying to copy this to the Elixir codebase.","ref":"dumping.html#dump-modules"},{"type":"extras","title":"Dumping Hoon for Elixir - Dumping","doc":"Since Anoma itself runs Nock and not Hoon, we have to take the Hoon code we have and include it in Elixir somehow.\n\nThis process isn't particular difficult, and we can do it by simply using the tools we've learned in this document.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFor example, it's not uncommon when the standard library that test indicies are not out of date and need to be updated, or maybe we define out a new hoon function for testing.\n\nIn these scenarios, there is a very easy way to update the code.\n\nLet us look at the fibonacci example in Elixir\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n# can be found in https://github.com/anoma/anoma/blob/base/lib/test_helper/nock.ex\n  @spec factorial() :: Noun.t()\n  def factorial() do\n    arm = Noun.Format.parse_always(\"\n    [ 8\n      [1 1 0]\n      8\n      [ 1\n        6\n        [5 [0 30] 1 0]\n        [0 13]\n        9\n        2\n        10\n        [30 8 [9 342 0 255] 9 2 10 [6 0 62] 0 2]\n        10\n        [6 [8 [9 20 0 255] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n        0\n        1\n      ]\n      9\n      2\n      0\n      1\n    ]\")\n    sample = 1\n    [arm, sample | logics_core()]\n  end\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nHere we have some just plain old nock string representing the function, and we append the context to it via normal Elixir. We do this to save space, as we really don't want to dump the entire `Nock.logics_core/0` for every simple function.\n\nOn the Hoon side we just run this to get the proper new logic\n\n```hoon\n> .*  fib:tests  [0 2]\n[ 8\n  [1 1 0]\n  8\n  [ 1\n    6\n    [5 [0 30] 1 0]\n    [0 13]\n    9\n    2\n    10\n    [30 8 [9 342 0 1.023] 9 2 10 [6 0 62] 0 2]\n    10\n    [6 [8 [9 20 0 1.023] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n    0\n    1\n  ]\n  9\n  2\n  0\n  1\n]\n```\n\nand then replace the old logic with the new code.\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  @spec factorial() :: Noun.t()\n  def factorial() do\n    arm = Noun.Format.parse_always(\"\n    [ 8\n      [1 1 0]\n      8\n      [ 1\n        6\n        [5 [0 30] 1 0]\n        [0 13]\n        9\n        2\n        10\n        [30 8 [9 342 0 1.023] 9 2 10 [6 0 62] 0 2]\n        10\n        [6 [8 [9 20 0 1.023] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n        0\n        1\n      ]\n      9\n      2\n      0\n      1\n    ]\")\n    sample = 1\n    [arm,, sample | logics_core()]\n  end\n```\n\nThe process is the same for the code in `Nock`, just dump the `[0 2]` index of the module and replace the string with the result you get in your terminal.","ref":"dumping.html#dumping-hoon-for-elixir"},{"type":"extras","title":"Dumping Indexing Offsets - Dumping","doc":"The tools that we have explored so far only deal with dumping definitions, however they do not explain where these functions are stored in the environment.\n\nThat is where [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) comes handy.\n\n[zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) simply gives us the hoon expression of the argument handed to it.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nLet us start off simple with [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis), let us look at what saying `anoma` actually does.\n\n```hoon\n> !=(anoma)\n[0 46]\n```\n\nInteresting, we can see that saying anoma, indexs into the current environment by `46`. The current environment in Hoon can be conjured with `.`.\n\n```hoon\n> !=(.)\n[0 1]\n```\n\nWith this knowledge in hand, we can verify that anoma really is at index 46!\n\n```hoon\n> =(.*(. [0 46]) anoma)\n%.y\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nNow that we know how to get the index for names like anoma, what about trying to get the index of a function like `dec` inside of the anoma environment.\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n> ;;  nock  !=(dec:anoma)\n[%7 p=[%0 p=46] q=[%9 p=342 q=[%0 p=15]]]\n```\n\nHere it's a bit more complicated to let us break it down step by step.\n\n1. `[%7 p=[%0 p=46] q=...]`\n   * In the section where we are calling `%7`.\n   * This has the effect of just trying to get anoma to be the subject of the following `q` computation.\n2. Now at `q=[%9 p=342 q=[%0 p=15]]` we are running this on anoma itself.\n   * `%9` is rather basic, trying to call the given index `p` at arm `q`.\n   * In our case, `dec` is located at index `342` inside of arm at the layer/module located at `[0 15]`.\n   * `[0 15]` is really layer 1 in the source code and is properly documented as such\n\n```hoon\n~%  %one  +  ~\n|%\n++  dec  ::  +342\n  ~/  %dec\n  |=  a=@\n  ?<  =(0 a)\n  =|  b=@\n  |-  ^-  @\n  ?:  =(a +(b))  b\n  $(b +(b))\n\n```\n\nThus, it's not very complicated, thus in the form\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nall we have to pay attention to is the `342` and the `15`, some more examples show this off well\n\n```hoon\n> !=(dec:anoma) ::  index 342 at layer 1\n[7 [0 46] 9 342 0 15]\n> !=(add:anoma) ::  index 20 at layer 1\n[7 [0 46] 9 20 0 15]\n> !=(trap:anoma) ::  index 20 at layer 2\n[7 [0 46] 9 20 0 7]\n> !=(unit:anoma) ::  index 42 at layer 2\n[7 [0 46] 9 42 0 7]\n```\n\nHere for any non nested module we can see the layers and indexs quite plainly!\n\n<!-- livebook:{\"branch_parent_index\":7} -->","ref":"dumping.html#dumping-indexing-offsets"},{"type":"extras","title":"How Index of Layers Change - Dumping","doc":"The hoon environment is a binary tree. Included below is an extended diagram that we will use for our explanation.\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n3 --> 6\n3 --> 7\n7 --> 14\n7 --> 15\n15 --> 30\n15 --> 31\n```\n\nWhenever, a layer is made in hoon, we should think of it as pushed onto the env. So for Anoma the layers can be seen like this\n\n```mermaid\nstateDiagram-v2\nlayer_four --> code_in_layer_four\nlayer_four --> layer_three\nlayer_three --> code_in_layer_three\nlayer_three --> layer_two\nlayer_two --> code_in_layer_two\nlayer_two --> layer_one\nlayer_one --> code_in_layer_one\nlayer_one --> 0_3_99\n```\n\nIf we pushed layer 5, then everything shifts, layer 1 moves from 15 to 31.\n\nThus the indexing works on a rather simple formula that can be read about: [here](https://oeis.org/A000918). The code is not exactly this formula, but below we will show how it shapes up.\n\n```elixir\nseries = 1..5 |> Enum.map(fn i -> 2 ** i - 1 end)\nindicies = 1..5\nmy_data = %{series: series, indicies: indicies}\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%{series: [1, 3, 7, 15, 31], indicies: 1..5}\n```\n\n<!-- livebook:{\"attrs\":\"eyJjaGFydF90aXRsZSI6IkluZGV4aW5nIFNlcmllcyIsImhlaWdodCI6MzAwLCJsYXllcnMiOlt7ImFjdGl2ZSI6dHJ1ZSwiY2hhcnRfdHlwZSI6ImJhciIsImNvbG9yX2ZpZWxkIjpudWxsLCJjb2xvcl9maWVsZF9hZ2dyZWdhdGUiOm51bGwsImNvbG9yX2ZpZWxkX2JpbiI6bnVsbCwiY29sb3JfZmllbGRfc2NhbGVfc2NoZW1lIjpudWxsLCJjb2xvcl9maWVsZF90eXBlIjpudWxsLCJkYXRhX3ZhcmlhYmxlIjoibXlfZGF0YSIsImdlb2RhdGFfY29sb3IiOiJncmVlbiIsImxhdGl0dWRlX2ZpZWxkIjoiYSIsImxvbmdpdHVkZV9maWVsZCI6ImIiLCJ4X2ZpZWxkIjoiaW5kaWNpZXMiLCJ4X2ZpZWxkX2FnZ3JlZ2F0ZSI6bnVsbCwieF9maWVsZF9iaW4iOm51bGwsInhfZmllbGRfc2NhbGVfdHlwZSI6bnVsbCwieF9maWVsZF90eXBlIjoicXVhbnRpdGF0aXZlIiwieV9maWVsZCI6InNlcmllcyIsInlfZmllbGRfYWdncmVnYXRlIjpudWxsLCJ5X2ZpZWxkX2JpbiI6bnVsbCwieV9maWVsZF9zY2FsZV90eXBlIjpudWxsLCJ5X2ZpZWxkX3R5cGUiOiJxdWFudGl0YXRpdmUifV0sInZsX2FsaWFzIjoiRWxpeGlyLlZlZ2FMaXRlIiwid2lkdGgiOjIwMH0\",\"chunks\":null,\"kind\":\"Elixir.KinoVegaLite.ChartCell\",\"livebook_object\":\"smart_cell\"} -->\n\n```elixir\nVegaLite.new(width: 200, height: 300, title: \"Indexing Series\")\n|> VegaLite.data_from_values(my_data, only: [\"indicies\", \"series\"])\n|> VegaLite.mark(:bar)\n|> VegaLite.encode_field(:x, \"indicies\", type: :quantitative)\n|> VegaLite.encode_field(:y, \"series\", type: :quantitative)\n```","ref":"dumping.html#how-index-of-layers-change"},{"type":"extras","title":"Setting up Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Setting up Hoon","ref":"setting-up.html"},{"type":"extras","title":"Index - Setting up Hoon","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"setting-up.html#index"},{"type":"extras","title":"Getting a Good Hoon environment - Setting up Hoon","doc":"A good starting point is to read [Hoon's docs on environment](https://developers.urbit.org/guides/core/environment)\n\nIt's good to follow it until the section \"Mount a desk\"\n\nFrom here we can setup the environment quite nicely\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```hoon\n|merge %anoma our %base\n|mount %anoma\n```\n\nFrom here we want to remove all the uneeded files, get it to the following state:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```bash\n8 taichi@Gensokyo:~/Documents/Workspace/Hoon/zod git:master:? % tree anoma\nanoma\n├── mar\n│   ├── hoon.hoon\n│   ├── mime.hoon\n│   ├── noun.hoon\n│   ├── txt-diff.hoon\n│   └── txt.hoon\n└── sys.kelvin\n\n2 directories, 6 files\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nwith `sys.kelvin` having only `[%zuse 412]`\n\nNow that we have our minimal state, we can symlink in the files in\nhttps://github.com/anoma/anoma/tree/base/hoon\n\ninto `lib`. It should now look something like this\n\n```bash\n9 taichi@Gensokyo:~/Documents/Workspace/Hoon/zod git:master:? % tree anoma\nanoma\n├── lib\n│   ├── anoma.hoon -> .../hoon/anoma.hoon\n│   ├── logics.hoon -> .../hoon/logics.hoon\n│   ├── resource-machine.hoon -> .../hoon/resource-machine.hoon\n│   └── tests.hoon -> .../hoon/tests.hoon\n├── mar\n│   ├── hoon.hoon\n│   ├── mime.hoon\n│   ├── noun.hoon\n│   ├── txt-diff.hoon\n│   └── txt.hoon\n└── sys.kelvin\n\n3 directories, 10 files\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nNow we can mount our anoma code into hoon\n\n```hoon\n> |commit %anoma\n>=\n> =anoma -build-file /=anoma=/lib/anoma/hoon\n> =resource-machine -build-file /=anoma=/lib/resource-machine/hoon\n> =logics -build-file /=anoma=/lib/logics/hoon\n> =tests -build-file /=anoma=/lib/tests/hoon\n```\n\nFrom here, the hoon environment is ready to be used and it should work just as Anoma uses Nock.","ref":"setting-up.html#getting-a-good-hoon-environment"}],"content_type":"text/markdown","producer":{"name":"ex_doc","version":[48,46,51,52,46,50]}}